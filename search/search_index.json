{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#introduction","title":"Introduction","text":"<p>The user interface has evolved dramatically over the years, bringing us incredible benefits in terms of time efficiency. For instance, in the past, we had to manually dial a number to call someone with an old phone. But now, with buttons, touch screens and even voice commands, we can make calls in a matter of seconds.</p> <p>In many machine learning projects, we face the challenge of comparing different models, datasets and frameworks. This can be very tedious\ud83d\ude12 and time-consuming\u23f3. Because each dataset has its own format, each framework has its own configuration and each model has its own input and output even they are dealing with the exact same task \ud83d\ude20.</p> <p>When it comes to MLOps (machine learning operations), you need to be able to keep up with all the new ideas and SOTA models in deep learning as quickly as possible\ud83d\ude80.</p> <p>Here comes Waffle\ud83e\uddc7. Waffle is a framework that lets you use lots of different deep learning tools through just one interface. It's user-friendly and easy\ud83d\ude0a. We believe it's going to make a big revolution in the AI industry.</p> <p></p> <p>Experience the power\ud83d\udcaa of revolution that Waffle\ud83e\uddc7 brings to you, unlocking limitless possibilities for your machine learning projects.</p>"},{"location":"#discussion","title":"Discussion","text":"<p>If you want to discuss about waffle or request new features, please use our discussion page</p> <p></p>"},{"location":"tutorials/","title":"Welcome to Waffle Tutorial \ud83e\uddc7\ud83e\uddc7\ud83e\uddc7","text":"<p>In this tutorial, we will learn how to use <code>Waffle</code>: </p> <ul> <li>Waffle Hub</li> </ul>"},{"location":"tutorials/hub/","title":"Index","text":"<p>You can do following things with this Waffle Hub:</p> <ul> <li>Waffle Hub</li> </ul> <p>See Waffle Hub for more details.</p>"},{"location":"tutorials/hub/using_hub/","title":"Waffle_hub","text":"In\u00a0[1]: Copied! <pre>from waffle_hub.hub import Hub\nfrom waffle_hub.type import TaskType\n\nHub.get_available_backends()\n</pre> from waffle_hub.hub import Hub from waffle_hub.type import TaskType  Hub.get_available_backends() Out[1]: <pre>[&lt;BackendType.ULTRALYTICS: 'ultralytics'&gt;,\n &lt;BackendType.AUTOCARE_DLT: 'autocare_dlt'&gt;,\n &lt;BackendType.TRANSFORMERS: 'transformers'&gt;]</pre> In\u00a0[2]: Copied! <pre>Hub.get_available_tasks(\"ultralytics\")\n</pre> Hub.get_available_tasks(\"ultralytics\") Out[2]: <pre>[&lt;TaskType.OBJECT_DETECTION: 'object_detection'&gt;,\n &lt;TaskType.CLASSIFICATION: 'classification'&gt;,\n &lt;TaskType.INSTANCE_SEGMENTATION: 'instance_segmentation'&gt;]</pre> In\u00a0[3]: Copied! <pre>Hub.get_available_model_types(\"ultralytics\", \"OBJECT_DETECTION\")\n</pre> Hub.get_available_model_types(\"ultralytics\", \"OBJECT_DETECTION\") Out[3]: <pre>['yolov8', 'yolov5']</pre> In\u00a0[4]: Copied! <pre>Hub.get_available_model_sizes(\"ultralytics\", \"OBJECT_DETECTION\", \"yolov8\")\n</pre> Hub.get_available_model_sizes(\"ultralytics\", \"OBJECT_DETECTION\", \"yolov8\") Out[4]: <pre>['n', 's', 'm', 'l', 'x']</pre> In\u00a0[5]: Copied! <pre>Hub.get_available_tasks(\"transformers\")\n</pre> Hub.get_available_tasks(\"transformers\") Out[5]: <pre>[&lt;TaskType.OBJECT_DETECTION: 'object_detection'&gt;,\n &lt;TaskType.CLASSIFICATION: 'classification'&gt;]</pre> In\u00a0[6]: Copied! <pre>Hub.get_available_model_types(\"transformers\", \"OBJECT_DETECTION\")\n</pre> Hub.get_available_model_types(\"transformers\", \"OBJECT_DETECTION\") Out[6]: <pre>['DETR', 'DETA', 'YOLOS']</pre> In\u00a0[7]: Copied! <pre>Hub.get_available_model_sizes(\"transformers\", \"OBJECT_DETECTION\", \"DETR\")\n</pre> Hub.get_available_model_sizes(\"transformers\", \"OBJECT_DETECTION\", \"DETR\") Out[7]: <pre>['base', 'large', 'conditional', 'deformable']</pre> In\u00a0[8]: Copied! <pre>Hub.get_available_tasks(\"autocare_dlt\")\n</pre> Hub.get_available_tasks(\"autocare_dlt\") <pre>2024-01-04 17:06:24.197 | WARNING  | autocare_dlt.core.dataset.utils.coco_eval:&lt;module&gt;:13 - Install fast-coco-eval is recommended, now using pycocotools.\n</pre> Out[8]: <pre>[&lt;TaskType.OBJECT_DETECTION: 'object_detection'&gt;,\n &lt;TaskType.CLASSIFICATION: 'classification'&gt;,\n &lt;TaskType.TEXT_RECOGNITION: 'text_recognition'&gt;,\n &lt;TaskType.SEMANTIC_SEGMENTATION: 'semantic_segmentation'&gt;]</pre> In\u00a0[9]: Copied! <pre>Hub.get_available_model_types(\"autocare_dlt\", \"OBJECT_DETECTION\")\n</pre> Hub.get_available_model_types(\"autocare_dlt\", \"OBJECT_DETECTION\") Out[9]: <pre>['YOLOv5']</pre> In\u00a0[10]: Copied! <pre>Hub.get_available_model_sizes(\"autocare_dlt\", \"OBJECT_DETECTION\", \"YOLOv5\")\n</pre> Hub.get_available_model_sizes(\"autocare_dlt\", \"OBJECT_DETECTION\", \"YOLOv5\") Out[10]: <pre>['s', 'm', 'l']</pre> In\u00a0[11]: Copied! <pre>ultralytics_hub = Hub.new(\n    name=\"ultralytics_mnist_detection\",\n    backend=\"ultralytics\",\n    task=\"object_detection\",\n    model_type=\"yolov8\",\n    model_size=\"n\",\n)\n</pre> ultralytics_hub = Hub.new(     name=\"ultralytics_mnist_detection\",     backend=\"ultralytics\",     task=\"object_detection\",     model_type=\"yolov8\",     model_size=\"n\", ) <pre>/home/snuailab/Desktop/waffle_hub/waffle_hub/hub/manager/base_manager.py:168: UserWarning: Categories is not specified.\nIt follows the categories of Dataset when the training starts.\n  warnings.warn(\n</pre> <p><code>Hub</code> instance provides several useful properties and methods. See Hub Documentation for more details.</p> In\u00a0[12]: Copied! <pre>ultralytics_hub.manager.MODEL_TYPES\n</pre> ultralytics_hub.manager.MODEL_TYPES Out[12]: <pre>{&lt;TaskType.OBJECT_DETECTION: 'object_detection'&gt;: {'yolov8': {'n': 'yolov8n.pt',\n   's': 'yolov8s.pt',\n   'm': 'yolov8m.pt',\n   'l': 'yolov8l.pt',\n   'x': 'yolov8x.pt'},\n  'yolov5': {'n': 'yolov5nu.pt',\n   's': 'yolov5su.pt',\n   'm': 'yolov5mu.pt',\n   'l': 'yolov5lu.pt',\n   'x': 'yolov5xu.pt',\n   'n6': 'yolov5n6u.pt',\n   's6': 'yolov5s6u.pt',\n   'm6': 'yolov5m6u.pt',\n   'l6': 'yolov5l6u.pt',\n   'x6': 'yolov5x6u.pt'}},\n &lt;TaskType.CLASSIFICATION: 'classification'&gt;: {'yolov8': {'n': 'yolov8n-cls.pt',\n   's': 'yolov8s-cls.pt',\n   'm': 'yolov8m-cls.pt',\n   'l': 'yolov8l-cls.pt',\n   'x': 'yolov8x-cls.pt'}},\n &lt;TaskType.INSTANCE_SEGMENTATION: 'instance_segmentation'&gt;: {'yolov8': {'n': 'yolov8n-seg.pt',\n   's': 'yolov8s-seg.pt',\n   'm': 'yolov8m-seg.pt',\n   'l': 'yolov8l-seg.pt',\n   'x': 'yolov8x-seg.pt'}}}</pre> In\u00a0[13]: Copied! <pre>ultralytics_hub.get_model_config()\n</pre> ultralytics_hub.get_model_config() Out[13]: <pre>ModelConfig(name='ultralytics_mnist_detection', backend='ultralytics', version='8.0.227', task='object_detection', model_type='yolov8', model_size='n', categories=[])</pre> In\u00a0[14]: Copied! <pre>huggingface_hub = Hub.new(\n    name=\"huggingface_mnist_detection\",\n    backend=\"transformers\",\n    task=\"object_detection\",\n    model_type=\"DETR\",\n    model_size=\"base\",\n)\n</pre> huggingface_hub = Hub.new(     name=\"huggingface_mnist_detection\",     backend=\"transformers\",     task=\"object_detection\",     model_type=\"DETR\",     model_size=\"base\", ) In\u00a0[15]: Copied! <pre>huggingface_hub.manager.MODEL_TYPES\n</pre> huggingface_hub.manager.MODEL_TYPES Out[15]: <pre>{&lt;TaskType.OBJECT_DETECTION: 'object_detection'&gt;: {'DETR': {'base': 'facebook/detr-resnet-50',\n   'large': 'facebook/detr-resnet-101',\n   'conditional': 'microsoft/conditional-detr-resnet-50',\n   'deformable': 'SenseTime/deformable-detr'},\n  'DETA': {'resnet': 'jozhang97/deta-resnet-50',\n   'swin': 'jozhang97/deta-swin-large'},\n  'YOLOS': {'base': 'hustvl/yolos-base',\n   'tiny': 'hustvl/yolos-tiny',\n   'small': 'hustvl/yolos-small'}},\n &lt;TaskType.CLASSIFICATION: 'classification'&gt;: {'ResNet': {'50': 'microsoft/resnet-50',\n   '18': 'microsoft/resnet-18',\n   '101': 'microsoft/resnet-101',\n   '152': 'microsoft/resnet-152'},\n  'ViT': {'base': 'google/vit-base-patch16-224',\n   'tiny': 'WinKawaks/vit-tiny-patch16-224',\n   'large': 'google/vit-large-patch16-224'},\n  'ConvNextV2': {'base': 'facebook/convnextv2-base-22k-224',\n   'tiny': 'facebook/convnextv2-tiny-22k-224',\n   'large': 'facebook/convnextv2-large-22k-224',\n   'huge': 'facebook/convnextv2-huge-22k-224'},\n  'Swinv2': {'base': 'microsoft/swinv2-base-patch4-window8-256',\n   'tiny': 'microsoft/swinv2-tiny-patch4-window8_256',\n   'small': 'microsoft/swinv2-small-patch4-window8_256',\n   'large': 'microsoft/swinv2-large-patch4-window12-192-22k'}}}</pre> In\u00a0[16]: Copied! <pre>huggingface_hub.get_model_config()\n</pre> huggingface_hub.get_model_config() Out[16]: <pre>ModelConfig(name='huggingface_mnist_detection', backend='transformers', version='4.34.1', task='object_detection', model_type='DETR', model_size='base', categories=[])</pre> In\u00a0[17]: Copied! <pre>autocare_dlt_hub = Hub.new(\n    name=\"autocare_dlt_mnist_detection\",\n    backend=\"autocare_dlt\",\n    task=\"object_detection\",\n    model_type=\"YOLOv5\",\n    model_size=\"s\",\n)\n</pre> autocare_dlt_hub = Hub.new(     name=\"autocare_dlt_mnist_detection\",     backend=\"autocare_dlt\",     task=\"object_detection\",     model_type=\"YOLOv5\",     model_size=\"s\", ) <pre>/home/snuailab/Desktop/waffle_hub/waffle_hub/hub/manager/adapter/autocare_dlt/autocare_dlt.py:71: UserWarning: You've loaded the Hub created with autocare_dlt==autocare-dlt, \nbut the installed version is 0.2.6.\n  warnings.warn(\n</pre> In\u00a0[18]: Copied! <pre>autocare_dlt_hub.manager.MODEL_TYPES\n</pre> autocare_dlt_hub.manager.MODEL_TYPES Out[18]: <pre>{&lt;TaskType.OBJECT_DETECTION: 'object_detection'&gt;: {'YOLOv5': ['s', 'm', 'l']},\n &lt;TaskType.CLASSIFICATION: 'classification'&gt;: {'Classifier': ['s', 'm', 'l']},\n &lt;TaskType.TEXT_RECOGNITION: 'text_recognition'&gt;: {'TextRecognition': ['s',\n   'm',\n   'l'],\n  'LicencePlateRecognition': ['s', 'm', 'l']},\n &lt;TaskType.SEMANTIC_SEGMENTATION: 'semantic_segmentation'&gt;: {'Segmenter': ['m']}}</pre> In\u00a0[19]: Copied! <pre>autocare_dlt_hub.get_model_config()\n</pre> autocare_dlt_hub.get_model_config() Out[19]: <pre>ModelConfig(name='autocare_dlt_mnist_detection', backend='autocare_dlt', version='autocare-dlt', task='object_detection', model_type='YOLOv5', model_size='s', categories=[])</pre> <p>(The tutorials are based on \"ultralytics\" and other backends can be used the same.)</p> In\u00a0[20]: Copied! <pre>from waffle_hub.dataset import Dataset\n\n# make sample or load\ntry:\n    dataset = Dataset.sample(\"mnist_det\", task=TaskType.OBJECT_DETECTION)\n    dataset.split(train_ratio=0.8, val_ratio=0.1, test_ratio=0.1)\nexcept:\n    dataset = Dataset.load(\"mnist_det\")\n</pre> from waffle_hub.dataset import Dataset  # make sample or load try:     dataset = Dataset.sample(\"mnist_det\", task=TaskType.OBJECT_DETECTION)     dataset.split(train_ratio=0.8, val_ratio=0.1, test_ratio=0.1) except:     dataset = Dataset.load(\"mnist_det\")  <pre>loading annotations into memory...\nDone (t=0.00s)\ncreating index...\nindex created!\n</pre> <pre>1it [00:00, 26.75it/s]:   0%|          | 0/100 [00:00&lt;?, ?it/s]\nImporting coco dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00, 2504.71it/s]\n</pre> In\u00a0[21]: Copied! <pre>result = ultralytics_hub.train(\n    dataset=dataset,\n    image_size=640,\n    epochs=50,\n    batch_size=4,\n)\n\nresult\n</pre> result = ultralytics_hub.train(     dataset=dataset,     image_size=640,     epochs=50,     batch_size=4, )  result <pre>New https://pypi.org/project/ultralytics/8.0.234 available \ud83d\ude03 Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.227 \ud83d\ude80 Python-3.10.13 torch-1.13.1 CUDA:0 (NVIDIA GeForce RTX 3070, 7982MiB)\nWARNING \u26a0\ufe0f Upgrade to torch&gt;=2.0.0 for deterministic training.\nengine/trainer: task=detect, mode=train, model=yolov8n.pt, data=/home/snuailab/Desktop/waffle_hub/docs/tutorials/datasets/mnist_det/exports/ULTRALYTICS/data.yaml, epochs=50, patience=50, batch=4, imgsz=[640, 640], save=True, save_period=-1, cache=False, device=0, workers=2, project=hubs/ultralytics_mnist_detection, name=artifacts, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=hubs/ultralytics_mnist_detection/artifacts\nOverriding model.yaml nc=80 with nc=2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \nModel summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\nTensorBoard: Start with 'tensorboard --logdir hubs/ultralytics_mnist_detection/artifacts', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\nAMP: running Automatic Mixed Precision (AMP) checks with YOLOv8n...\nAMP: checks passed \u2705\nWARNING \u26a0\ufe0f updating to 'imgsz=640'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\ntrain: New cache created: /home/snuailab/Desktop/waffle_hub/docs/tutorials/datasets/mnist_det/exports/ULTRALYTICS/train/labels.cache\n</pre> <pre>train: Scanning /home/snuailab/Desktop/waffle_hub/docs/tutorials/datasets/mnist_det/exports/ULTRALYTICS/train/labels... 79 images, 0 backgrounds, 0 corrupt: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 79/79 [00:00&lt;00:00, 4415.00it/s]\n</pre> <pre>albumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\nval: New cache created: /home/snuailab/Desktop/waffle_hub/docs/tutorials/datasets/mnist_det/exports/ULTRALYTICS/val/labels.cache\n</pre> <pre>val: Scanning /home/snuailab/Desktop/waffle_hub/docs/tutorials/datasets/mnist_det/exports/ULTRALYTICS/val/labels... 9 images, 0 backgrounds, 0 corrupt: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 3013.87it/s]\n</pre> <pre>Plotting labels to hubs/ultralytics_mnist_detection/artifacts/labels.jpg... \noptimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \noptimizer: AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to hubs/ultralytics_mnist_detection/artifacts\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>       1/50      0.69G      1.822      5.281      1.261          1        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:01&lt;00:00, 16.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 19.36it/s]\n</pre> <pre>                   all          9          9    0.00333          1      0.269      0.251\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>       2/50     0.734G       1.46      3.949      1.172          5        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.01it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 39.78it/s]\n</pre> <pre>                   all          9          9    0.00333          1      0.659      0.387\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>       3/50     0.734G      1.215      3.469      1.105          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 24.57it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 40.61it/s]\n</pre> <pre>                   all          9          9    0.00336          1      0.709      0.398\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>       4/50     0.734G      1.232      2.838      1.084          7        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.36it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 39.56it/s]\n</pre> <pre>                   all          9          9      0.549      0.528      0.661       0.37\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>       5/50     0.734G      1.297      2.922      1.138          4        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 39.54it/s]\n</pre> <pre>                   all          9          9      0.363      0.518       0.43      0.175\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>       6/50     0.734G      1.615      3.675      1.343          2        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 41.46it/s]\n</pre> <pre>                   all          9          9     0.0511        0.2     0.0402    0.00585\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>       7/50     0.734G      1.274      3.439      1.118          5        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 40.06it/s]\n</pre> <pre>                   all          9          9      0.504      0.125     0.0116    0.00534\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>       8/50     0.734G      1.344      3.187      1.172          4        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.82it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 37.59it/s]\n</pre> <pre>                   all          9          9       0.52      0.442      0.423      0.234\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>       9/50     0.734G      1.114      2.676      1.024          6        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 40.40it/s]\n</pre> <pre>                   all          9          9       0.51      0.994      0.544      0.414\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      10/50     0.734G      1.179      2.848      1.035          5        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 24.45it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 41.00it/s]\n</pre> <pre>                   all          9          9      0.703      0.688      0.797      0.537\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      11/50     0.734G      1.321      2.869       1.13          4        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.44it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 35.82it/s]\n</pre> <pre>                   all          9          9      0.683      0.982      0.962       0.75\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      12/50     0.734G      1.073      2.282      1.011          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 27.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 40.96it/s]\n</pre> <pre>                   all          9          9      0.961      0.885      0.978      0.751\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      13/50     0.734G      1.133      2.143      1.087          2        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 27.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 37.22it/s]\n</pre> <pre>                   all          9          9      0.918      0.926      0.995      0.821\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      14/50     0.734G      1.035      2.394      1.038          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 42.05it/s]\n</pre> <pre>                   all          9          9      0.915          1      0.995      0.808\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      15/50     0.734G      1.278      2.525      1.098          4        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.47it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 42.29it/s]\n</pre> <pre>                   all          9          9      0.914          1      0.995      0.799\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      16/50     0.734G       1.12       2.02       1.03          4        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.45it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 40.61it/s]\n</pre> <pre>                   all          9          9      0.985          1      0.995       0.79\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      17/50     0.734G       1.03      1.836     0.9985          6        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 39.34it/s]\n</pre> <pre>                   all          9          9      0.985          1      0.995      0.761\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      18/50     0.734G      1.069      2.128      1.005          6        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.53it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 40.82it/s]\n</pre> <pre>                   all          9          9      0.983          1      0.995      0.813\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      19/50     0.734G      0.957      1.706     0.9848          2        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.56it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 41.70it/s]\n</pre> <pre>                   all          9          9      0.964          1      0.995      0.801\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      20/50     0.734G      1.015      1.783      1.052          2        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 37.79it/s]\n</pre> <pre>                   all          9          9      0.959          1      0.995      0.824\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      21/50     0.734G     0.9298      2.976      1.003          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 39.18it/s]\n</pre> <pre>                   all          9          9      0.955          1      0.995      0.832\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      22/50     0.734G      1.006      2.071       1.02          5        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 24.94it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 40.83it/s]\n</pre> <pre>                   all          9          9      0.949          1      0.995      0.836\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      23/50     0.734G     0.9847      1.668      1.011          7        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.91it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 39.67it/s]\n</pre> <pre>                   all          9          9      0.974          1      0.995      0.808\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      24/50     0.734G     0.8943      1.887     0.9774          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.51it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 41.02it/s]\n</pre> <pre>                   all          9          9      0.972      0.999      0.995      0.841\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      25/50     0.734G     0.8872      1.614     0.9938          5        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.49it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 41.67it/s]\n</pre> <pre>                   all          9          9      0.967          1      0.995      0.841\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      26/50     0.734G     0.8488      1.626     0.9292          2        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 42.07it/s]\n</pre> <pre>                   all          9          9      0.987          1      0.995      0.848\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      27/50     0.734G     0.9375      1.651     0.9823          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.79it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 43.38it/s]\n</pre> <pre>                   all          9          9      0.978          1      0.995      0.916\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      28/50     0.734G     0.8891      1.548      1.009          7        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 24.02it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 40.40it/s]\n</pre> <pre>                   all          9          9      0.981          1      0.995       0.96\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      29/50     0.734G     0.8107      1.592     0.9312          2        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 23.79it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 38.68it/s]\n</pre> <pre>                   all          9          9      0.987          1      0.995      0.905\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      30/50     0.734G     0.8249      1.368     0.9427          5        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 23.54it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 44.01it/s]\n</pre> <pre>                   all          9          9       0.99          1      0.995      0.904\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      31/50     0.734G     0.7314      1.373     0.9075          4        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 23.63it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 40.21it/s]\n</pre> <pre>                   all          9          9      0.988          1      0.995      0.888\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      32/50     0.734G     0.7548      1.301     0.9252          4        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 39.95it/s]\n</pre> <pre>                   all          9          9      0.984          1      0.995      0.912\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      33/50     0.734G     0.7588      1.596     0.9135          5        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 28.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 45.52it/s]\n</pre> <pre>                   all          9          9      0.971          1      0.995       0.89\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      34/50     0.734G     0.7808      1.432      0.927          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 42.34it/s]\n</pre> <pre>                   all          9          9      0.964          1      0.995      0.839\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      35/50     0.734G     0.8292      1.507     0.9695          4        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 41.49it/s]\n</pre> <pre>                   all          9          9      0.978          1      0.995      0.848\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      36/50     0.734G     0.7424      1.348     0.9429          2        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 43.04it/s]\n</pre> <pre>                   all          9          9      0.987          1      0.995      0.863\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      37/50     0.734G     0.8563      1.267     0.9637          4        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.81it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 41.94it/s]\n</pre> <pre>                   all          9          9      0.985          1      0.995      0.882\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      38/50     0.734G     0.7505      1.268     0.8922          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 44.28it/s]\n</pre> <pre>                   all          9          9      0.985          1      0.995      0.891\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      39/50     0.734G     0.6884      1.269     0.9136          5        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 27.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 44.60it/s]\n</pre> <pre>                   all          9          9      0.977          1      0.995      0.872\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      40/50     0.734G     0.7634      1.237      0.911          8        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.13it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 45.40it/s]\n</pre> <pre>                   all          9          9       0.97          1      0.995      0.882\nClosing dataloader mosaic\nalbumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      41/50     0.732G      0.657      1.304     0.9203          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 22.98it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 42.61it/s]\n</pre> <pre>                   all          9          9      0.963      0.999      0.995      0.902\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      42/50     0.732G     0.6394      1.248     0.9003          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 25.67it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 44.40it/s]\n</pre> <pre>                   all          9          9      0.964          1      0.995        0.9\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      43/50     0.732G     0.6424       1.27     0.8791          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.81it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 44.02it/s]\n</pre> <pre>                   all          9          9       0.97          1      0.995        0.9\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      44/50     0.732G     0.5794      1.157     0.8961          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 27.23it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 43.70it/s]\n</pre> <pre>                   all          9          9      0.977          1      0.995      0.941\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      45/50     0.732G     0.6225       1.21     0.8864          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.76it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 44.50it/s]\n</pre> <pre>                   all          9          9      0.982          1      0.995      0.902\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      46/50     0.732G     0.6082      1.201     0.8573          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.01it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 44.54it/s]\n</pre> <pre>                   all          9          9      0.989          1      0.995      0.898\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      47/50     0.732G      0.555       1.19     0.8721          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.47it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 42.92it/s]\n</pre> <pre>                   all          9          9       0.99          1      0.995      0.927\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      48/50     0.732G     0.5454      1.161     0.8357          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 27.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 44.35it/s]\n</pre> <pre>                   all          9          9       0.99          1      0.995       0.93\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      49/50     0.732G     0.5389       1.13     0.8415          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.77it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 40.50it/s]\n</pre> <pre>                   all          9          9       0.99          1      0.995      0.912\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n</pre> <pre>      50/50     0.732G     0.5439      1.111     0.8559          3        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 26.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 43.84it/s]\n</pre> <pre>                   all          9          9      0.989          1      0.995      0.924\n\n50 epochs completed in 0.018 hours.\nOptimizer stripped from hubs/ultralytics_mnist_detection/artifacts/weights/last.pt, 6.2MB\nOptimizer stripped from hubs/ultralytics_mnist_detection/artifacts/weights/best.pt, 6.2MB\n\nValidating hubs/ultralytics_mnist_detection/artifacts/weights/best.pt...\nUltralytics YOLOv8.0.227 \ud83d\ude80 Python-3.10.13 torch-1.13.1 CUDA:0 (NVIDIA GeForce RTX 3070, 7982MiB)\nModel summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n</pre> <pre>                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 31.37it/s]\n</pre> <pre>                   all          9          9      0.981          1      0.995       0.96\n                     1          9          4      0.986          1      0.995      0.958\n                     2          9          5      0.976          1      0.995      0.963\nSpeed: 1.2ms preprocess, 2.0ms inference, 0.0ms loss, 1.1ms postprocess per image\nResults saved to hubs/ultralytics_mnist_detection/artifacts\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:01&lt;00:00,  2.29it/s]\n</pre> Out[21]: <pre>TrainResult(best_ckpt_file=PosixPath('hubs/ultralytics_mnist_detection/weights/best_ckpt.pt'), last_ckpt_file=PosixPath('hubs/ultralytics_mnist_detection/weights/last_ckpt.pt'), metrics=[[{'tag': 'epoch', 'value': 1.0}, {'tag': 'train/box_loss', 'value': 1.8225}, {'tag': 'train/cls_loss', 'value': 5.2812}, {'tag': 'train/dfl_loss', 'value': 1.2608}, {'tag': 'metrics/precision(B)', 'value': 0.00333}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.26931}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.25096}, {'tag': 'val/box_loss', 'value': 0.51613}, {'tag': 'val/cls_loss', 'value': 3.4685}, {'tag': 'val/dfl_loss', 'value': 0.81329}, {'tag': 'lr/pg0', 'value': 0.00031673}, {'tag': 'lr/pg1', 'value': 0.00031673}, {'tag': 'lr/pg2', 'value': 0.00031673}], [{'tag': 'epoch', 'value': 2.0}, {'tag': 'train/box_loss', 'value': 1.4599}, {'tag': 'train/cls_loss', 'value': 3.9494}, {'tag': 'train/dfl_loss', 'value': 1.1722}, {'tag': 'metrics/precision(B)', 'value': 0.00333}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.65933}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.38712}, {'tag': 'val/box_loss', 'value': 0.69611}, {'tag': 'val/cls_loss', 'value': 3.413}, {'tag': 'val/dfl_loss', 'value': 0.84745}, {'tag': 'lr/pg0', 'value': 0.00063726}, {'tag': 'lr/pg1', 'value': 0.00063726}, {'tag': 'lr/pg2', 'value': 0.00063726}], [{'tag': 'epoch', 'value': 3.0}, {'tag': 'train/box_loss', 'value': 1.2146}, {'tag': 'train/cls_loss', 'value': 3.4686}, {'tag': 'train/dfl_loss', 'value': 1.1051}, {'tag': 'metrics/precision(B)', 'value': 0.00336}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.7093}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.39844}, {'tag': 'val/box_loss', 'value': 0.58417}, {'tag': 'val/cls_loss', 'value': 3.6027}, {'tag': 'val/dfl_loss', 'value': 0.84142}, {'tag': 'lr/pg0', 'value': 0.00094458}, {'tag': 'lr/pg1', 'value': 0.00094458}, {'tag': 'lr/pg2', 'value': 0.00094458}], [{'tag': 'epoch', 'value': 4.0}, {'tag': 'train/box_loss', 'value': 1.2317}, {'tag': 'train/cls_loss', 'value': 2.838}, {'tag': 'train/dfl_loss', 'value': 1.0842}, {'tag': 'metrics/precision(B)', 'value': 0.54853}, {'tag': 'metrics/recall(B)', 'value': 0.52842}, {'tag': 'metrics/mAP50(B)', 'value': 0.66128}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.37006}, {'tag': 'val/box_loss', 'value': 1.1094}, {'tag': 'val/cls_loss', 'value': 3.5395}, {'tag': 'val/dfl_loss', 'value': 1.0867}, {'tag': 'lr/pg0', 'value': 0.0012387}, {'tag': 'lr/pg1', 'value': 0.0012387}, {'tag': 'lr/pg2', 'value': 0.0012387}], [{'tag': 'epoch', 'value': 5.0}, {'tag': 'train/box_loss', 'value': 1.297}, {'tag': 'train/cls_loss', 'value': 2.9219}, {'tag': 'train/dfl_loss', 'value': 1.1375}, {'tag': 'metrics/precision(B)', 'value': 0.36344}, {'tag': 'metrics/recall(B)', 'value': 0.51758}, {'tag': 'metrics/mAP50(B)', 'value': 0.42958}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.17546}, {'tag': 'val/box_loss', 'value': 1.8593}, {'tag': 'val/cls_loss', 'value': 4.9146}, {'tag': 'val/dfl_loss', 'value': 2.2106}, {'tag': 'lr/pg0', 'value': 0.0015196}, {'tag': 'lr/pg1', 'value': 0.0015196}, {'tag': 'lr/pg2', 'value': 0.0015196}], [{'tag': 'epoch', 'value': 6.0}, {'tag': 'train/box_loss', 'value': 1.6153}, {'tag': 'train/cls_loss', 'value': 3.6754}, {'tag': 'train/dfl_loss', 'value': 1.3431}, {'tag': 'metrics/precision(B)', 'value': 0.05112}, {'tag': 'metrics/recall(B)', 'value': 0.2}, {'tag': 'metrics/mAP50(B)', 'value': 0.04019}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.00585}, {'tag': 'val/box_loss', 'value': 3.0766}, {'tag': 'val/cls_loss', 'value': 4.9085}, {'tag': 'val/dfl_loss', 'value': 4.9204}, {'tag': 'lr/pg0', 'value': 0.001502}, {'tag': 'lr/pg1', 'value': 0.001502}, {'tag': 'lr/pg2', 'value': 0.001502}], [{'tag': 'epoch', 'value': 7.0}, {'tag': 'train/box_loss', 'value': 1.2743}, {'tag': 'train/cls_loss', 'value': 3.439}, {'tag': 'train/dfl_loss', 'value': 1.1176}, {'tag': 'metrics/precision(B)', 'value': 0.50438}, {'tag': 'metrics/recall(B)', 'value': 0.125}, {'tag': 'metrics/mAP50(B)', 'value': 0.01162}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.00534}, {'tag': 'val/box_loss', 'value': 1.4504}, {'tag': 'val/cls_loss', 'value': 4.5337}, {'tag': 'val/dfl_loss', 'value': 1.3232}, {'tag': 'lr/pg0', 'value': 0.001502}, {'tag': 'lr/pg1', 'value': 0.001502}, {'tag': 'lr/pg2', 'value': 0.001502}], [{'tag': 'epoch', 'value': 8.0}, {'tag': 'train/box_loss', 'value': 1.3441}, {'tag': 'train/cls_loss', 'value': 3.1871}, {'tag': 'train/dfl_loss', 'value': 1.172}, {'tag': 'metrics/precision(B)', 'value': 0.51999}, {'tag': 'metrics/recall(B)', 'value': 0.44235}, {'tag': 'metrics/mAP50(B)', 'value': 0.42304}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.23404}, {'tag': 'val/box_loss', 'value': 1.4004}, {'tag': 'val/cls_loss', 'value': 4.9148}, {'tag': 'val/dfl_loss', 'value': 1.4029}, {'tag': 'lr/pg0', 'value': 0.001469}, {'tag': 'lr/pg1', 'value': 0.001469}, {'tag': 'lr/pg2', 'value': 0.001469}], [{'tag': 'epoch', 'value': 9.0}, {'tag': 'train/box_loss', 'value': 1.1144}, {'tag': 'train/cls_loss', 'value': 2.6761}, {'tag': 'train/dfl_loss', 'value': 1.0244}, {'tag': 'metrics/precision(B)', 'value': 0.50955}, {'tag': 'metrics/recall(B)', 'value': 0.99396}, {'tag': 'metrics/mAP50(B)', 'value': 0.54416}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.41421}, {'tag': 'val/box_loss', 'value': 1.1669}, {'tag': 'val/cls_loss', 'value': 8.431}, {'tag': 'val/dfl_loss', 'value': 1.2428}, {'tag': 'lr/pg0', 'value': 0.001436}, {'tag': 'lr/pg1', 'value': 0.001436}, {'tag': 'lr/pg2', 'value': 0.001436}], [{'tag': 'epoch', 'value': 10.0}, {'tag': 'train/box_loss', 'value': 1.1793}, {'tag': 'train/cls_loss', 'value': 2.8477}, {'tag': 'train/dfl_loss', 'value': 1.0346}, {'tag': 'metrics/precision(B)', 'value': 0.70318}, {'tag': 'metrics/recall(B)', 'value': 0.68772}, {'tag': 'metrics/mAP50(B)', 'value': 0.79738}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.5373}, {'tag': 'val/box_loss', 'value': 1.1955}, {'tag': 'val/cls_loss', 'value': 2.6794}, {'tag': 'val/dfl_loss', 'value': 1.2981}, {'tag': 'lr/pg0', 'value': 0.0014029}, {'tag': 'lr/pg1', 'value': 0.0014029}, {'tag': 'lr/pg2', 'value': 0.0014029}], [{'tag': 'epoch', 'value': 11.0}, {'tag': 'train/box_loss', 'value': 1.3206}, {'tag': 'train/cls_loss', 'value': 2.8687}, {'tag': 'train/dfl_loss', 'value': 1.13}, {'tag': 'metrics/precision(B)', 'value': 0.68304}, {'tag': 'metrics/recall(B)', 'value': 0.98161}, {'tag': 'metrics/mAP50(B)', 'value': 0.96167}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.7501}, {'tag': 'val/box_loss', 'value': 0.73004}, {'tag': 'val/cls_loss', 'value': 2.117}, {'tag': 'val/dfl_loss', 'value': 1.0188}, {'tag': 'lr/pg0', 'value': 0.0013699}, {'tag': 'lr/pg1', 'value': 0.0013699}, {'tag': 'lr/pg2', 'value': 0.0013699}], [{'tag': 'epoch', 'value': 12.0}, {'tag': 'train/box_loss', 'value': 1.0732}, {'tag': 'train/cls_loss', 'value': 2.2815}, {'tag': 'train/dfl_loss', 'value': 1.011}, {'tag': 'metrics/precision(B)', 'value': 0.96143}, {'tag': 'metrics/recall(B)', 'value': 0.88542}, {'tag': 'metrics/mAP50(B)', 'value': 0.97833}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.75087}, {'tag': 'val/box_loss', 'value': 0.9156}, {'tag': 'val/cls_loss', 'value': 2.0097}, {'tag': 'val/dfl_loss', 'value': 1.0319}, {'tag': 'lr/pg0', 'value': 0.0013369}, {'tag': 'lr/pg1', 'value': 0.0013369}, {'tag': 'lr/pg2', 'value': 0.0013369}], [{'tag': 'epoch', 'value': 13.0}, {'tag': 'train/box_loss', 'value': 1.1329}, {'tag': 'train/cls_loss', 'value': 2.1429}, {'tag': 'train/dfl_loss', 'value': 1.0872}, {'tag': 'metrics/precision(B)', 'value': 0.91781}, {'tag': 'metrics/recall(B)', 'value': 0.92588}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.82054}, {'tag': 'val/box_loss', 'value': 0.83821}, {'tag': 'val/cls_loss', 'value': 2.169}, {'tag': 'val/dfl_loss', 'value': 1.0358}, {'tag': 'lr/pg0', 'value': 0.0013039}, {'tag': 'lr/pg1', 'value': 0.0013039}, {'tag': 'lr/pg2', 'value': 0.0013039}], [{'tag': 'epoch', 'value': 14.0}, {'tag': 'train/box_loss', 'value': 1.035}, {'tag': 'train/cls_loss', 'value': 2.3938}, {'tag': 'train/dfl_loss', 'value': 1.0382}, {'tag': 'metrics/precision(B)', 'value': 0.91485}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.80837}, {'tag': 'val/box_loss', 'value': 0.92436}, {'tag': 'val/cls_loss', 'value': 1.8534}, {'tag': 'val/dfl_loss', 'value': 1.068}, {'tag': 'lr/pg0', 'value': 0.0012709}, {'tag': 'lr/pg1', 'value': 0.0012709}, {'tag': 'lr/pg2', 'value': 0.0012709}], [{'tag': 'epoch', 'value': 15.0}, {'tag': 'train/box_loss', 'value': 1.278}, {'tag': 'train/cls_loss', 'value': 2.5248}, {'tag': 'train/dfl_loss', 'value': 1.0984}, {'tag': 'metrics/precision(B)', 'value': 0.91396}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.79893}, {'tag': 'val/box_loss', 'value': 0.99959}, {'tag': 'val/cls_loss', 'value': 1.8918}, {'tag': 'val/dfl_loss', 'value': 1.1467}, {'tag': 'lr/pg0', 'value': 0.0012379}, {'tag': 'lr/pg1', 'value': 0.0012379}, {'tag': 'lr/pg2', 'value': 0.0012379}], [{'tag': 'epoch', 'value': 16.0}, {'tag': 'train/box_loss', 'value': 1.12}, {'tag': 'train/cls_loss', 'value': 2.0196}, {'tag': 'train/dfl_loss', 'value': 1.0302}, {'tag': 'metrics/precision(B)', 'value': 0.98511}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.78963}, {'tag': 'val/box_loss', 'value': 1.0088}, {'tag': 'val/cls_loss', 'value': 1.7157}, {'tag': 'val/dfl_loss', 'value': 1.1321}, {'tag': 'lr/pg0', 'value': 0.0012049}, {'tag': 'lr/pg1', 'value': 0.0012049}, {'tag': 'lr/pg2', 'value': 0.0012049}], [{'tag': 'epoch', 'value': 17.0}, {'tag': 'train/box_loss', 'value': 1.03}, {'tag': 'train/cls_loss', 'value': 1.8361}, {'tag': 'train/dfl_loss', 'value': 0.99846}, {'tag': 'metrics/precision(B)', 'value': 0.98497}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.76119}, {'tag': 'val/box_loss', 'value': 0.87313}, {'tag': 'val/cls_loss', 'value': 1.755}, {'tag': 'val/dfl_loss', 'value': 1.0414}, {'tag': 'lr/pg0', 'value': 0.0011719}, {'tag': 'lr/pg1', 'value': 0.0011719}, {'tag': 'lr/pg2', 'value': 0.0011719}], [{'tag': 'epoch', 'value': 18.0}, {'tag': 'train/box_loss', 'value': 1.0686}, {'tag': 'train/cls_loss', 'value': 2.1277}, {'tag': 'train/dfl_loss', 'value': 1.005}, {'tag': 'metrics/precision(B)', 'value': 0.98289}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.81328}, {'tag': 'val/box_loss', 'value': 0.77755}, {'tag': 'val/cls_loss', 'value': 1.683}, {'tag': 'val/dfl_loss', 'value': 0.94955}, {'tag': 'lr/pg0', 'value': 0.0011389}, {'tag': 'lr/pg1', 'value': 0.0011389}, {'tag': 'lr/pg2', 'value': 0.0011389}], [{'tag': 'epoch', 'value': 19.0}, {'tag': 'train/box_loss', 'value': 0.95701}, {'tag': 'train/cls_loss', 'value': 1.7063}, {'tag': 'train/dfl_loss', 'value': 0.98483}, {'tag': 'metrics/precision(B)', 'value': 0.96426}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.80143}, {'tag': 'val/box_loss', 'value': 0.63516}, {'tag': 'val/cls_loss', 'value': 1.5477}, {'tag': 'val/dfl_loss', 'value': 0.9032}, {'tag': 'lr/pg0', 'value': 0.0011059}, {'tag': 'lr/pg1', 'value': 0.0011059}, {'tag': 'lr/pg2', 'value': 0.0011059}], [{'tag': 'epoch', 'value': 20.0}, {'tag': 'train/box_loss', 'value': 1.0154}, {'tag': 'train/cls_loss', 'value': 1.7834}, {'tag': 'train/dfl_loss', 'value': 1.0516}, {'tag': 'metrics/precision(B)', 'value': 0.95888}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.82447}, {'tag': 'val/box_loss', 'value': 0.5856}, {'tag': 'val/cls_loss', 'value': 1.5122}, {'tag': 'val/dfl_loss', 'value': 0.88545}, {'tag': 'lr/pg0', 'value': 0.0010729}, {'tag': 'lr/pg1', 'value': 0.0010729}, {'tag': 'lr/pg2', 'value': 0.0010729}], [{'tag': 'epoch', 'value': 21.0}, {'tag': 'train/box_loss', 'value': 0.92979}, {'tag': 'train/cls_loss', 'value': 2.9758}, {'tag': 'train/dfl_loss', 'value': 1.0026}, {'tag': 'metrics/precision(B)', 'value': 0.95478}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.83234}, {'tag': 'val/box_loss', 'value': 0.60787}, {'tag': 'val/cls_loss', 'value': 1.4665}, {'tag': 'val/dfl_loss', 'value': 0.89279}, {'tag': 'lr/pg0', 'value': 0.0010399}, {'tag': 'lr/pg1', 'value': 0.0010399}, {'tag': 'lr/pg2', 'value': 0.0010399}], [{'tag': 'epoch', 'value': 22.0}, {'tag': 'train/box_loss', 'value': 1.0061}, {'tag': 'train/cls_loss', 'value': 2.0711}, {'tag': 'train/dfl_loss', 'value': 1.02}, {'tag': 'metrics/precision(B)', 'value': 0.94932}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.83564}, {'tag': 'val/box_loss', 'value': 0.65912}, {'tag': 'val/cls_loss', 'value': 1.4789}, {'tag': 'val/dfl_loss', 'value': 0.90882}, {'tag': 'lr/pg0', 'value': 0.0010069}, {'tag': 'lr/pg1', 'value': 0.0010069}, {'tag': 'lr/pg2', 'value': 0.0010069}], [{'tag': 'epoch', 'value': 23.0}, {'tag': 'train/box_loss', 'value': 0.98472}, {'tag': 'train/cls_loss', 'value': 1.6678}, {'tag': 'train/dfl_loss', 'value': 1.0112}, {'tag': 'metrics/precision(B)', 'value': 0.97403}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.80763}, {'tag': 'val/box_loss', 'value': 0.58132}, {'tag': 'val/cls_loss', 'value': 1.4026}, {'tag': 'val/dfl_loss', 'value': 0.87839}, {'tag': 'lr/pg0', 'value': 0.00097386}, {'tag': 'lr/pg1', 'value': 0.00097386}, {'tag': 'lr/pg2', 'value': 0.00097386}], [{'tag': 'epoch', 'value': 24.0}, {'tag': 'train/box_loss', 'value': 0.89431}, {'tag': 'train/cls_loss', 'value': 1.8867}, {'tag': 'train/dfl_loss', 'value': 0.97741}, {'tag': 'metrics/precision(B)', 'value': 0.97196}, {'tag': 'metrics/recall(B)', 'value': 0.99866}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.84066}, {'tag': 'val/box_loss', 'value': 0.56923}, {'tag': 'val/cls_loss', 'value': 1.2981}, {'tag': 'val/dfl_loss', 'value': 0.87291}, {'tag': 'lr/pg0', 'value': 0.00094085}, {'tag': 'lr/pg1', 'value': 0.00094085}, {'tag': 'lr/pg2', 'value': 0.00094085}], [{'tag': 'epoch', 'value': 25.0}, {'tag': 'train/box_loss', 'value': 0.88719}, {'tag': 'train/cls_loss', 'value': 1.6143}, {'tag': 'train/dfl_loss', 'value': 0.99381}, {'tag': 'metrics/precision(B)', 'value': 0.96733}, {'tag': 'metrics/recall(B)', 'value': 0.9997}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.84075}, {'tag': 'val/box_loss', 'value': 0.48798}, {'tag': 'val/cls_loss', 'value': 1.2675}, {'tag': 'val/dfl_loss', 'value': 0.85425}, {'tag': 'lr/pg0', 'value': 0.00090785}, {'tag': 'lr/pg1', 'value': 0.00090785}, {'tag': 'lr/pg2', 'value': 0.00090785}], [{'tag': 'epoch', 'value': 26.0}, {'tag': 'train/box_loss', 'value': 0.84876}, {'tag': 'train/cls_loss', 'value': 1.6264}, {'tag': 'train/dfl_loss', 'value': 0.92925}, {'tag': 'metrics/precision(B)', 'value': 0.98731}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.84798}, {'tag': 'val/box_loss', 'value': 0.55751}, {'tag': 'val/cls_loss', 'value': 1.1992}, {'tag': 'val/dfl_loss', 'value': 0.86784}, {'tag': 'lr/pg0', 'value': 0.00087484}, {'tag': 'lr/pg1', 'value': 0.00087484}, {'tag': 'lr/pg2', 'value': 0.00087484}], [{'tag': 'epoch', 'value': 27.0}, {'tag': 'train/box_loss', 'value': 0.93747}, {'tag': 'train/cls_loss', 'value': 1.6506}, {'tag': 'train/dfl_loss', 'value': 0.98225}, {'tag': 'metrics/precision(B)', 'value': 0.97825}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.91569}, {'tag': 'val/box_loss', 'value': 0.5384}, {'tag': 'val/cls_loss', 'value': 1.1146}, {'tag': 'val/dfl_loss', 'value': 0.85695}, {'tag': 'lr/pg0', 'value': 0.00084184}, {'tag': 'lr/pg1', 'value': 0.00084184}, {'tag': 'lr/pg2', 'value': 0.00084184}], [{'tag': 'epoch', 'value': 28.0}, {'tag': 'train/box_loss', 'value': 0.88906}, {'tag': 'train/cls_loss', 'value': 1.548}, {'tag': 'train/dfl_loss', 'value': 1.0091}, {'tag': 'metrics/precision(B)', 'value': 0.981}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.96028}, {'tag': 'val/box_loss', 'value': 0.51107}, {'tag': 'val/cls_loss', 'value': 1.0871}, {'tag': 'val/dfl_loss', 'value': 0.85397}, {'tag': 'lr/pg0', 'value': 0.00080883}, {'tag': 'lr/pg1', 'value': 0.00080883}, {'tag': 'lr/pg2', 'value': 0.00080883}], [{'tag': 'epoch', 'value': 29.0}, {'tag': 'train/box_loss', 'value': 0.81072}, {'tag': 'train/cls_loss', 'value': 1.5923}, {'tag': 'train/dfl_loss', 'value': 0.93118}, {'tag': 'metrics/precision(B)', 'value': 0.98749}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.90461}, {'tag': 'val/box_loss', 'value': 0.47067}, {'tag': 'val/cls_loss', 'value': 1.0576}, {'tag': 'val/dfl_loss', 'value': 0.84179}, {'tag': 'lr/pg0', 'value': 0.00077582}, {'tag': 'lr/pg1', 'value': 0.00077582}, {'tag': 'lr/pg2', 'value': 0.00077582}], [{'tag': 'epoch', 'value': 30.0}, {'tag': 'train/box_loss', 'value': 0.8249}, {'tag': 'train/cls_loss', 'value': 1.3682}, {'tag': 'train/dfl_loss', 'value': 0.94273}, {'tag': 'metrics/precision(B)', 'value': 0.98969}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.9036}, {'tag': 'val/box_loss', 'value': 0.39666}, {'tag': 'val/cls_loss', 'value': 1.053}, {'tag': 'val/dfl_loss', 'value': 0.82851}, {'tag': 'lr/pg0', 'value': 0.00074282}, {'tag': 'lr/pg1', 'value': 0.00074282}, {'tag': 'lr/pg2', 'value': 0.00074282}], [{'tag': 'epoch', 'value': 31.0}, {'tag': 'train/box_loss', 'value': 0.73144}, {'tag': 'train/cls_loss', 'value': 1.3732}, {'tag': 'train/dfl_loss', 'value': 0.90753}, {'tag': 'metrics/precision(B)', 'value': 0.98757}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.88781}, {'tag': 'val/box_loss', 'value': 0.375}, {'tag': 'val/cls_loss', 'value': 0.99855}, {'tag': 'val/dfl_loss', 'value': 0.83017}, {'tag': 'lr/pg0', 'value': 0.00070981}, {'tag': 'lr/pg1', 'value': 0.00070981}, {'tag': 'lr/pg2', 'value': 0.00070981}], [{'tag': 'epoch', 'value': 32.0}, {'tag': 'train/box_loss', 'value': 0.75478}, {'tag': 'train/cls_loss', 'value': 1.3006}, {'tag': 'train/dfl_loss', 'value': 0.92523}, {'tag': 'metrics/precision(B)', 'value': 0.98351}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.91202}, {'tag': 'val/box_loss', 'value': 0.43955}, {'tag': 'val/cls_loss', 'value': 1.0266}, {'tag': 'val/dfl_loss', 'value': 0.84016}, {'tag': 'lr/pg0', 'value': 0.0006768}, {'tag': 'lr/pg1', 'value': 0.0006768}, {'tag': 'lr/pg2', 'value': 0.0006768}], [{'tag': 'epoch', 'value': 33.0}, {'tag': 'train/box_loss', 'value': 0.75876}, {'tag': 'train/cls_loss', 'value': 1.5963}, {'tag': 'train/dfl_loss', 'value': 0.91352}, {'tag': 'metrics/precision(B)', 'value': 0.97136}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.88963}, {'tag': 'val/box_loss', 'value': 0.49852}, {'tag': 'val/cls_loss', 'value': 1.1063}, {'tag': 'val/dfl_loss', 'value': 0.85433}, {'tag': 'lr/pg0', 'value': 0.0006438}, {'tag': 'lr/pg1', 'value': 0.0006438}, {'tag': 'lr/pg2', 'value': 0.0006438}], [{'tag': 'epoch', 'value': 34.0}, {'tag': 'train/box_loss', 'value': 0.78078}, {'tag': 'train/cls_loss', 'value': 1.4324}, {'tag': 'train/dfl_loss', 'value': 0.92701}, {'tag': 'metrics/precision(B)', 'value': 0.9645}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.83881}, {'tag': 'val/box_loss', 'value': 0.60238}, {'tag': 'val/cls_loss', 'value': 1.1641}, {'tag': 'val/dfl_loss', 'value': 0.87747}, {'tag': 'lr/pg0', 'value': 0.00061079}, {'tag': 'lr/pg1', 'value': 0.00061079}, {'tag': 'lr/pg2', 'value': 0.00061079}], [{'tag': 'epoch', 'value': 35.0}, {'tag': 'train/box_loss', 'value': 0.8292}, {'tag': 'train/cls_loss', 'value': 1.5066}, {'tag': 'train/dfl_loss', 'value': 0.96952}, {'tag': 'metrics/precision(B)', 'value': 0.97829}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.84816}, {'tag': 'val/box_loss', 'value': 0.56216}, {'tag': 'val/cls_loss', 'value': 1.1453}, {'tag': 'val/dfl_loss', 'value': 0.86508}, {'tag': 'lr/pg0', 'value': 0.00057778}, {'tag': 'lr/pg1', 'value': 0.00057778}, {'tag': 'lr/pg2', 'value': 0.00057778}], [{'tag': 'epoch', 'value': 36.0}, {'tag': 'train/box_loss', 'value': 0.74242}, {'tag': 'train/cls_loss', 'value': 1.3477}, {'tag': 'train/dfl_loss', 'value': 0.94292}, {'tag': 'metrics/precision(B)', 'value': 0.98707}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.86303}, {'tag': 'val/box_loss', 'value': 0.48702}, {'tag': 'val/cls_loss', 'value': 1.1534}, {'tag': 'val/dfl_loss', 'value': 0.85386}, {'tag': 'lr/pg0', 'value': 0.00054478}, {'tag': 'lr/pg1', 'value': 0.00054478}, {'tag': 'lr/pg2', 'value': 0.00054478}], [{'tag': 'epoch', 'value': 37.0}, {'tag': 'train/box_loss', 'value': 0.8563}, {'tag': 'train/cls_loss', 'value': 1.2671}, {'tag': 'train/dfl_loss', 'value': 0.96367}, {'tag': 'metrics/precision(B)', 'value': 0.9853}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.88155}, {'tag': 'val/box_loss', 'value': 0.46772}, {'tag': 'val/cls_loss', 'value': 1.109}, {'tag': 'val/dfl_loss', 'value': 0.85329}, {'tag': 'lr/pg0', 'value': 0.00051177}, {'tag': 'lr/pg1', 'value': 0.00051177}, {'tag': 'lr/pg2', 'value': 0.00051177}], [{'tag': 'epoch', 'value': 38.0}, {'tag': 'train/box_loss', 'value': 0.75051}, {'tag': 'train/cls_loss', 'value': 1.2677}, {'tag': 'train/dfl_loss', 'value': 0.89221}, {'tag': 'metrics/precision(B)', 'value': 0.98462}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.89094}, {'tag': 'val/box_loss', 'value': 0.45846}, {'tag': 'val/cls_loss', 'value': 1.0294}, {'tag': 'val/dfl_loss', 'value': 0.85682}, {'tag': 'lr/pg0', 'value': 0.00047876}, {'tag': 'lr/pg1', 'value': 0.00047876}, {'tag': 'lr/pg2', 'value': 0.00047876}], [{'tag': 'epoch', 'value': 39.0}, {'tag': 'train/box_loss', 'value': 0.68843}, {'tag': 'train/cls_loss', 'value': 1.2692}, {'tag': 'train/dfl_loss', 'value': 0.9136}, {'tag': 'metrics/precision(B)', 'value': 0.97703}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.87248}, {'tag': 'val/box_loss', 'value': 0.44022}, {'tag': 'val/cls_loss', 'value': 1.07}, {'tag': 'val/dfl_loss', 'value': 0.85327}, {'tag': 'lr/pg0', 'value': 0.00044576}, {'tag': 'lr/pg1', 'value': 0.00044576}, {'tag': 'lr/pg2', 'value': 0.00044576}], [{'tag': 'epoch', 'value': 40.0}, {'tag': 'train/box_loss', 'value': 0.76343}, {'tag': 'train/cls_loss', 'value': 1.2374}, {'tag': 'train/dfl_loss', 'value': 0.91103}, {'tag': 'metrics/precision(B)', 'value': 0.96992}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.88185}, {'tag': 'val/box_loss', 'value': 0.40082}, {'tag': 'val/cls_loss', 'value': 1.0924}, {'tag': 'val/dfl_loss', 'value': 0.84257}, {'tag': 'lr/pg0', 'value': 0.00041275}, {'tag': 'lr/pg1', 'value': 0.00041275}, {'tag': 'lr/pg2', 'value': 0.00041275}], [{'tag': 'epoch', 'value': 41.0}, {'tag': 'train/box_loss', 'value': 0.65702}, {'tag': 'train/cls_loss', 'value': 1.3044}, {'tag': 'train/dfl_loss', 'value': 0.92026}, {'tag': 'metrics/precision(B)', 'value': 0.96291}, {'tag': 'metrics/recall(B)', 'value': 0.99873}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.90155}, {'tag': 'val/box_loss', 'value': 0.40349}, {'tag': 'val/cls_loss', 'value': 0.99385}, {'tag': 'val/dfl_loss', 'value': 0.84281}, {'tag': 'lr/pg0', 'value': 0.00037974}, {'tag': 'lr/pg1', 'value': 0.00037974}, {'tag': 'lr/pg2', 'value': 0.00037974}], [{'tag': 'epoch', 'value': 42.0}, {'tag': 'train/box_loss', 'value': 0.63936}, {'tag': 'train/cls_loss', 'value': 1.2483}, {'tag': 'train/dfl_loss', 'value': 0.9003}, {'tag': 'metrics/precision(B)', 'value': 0.9642}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.89963}, {'tag': 'val/box_loss', 'value': 0.41567}, {'tag': 'val/cls_loss', 'value': 0.95405}, {'tag': 'val/dfl_loss', 'value': 0.83693}, {'tag': 'lr/pg0', 'value': 0.00034674}, {'tag': 'lr/pg1', 'value': 0.00034674}, {'tag': 'lr/pg2', 'value': 0.00034674}], [{'tag': 'epoch', 'value': 43.0}, {'tag': 'train/box_loss', 'value': 0.64237}, {'tag': 'train/cls_loss', 'value': 1.2701}, {'tag': 'train/dfl_loss', 'value': 0.87913}, {'tag': 'metrics/precision(B)', 'value': 0.97005}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.89963}, {'tag': 'val/box_loss', 'value': 0.4301}, {'tag': 'val/cls_loss', 'value': 0.96179}, {'tag': 'val/dfl_loss', 'value': 0.83769}, {'tag': 'lr/pg0', 'value': 0.00031373}, {'tag': 'lr/pg1', 'value': 0.00031373}, {'tag': 'lr/pg2', 'value': 0.00031373}], [{'tag': 'epoch', 'value': 44.0}, {'tag': 'train/box_loss', 'value': 0.57941}, {'tag': 'train/cls_loss', 'value': 1.1566}, {'tag': 'train/dfl_loss', 'value': 0.89615}, {'tag': 'metrics/precision(B)', 'value': 0.97691}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.9414}, {'tag': 'val/box_loss', 'value': 0.45878}, {'tag': 'val/cls_loss', 'value': 0.95365}, {'tag': 'val/dfl_loss', 'value': 0.84326}, {'tag': 'lr/pg0', 'value': 0.00028072}, {'tag': 'lr/pg1', 'value': 0.00028072}, {'tag': 'lr/pg2', 'value': 0.00028072}], [{'tag': 'epoch', 'value': 45.0}, {'tag': 'train/box_loss', 'value': 0.62247}, {'tag': 'train/cls_loss', 'value': 1.2098}, {'tag': 'train/dfl_loss', 'value': 0.88644}, {'tag': 'metrics/precision(B)', 'value': 0.9817}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.90222}, {'tag': 'val/box_loss', 'value': 0.43521}, {'tag': 'val/cls_loss', 'value': 0.96194}, {'tag': 'val/dfl_loss', 'value': 0.83812}, {'tag': 'lr/pg0', 'value': 0.00024772}, {'tag': 'lr/pg1', 'value': 0.00024772}, {'tag': 'lr/pg2', 'value': 0.00024772}], [{'tag': 'epoch', 'value': 46.0}, {'tag': 'train/box_loss', 'value': 0.60818}, {'tag': 'train/cls_loss', 'value': 1.2013}, {'tag': 'train/dfl_loss', 'value': 0.8573}, {'tag': 'metrics/precision(B)', 'value': 0.9889}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.89776}, {'tag': 'val/box_loss', 'value': 0.38069}, {'tag': 'val/cls_loss', 'value': 0.95059}, {'tag': 'val/dfl_loss', 'value': 0.83151}, {'tag': 'lr/pg0', 'value': 0.00021471}, {'tag': 'lr/pg1', 'value': 0.00021471}, {'tag': 'lr/pg2', 'value': 0.00021471}], [{'tag': 'epoch', 'value': 47.0}, {'tag': 'train/box_loss', 'value': 0.55504}, {'tag': 'train/cls_loss', 'value': 1.1902}, {'tag': 'train/dfl_loss', 'value': 0.87212}, {'tag': 'metrics/precision(B)', 'value': 0.9898}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.92709}, {'tag': 'val/box_loss', 'value': 0.35229}, {'tag': 'val/cls_loss', 'value': 0.92473}, {'tag': 'val/dfl_loss', 'value': 0.82766}, {'tag': 'lr/pg0', 'value': 0.0001817}, {'tag': 'lr/pg1', 'value': 0.0001817}, {'tag': 'lr/pg2', 'value': 0.0001817}], [{'tag': 'epoch', 'value': 48.0}, {'tag': 'train/box_loss', 'value': 0.54536}, {'tag': 'train/cls_loss', 'value': 1.1609}, {'tag': 'train/dfl_loss', 'value': 0.83567}, {'tag': 'metrics/precision(B)', 'value': 0.99}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.93022}, {'tag': 'val/box_loss', 'value': 0.36754}, {'tag': 'val/cls_loss', 'value': 0.91815}, {'tag': 'val/dfl_loss', 'value': 0.8254}, {'tag': 'lr/pg0', 'value': 0.0001487}, {'tag': 'lr/pg1', 'value': 0.0001487}, {'tag': 'lr/pg2', 'value': 0.0001487}], [{'tag': 'epoch', 'value': 49.0}, {'tag': 'train/box_loss', 'value': 0.53891}, {'tag': 'train/cls_loss', 'value': 1.1296}, {'tag': 'train/dfl_loss', 'value': 0.84148}, {'tag': 'metrics/precision(B)', 'value': 0.98987}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.91172}, {'tag': 'val/box_loss', 'value': 0.37659}, {'tag': 'val/cls_loss', 'value': 0.9197}, {'tag': 'val/dfl_loss', 'value': 0.82518}, {'tag': 'lr/pg0', 'value': 0.00011569}, {'tag': 'lr/pg1', 'value': 0.00011569}, {'tag': 'lr/pg2', 'value': 0.00011569}], [{'tag': 'epoch', 'value': 50.0}, {'tag': 'train/box_loss', 'value': 0.54389}, {'tag': 'train/cls_loss', 'value': 1.111}, {'tag': 'train/dfl_loss', 'value': 0.8559}, {'tag': 'metrics/precision(B)', 'value': 0.98916}, {'tag': 'metrics/recall(B)', 'value': 1.0}, {'tag': 'metrics/mAP50(B)', 'value': 0.995}, {'tag': 'metrics/mAP50-95(B)', 'value': 0.92422}, {'tag': 'val/box_loss', 'value': 0.37283}, {'tag': 'val/cls_loss', 'value': 0.92134}, {'tag': 'val/dfl_loss', 'value': 0.82441}, {'tag': 'lr/pg0', 'value': 8.2683e-05}, {'tag': 'lr/pg1', 'value': 8.2683e-05}, {'tag': 'lr/pg2', 'value': 8.2683e-05}]], eval_metrics=[{'tag': 'mAP', 'value': 0.835066020488739}, {'tag': 'mAP_50', 'value': 1.0}, {'tag': 'mAP_75', 'value': 1.0}, {'tag': 'mAP_small', 'value': 0.7205445766448975}, {'tag': 'mAP_medium', 'value': 0.871039628982544}, {'tag': 'mAP_large', 'value': -1.0}, {'tag': 'mAR_1', 'value': 0.8500000238418579}, {'tag': 'mAR_10', 'value': 0.8500000238418579}, {'tag': 'mAR_100', 'value': 0.8500000238418579}, {'tag': 'mAR_small', 'value': 0.7250000238418579}, {'tag': 'mAR_medium', 'value': 0.871039628982544}, {'tag': 'mAR_large', 'value': -1.0}, {'tag': 'mAP_per_class', 'value': [{'class_name': '1', 'value': 0.7533003091812134}, {'class_name': '2', 'value': 0.9168316721916199}]}, {'tag': 'mAR_100_per_class', 'value': [{'class_name': '1', 'value': 0.7666666507720947}, {'class_name': '2', 'value': 0.9333333373069763}]}])</pre> In\u00a0[22]: Copied! <pre>ultralytics_hub.get_train_config()\n</pre> ultralytics_hub.get_train_config() Out[22]: <pre>TrainConfig(dataset_path='/home/snuailab/Desktop/waffle_hub/docs/tutorials/datasets/mnist_det/exports/ULTRALYTICS/data.yaml', epochs=50, batch_size=4, image_size=[640, 640], learning_rate=0.01, letter_box=True, pretrained_model='yolov8n.pt', device='0', workers=2, seed=0, advance_params={}, verbose=True)</pre> In\u00a0[23]: Copied! <pre>ultralytics_hub.get_train_state()\n</pre> ultralytics_hub.get_train_state() Out[23]: <pre>{'status': 'success',\n 'error_type': None,\n 'error_msg': None,\n 'step': 50,\n 'total_step': 50}</pre> In\u00a0[24]: Copied! <pre>ultralytics_hub.get_metrics()\n</pre> ultralytics_hub.get_metrics() Out[24]: <pre>[[{'tag': 'epoch', 'value': 1.0},\n  {'tag': 'train/box_loss', 'value': 1.8225},\n  {'tag': 'train/cls_loss', 'value': 5.2812},\n  {'tag': 'train/dfl_loss', 'value': 1.2608},\n  {'tag': 'metrics/precision(B)', 'value': 0.00333},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.26931},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.25096},\n  {'tag': 'val/box_loss', 'value': 0.51613},\n  {'tag': 'val/cls_loss', 'value': 3.4685},\n  {'tag': 'val/dfl_loss', 'value': 0.81329},\n  {'tag': 'lr/pg0', 'value': 0.00031673},\n  {'tag': 'lr/pg1', 'value': 0.00031673},\n  {'tag': 'lr/pg2', 'value': 0.00031673}],\n [{'tag': 'epoch', 'value': 2.0},\n  {'tag': 'train/box_loss', 'value': 1.4599},\n  {'tag': 'train/cls_loss', 'value': 3.9494},\n  {'tag': 'train/dfl_loss', 'value': 1.1722},\n  {'tag': 'metrics/precision(B)', 'value': 0.00333},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.65933},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.38712},\n  {'tag': 'val/box_loss', 'value': 0.69611},\n  {'tag': 'val/cls_loss', 'value': 3.413},\n  {'tag': 'val/dfl_loss', 'value': 0.84745},\n  {'tag': 'lr/pg0', 'value': 0.00063726},\n  {'tag': 'lr/pg1', 'value': 0.00063726},\n  {'tag': 'lr/pg2', 'value': 0.00063726}],\n [{'tag': 'epoch', 'value': 3.0},\n  {'tag': 'train/box_loss', 'value': 1.2146},\n  {'tag': 'train/cls_loss', 'value': 3.4686},\n  {'tag': 'train/dfl_loss', 'value': 1.1051},\n  {'tag': 'metrics/precision(B)', 'value': 0.00336},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.7093},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.39844},\n  {'tag': 'val/box_loss', 'value': 0.58417},\n  {'tag': 'val/cls_loss', 'value': 3.6027},\n  {'tag': 'val/dfl_loss', 'value': 0.84142},\n  {'tag': 'lr/pg0', 'value': 0.00094458},\n  {'tag': 'lr/pg1', 'value': 0.00094458},\n  {'tag': 'lr/pg2', 'value': 0.00094458}],\n [{'tag': 'epoch', 'value': 4.0},\n  {'tag': 'train/box_loss', 'value': 1.2317},\n  {'tag': 'train/cls_loss', 'value': 2.838},\n  {'tag': 'train/dfl_loss', 'value': 1.0842},\n  {'tag': 'metrics/precision(B)', 'value': 0.54853},\n  {'tag': 'metrics/recall(B)', 'value': 0.52842},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.66128},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.37006},\n  {'tag': 'val/box_loss', 'value': 1.1094},\n  {'tag': 'val/cls_loss', 'value': 3.5395},\n  {'tag': 'val/dfl_loss', 'value': 1.0867},\n  {'tag': 'lr/pg0', 'value': 0.0012387},\n  {'tag': 'lr/pg1', 'value': 0.0012387},\n  {'tag': 'lr/pg2', 'value': 0.0012387}],\n [{'tag': 'epoch', 'value': 5.0},\n  {'tag': 'train/box_loss', 'value': 1.297},\n  {'tag': 'train/cls_loss', 'value': 2.9219},\n  {'tag': 'train/dfl_loss', 'value': 1.1375},\n  {'tag': 'metrics/precision(B)', 'value': 0.36344},\n  {'tag': 'metrics/recall(B)', 'value': 0.51758},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.42958},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.17546},\n  {'tag': 'val/box_loss', 'value': 1.8593},\n  {'tag': 'val/cls_loss', 'value': 4.9146},\n  {'tag': 'val/dfl_loss', 'value': 2.2106},\n  {'tag': 'lr/pg0', 'value': 0.0015196},\n  {'tag': 'lr/pg1', 'value': 0.0015196},\n  {'tag': 'lr/pg2', 'value': 0.0015196}],\n [{'tag': 'epoch', 'value': 6.0},\n  {'tag': 'train/box_loss', 'value': 1.6153},\n  {'tag': 'train/cls_loss', 'value': 3.6754},\n  {'tag': 'train/dfl_loss', 'value': 1.3431},\n  {'tag': 'metrics/precision(B)', 'value': 0.05112},\n  {'tag': 'metrics/recall(B)', 'value': 0.2},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.04019},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.00585},\n  {'tag': 'val/box_loss', 'value': 3.0766},\n  {'tag': 'val/cls_loss', 'value': 4.9085},\n  {'tag': 'val/dfl_loss', 'value': 4.9204},\n  {'tag': 'lr/pg0', 'value': 0.001502},\n  {'tag': 'lr/pg1', 'value': 0.001502},\n  {'tag': 'lr/pg2', 'value': 0.001502}],\n [{'tag': 'epoch', 'value': 7.0},\n  {'tag': 'train/box_loss', 'value': 1.2743},\n  {'tag': 'train/cls_loss', 'value': 3.439},\n  {'tag': 'train/dfl_loss', 'value': 1.1176},\n  {'tag': 'metrics/precision(B)', 'value': 0.50438},\n  {'tag': 'metrics/recall(B)', 'value': 0.125},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.01162},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.00534},\n  {'tag': 'val/box_loss', 'value': 1.4504},\n  {'tag': 'val/cls_loss', 'value': 4.5337},\n  {'tag': 'val/dfl_loss', 'value': 1.3232},\n  {'tag': 'lr/pg0', 'value': 0.001502},\n  {'tag': 'lr/pg1', 'value': 0.001502},\n  {'tag': 'lr/pg2', 'value': 0.001502}],\n [{'tag': 'epoch', 'value': 8.0},\n  {'tag': 'train/box_loss', 'value': 1.3441},\n  {'tag': 'train/cls_loss', 'value': 3.1871},\n  {'tag': 'train/dfl_loss', 'value': 1.172},\n  {'tag': 'metrics/precision(B)', 'value': 0.51999},\n  {'tag': 'metrics/recall(B)', 'value': 0.44235},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.42304},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.23404},\n  {'tag': 'val/box_loss', 'value': 1.4004},\n  {'tag': 'val/cls_loss', 'value': 4.9148},\n  {'tag': 'val/dfl_loss', 'value': 1.4029},\n  {'tag': 'lr/pg0', 'value': 0.001469},\n  {'tag': 'lr/pg1', 'value': 0.001469},\n  {'tag': 'lr/pg2', 'value': 0.001469}],\n [{'tag': 'epoch', 'value': 9.0},\n  {'tag': 'train/box_loss', 'value': 1.1144},\n  {'tag': 'train/cls_loss', 'value': 2.6761},\n  {'tag': 'train/dfl_loss', 'value': 1.0244},\n  {'tag': 'metrics/precision(B)', 'value': 0.50955},\n  {'tag': 'metrics/recall(B)', 'value': 0.99396},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.54416},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.41421},\n  {'tag': 'val/box_loss', 'value': 1.1669},\n  {'tag': 'val/cls_loss', 'value': 8.431},\n  {'tag': 'val/dfl_loss', 'value': 1.2428},\n  {'tag': 'lr/pg0', 'value': 0.001436},\n  {'tag': 'lr/pg1', 'value': 0.001436},\n  {'tag': 'lr/pg2', 'value': 0.001436}],\n [{'tag': 'epoch', 'value': 10.0},\n  {'tag': 'train/box_loss', 'value': 1.1793},\n  {'tag': 'train/cls_loss', 'value': 2.8477},\n  {'tag': 'train/dfl_loss', 'value': 1.0346},\n  {'tag': 'metrics/precision(B)', 'value': 0.70318},\n  {'tag': 'metrics/recall(B)', 'value': 0.68772},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.79738},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.5373},\n  {'tag': 'val/box_loss', 'value': 1.1955},\n  {'tag': 'val/cls_loss', 'value': 2.6794},\n  {'tag': 'val/dfl_loss', 'value': 1.2981},\n  {'tag': 'lr/pg0', 'value': 0.0014029},\n  {'tag': 'lr/pg1', 'value': 0.0014029},\n  {'tag': 'lr/pg2', 'value': 0.0014029}],\n [{'tag': 'epoch', 'value': 11.0},\n  {'tag': 'train/box_loss', 'value': 1.3206},\n  {'tag': 'train/cls_loss', 'value': 2.8687},\n  {'tag': 'train/dfl_loss', 'value': 1.13},\n  {'tag': 'metrics/precision(B)', 'value': 0.68304},\n  {'tag': 'metrics/recall(B)', 'value': 0.98161},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.96167},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.7501},\n  {'tag': 'val/box_loss', 'value': 0.73004},\n  {'tag': 'val/cls_loss', 'value': 2.117},\n  {'tag': 'val/dfl_loss', 'value': 1.0188},\n  {'tag': 'lr/pg0', 'value': 0.0013699},\n  {'tag': 'lr/pg1', 'value': 0.0013699},\n  {'tag': 'lr/pg2', 'value': 0.0013699}],\n [{'tag': 'epoch', 'value': 12.0},\n  {'tag': 'train/box_loss', 'value': 1.0732},\n  {'tag': 'train/cls_loss', 'value': 2.2815},\n  {'tag': 'train/dfl_loss', 'value': 1.011},\n  {'tag': 'metrics/precision(B)', 'value': 0.96143},\n  {'tag': 'metrics/recall(B)', 'value': 0.88542},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.97833},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.75087},\n  {'tag': 'val/box_loss', 'value': 0.9156},\n  {'tag': 'val/cls_loss', 'value': 2.0097},\n  {'tag': 'val/dfl_loss', 'value': 1.0319},\n  {'tag': 'lr/pg0', 'value': 0.0013369},\n  {'tag': 'lr/pg1', 'value': 0.0013369},\n  {'tag': 'lr/pg2', 'value': 0.0013369}],\n [{'tag': 'epoch', 'value': 13.0},\n  {'tag': 'train/box_loss', 'value': 1.1329},\n  {'tag': 'train/cls_loss', 'value': 2.1429},\n  {'tag': 'train/dfl_loss', 'value': 1.0872},\n  {'tag': 'metrics/precision(B)', 'value': 0.91781},\n  {'tag': 'metrics/recall(B)', 'value': 0.92588},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.82054},\n  {'tag': 'val/box_loss', 'value': 0.83821},\n  {'tag': 'val/cls_loss', 'value': 2.169},\n  {'tag': 'val/dfl_loss', 'value': 1.0358},\n  {'tag': 'lr/pg0', 'value': 0.0013039},\n  {'tag': 'lr/pg1', 'value': 0.0013039},\n  {'tag': 'lr/pg2', 'value': 0.0013039}],\n [{'tag': 'epoch', 'value': 14.0},\n  {'tag': 'train/box_loss', 'value': 1.035},\n  {'tag': 'train/cls_loss', 'value': 2.3938},\n  {'tag': 'train/dfl_loss', 'value': 1.0382},\n  {'tag': 'metrics/precision(B)', 'value': 0.91485},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.80837},\n  {'tag': 'val/box_loss', 'value': 0.92436},\n  {'tag': 'val/cls_loss', 'value': 1.8534},\n  {'tag': 'val/dfl_loss', 'value': 1.068},\n  {'tag': 'lr/pg0', 'value': 0.0012709},\n  {'tag': 'lr/pg1', 'value': 0.0012709},\n  {'tag': 'lr/pg2', 'value': 0.0012709}],\n [{'tag': 'epoch', 'value': 15.0},\n  {'tag': 'train/box_loss', 'value': 1.278},\n  {'tag': 'train/cls_loss', 'value': 2.5248},\n  {'tag': 'train/dfl_loss', 'value': 1.0984},\n  {'tag': 'metrics/precision(B)', 'value': 0.91396},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.79893},\n  {'tag': 'val/box_loss', 'value': 0.99959},\n  {'tag': 'val/cls_loss', 'value': 1.8918},\n  {'tag': 'val/dfl_loss', 'value': 1.1467},\n  {'tag': 'lr/pg0', 'value': 0.0012379},\n  {'tag': 'lr/pg1', 'value': 0.0012379},\n  {'tag': 'lr/pg2', 'value': 0.0012379}],\n [{'tag': 'epoch', 'value': 16.0},\n  {'tag': 'train/box_loss', 'value': 1.12},\n  {'tag': 'train/cls_loss', 'value': 2.0196},\n  {'tag': 'train/dfl_loss', 'value': 1.0302},\n  {'tag': 'metrics/precision(B)', 'value': 0.98511},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.78963},\n  {'tag': 'val/box_loss', 'value': 1.0088},\n  {'tag': 'val/cls_loss', 'value': 1.7157},\n  {'tag': 'val/dfl_loss', 'value': 1.1321},\n  {'tag': 'lr/pg0', 'value': 0.0012049},\n  {'tag': 'lr/pg1', 'value': 0.0012049},\n  {'tag': 'lr/pg2', 'value': 0.0012049}],\n [{'tag': 'epoch', 'value': 17.0},\n  {'tag': 'train/box_loss', 'value': 1.03},\n  {'tag': 'train/cls_loss', 'value': 1.8361},\n  {'tag': 'train/dfl_loss', 'value': 0.99846},\n  {'tag': 'metrics/precision(B)', 'value': 0.98497},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.76119},\n  {'tag': 'val/box_loss', 'value': 0.87313},\n  {'tag': 'val/cls_loss', 'value': 1.755},\n  {'tag': 'val/dfl_loss', 'value': 1.0414},\n  {'tag': 'lr/pg0', 'value': 0.0011719},\n  {'tag': 'lr/pg1', 'value': 0.0011719},\n  {'tag': 'lr/pg2', 'value': 0.0011719}],\n [{'tag': 'epoch', 'value': 18.0},\n  {'tag': 'train/box_loss', 'value': 1.0686},\n  {'tag': 'train/cls_loss', 'value': 2.1277},\n  {'tag': 'train/dfl_loss', 'value': 1.005},\n  {'tag': 'metrics/precision(B)', 'value': 0.98289},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.81328},\n  {'tag': 'val/box_loss', 'value': 0.77755},\n  {'tag': 'val/cls_loss', 'value': 1.683},\n  {'tag': 'val/dfl_loss', 'value': 0.94955},\n  {'tag': 'lr/pg0', 'value': 0.0011389},\n  {'tag': 'lr/pg1', 'value': 0.0011389},\n  {'tag': 'lr/pg2', 'value': 0.0011389}],\n [{'tag': 'epoch', 'value': 19.0},\n  {'tag': 'train/box_loss', 'value': 0.95701},\n  {'tag': 'train/cls_loss', 'value': 1.7063},\n  {'tag': 'train/dfl_loss', 'value': 0.98483},\n  {'tag': 'metrics/precision(B)', 'value': 0.96426},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.80143},\n  {'tag': 'val/box_loss', 'value': 0.63516},\n  {'tag': 'val/cls_loss', 'value': 1.5477},\n  {'tag': 'val/dfl_loss', 'value': 0.9032},\n  {'tag': 'lr/pg0', 'value': 0.0011059},\n  {'tag': 'lr/pg1', 'value': 0.0011059},\n  {'tag': 'lr/pg2', 'value': 0.0011059}],\n [{'tag': 'epoch', 'value': 20.0},\n  {'tag': 'train/box_loss', 'value': 1.0154},\n  {'tag': 'train/cls_loss', 'value': 1.7834},\n  {'tag': 'train/dfl_loss', 'value': 1.0516},\n  {'tag': 'metrics/precision(B)', 'value': 0.95888},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.82447},\n  {'tag': 'val/box_loss', 'value': 0.5856},\n  {'tag': 'val/cls_loss', 'value': 1.5122},\n  {'tag': 'val/dfl_loss', 'value': 0.88545},\n  {'tag': 'lr/pg0', 'value': 0.0010729},\n  {'tag': 'lr/pg1', 'value': 0.0010729},\n  {'tag': 'lr/pg2', 'value': 0.0010729}],\n [{'tag': 'epoch', 'value': 21.0},\n  {'tag': 'train/box_loss', 'value': 0.92979},\n  {'tag': 'train/cls_loss', 'value': 2.9758},\n  {'tag': 'train/dfl_loss', 'value': 1.0026},\n  {'tag': 'metrics/precision(B)', 'value': 0.95478},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.83234},\n  {'tag': 'val/box_loss', 'value': 0.60787},\n  {'tag': 'val/cls_loss', 'value': 1.4665},\n  {'tag': 'val/dfl_loss', 'value': 0.89279},\n  {'tag': 'lr/pg0', 'value': 0.0010399},\n  {'tag': 'lr/pg1', 'value': 0.0010399},\n  {'tag': 'lr/pg2', 'value': 0.0010399}],\n [{'tag': 'epoch', 'value': 22.0},\n  {'tag': 'train/box_loss', 'value': 1.0061},\n  {'tag': 'train/cls_loss', 'value': 2.0711},\n  {'tag': 'train/dfl_loss', 'value': 1.02},\n  {'tag': 'metrics/precision(B)', 'value': 0.94932},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.83564},\n  {'tag': 'val/box_loss', 'value': 0.65912},\n  {'tag': 'val/cls_loss', 'value': 1.4789},\n  {'tag': 'val/dfl_loss', 'value': 0.90882},\n  {'tag': 'lr/pg0', 'value': 0.0010069},\n  {'tag': 'lr/pg1', 'value': 0.0010069},\n  {'tag': 'lr/pg2', 'value': 0.0010069}],\n [{'tag': 'epoch', 'value': 23.0},\n  {'tag': 'train/box_loss', 'value': 0.98472},\n  {'tag': 'train/cls_loss', 'value': 1.6678},\n  {'tag': 'train/dfl_loss', 'value': 1.0112},\n  {'tag': 'metrics/precision(B)', 'value': 0.97403},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.80763},\n  {'tag': 'val/box_loss', 'value': 0.58132},\n  {'tag': 'val/cls_loss', 'value': 1.4026},\n  {'tag': 'val/dfl_loss', 'value': 0.87839},\n  {'tag': 'lr/pg0', 'value': 0.00097386},\n  {'tag': 'lr/pg1', 'value': 0.00097386},\n  {'tag': 'lr/pg2', 'value': 0.00097386}],\n [{'tag': 'epoch', 'value': 24.0},\n  {'tag': 'train/box_loss', 'value': 0.89431},\n  {'tag': 'train/cls_loss', 'value': 1.8867},\n  {'tag': 'train/dfl_loss', 'value': 0.97741},\n  {'tag': 'metrics/precision(B)', 'value': 0.97196},\n  {'tag': 'metrics/recall(B)', 'value': 0.99866},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.84066},\n  {'tag': 'val/box_loss', 'value': 0.56923},\n  {'tag': 'val/cls_loss', 'value': 1.2981},\n  {'tag': 'val/dfl_loss', 'value': 0.87291},\n  {'tag': 'lr/pg0', 'value': 0.00094085},\n  {'tag': 'lr/pg1', 'value': 0.00094085},\n  {'tag': 'lr/pg2', 'value': 0.00094085}],\n [{'tag': 'epoch', 'value': 25.0},\n  {'tag': 'train/box_loss', 'value': 0.88719},\n  {'tag': 'train/cls_loss', 'value': 1.6143},\n  {'tag': 'train/dfl_loss', 'value': 0.99381},\n  {'tag': 'metrics/precision(B)', 'value': 0.96733},\n  {'tag': 'metrics/recall(B)', 'value': 0.9997},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.84075},\n  {'tag': 'val/box_loss', 'value': 0.48798},\n  {'tag': 'val/cls_loss', 'value': 1.2675},\n  {'tag': 'val/dfl_loss', 'value': 0.85425},\n  {'tag': 'lr/pg0', 'value': 0.00090785},\n  {'tag': 'lr/pg1', 'value': 0.00090785},\n  {'tag': 'lr/pg2', 'value': 0.00090785}],\n [{'tag': 'epoch', 'value': 26.0},\n  {'tag': 'train/box_loss', 'value': 0.84876},\n  {'tag': 'train/cls_loss', 'value': 1.6264},\n  {'tag': 'train/dfl_loss', 'value': 0.92925},\n  {'tag': 'metrics/precision(B)', 'value': 0.98731},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.84798},\n  {'tag': 'val/box_loss', 'value': 0.55751},\n  {'tag': 'val/cls_loss', 'value': 1.1992},\n  {'tag': 'val/dfl_loss', 'value': 0.86784},\n  {'tag': 'lr/pg0', 'value': 0.00087484},\n  {'tag': 'lr/pg1', 'value': 0.00087484},\n  {'tag': 'lr/pg2', 'value': 0.00087484}],\n [{'tag': 'epoch', 'value': 27.0},\n  {'tag': 'train/box_loss', 'value': 0.93747},\n  {'tag': 'train/cls_loss', 'value': 1.6506},\n  {'tag': 'train/dfl_loss', 'value': 0.98225},\n  {'tag': 'metrics/precision(B)', 'value': 0.97825},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.91569},\n  {'tag': 'val/box_loss', 'value': 0.5384},\n  {'tag': 'val/cls_loss', 'value': 1.1146},\n  {'tag': 'val/dfl_loss', 'value': 0.85695},\n  {'tag': 'lr/pg0', 'value': 0.00084184},\n  {'tag': 'lr/pg1', 'value': 0.00084184},\n  {'tag': 'lr/pg2', 'value': 0.00084184}],\n [{'tag': 'epoch', 'value': 28.0},\n  {'tag': 'train/box_loss', 'value': 0.88906},\n  {'tag': 'train/cls_loss', 'value': 1.548},\n  {'tag': 'train/dfl_loss', 'value': 1.0091},\n  {'tag': 'metrics/precision(B)', 'value': 0.981},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.96028},\n  {'tag': 'val/box_loss', 'value': 0.51107},\n  {'tag': 'val/cls_loss', 'value': 1.0871},\n  {'tag': 'val/dfl_loss', 'value': 0.85397},\n  {'tag': 'lr/pg0', 'value': 0.00080883},\n  {'tag': 'lr/pg1', 'value': 0.00080883},\n  {'tag': 'lr/pg2', 'value': 0.00080883}],\n [{'tag': 'epoch', 'value': 29.0},\n  {'tag': 'train/box_loss', 'value': 0.81072},\n  {'tag': 'train/cls_loss', 'value': 1.5923},\n  {'tag': 'train/dfl_loss', 'value': 0.93118},\n  {'tag': 'metrics/precision(B)', 'value': 0.98749},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.90461},\n  {'tag': 'val/box_loss', 'value': 0.47067},\n  {'tag': 'val/cls_loss', 'value': 1.0576},\n  {'tag': 'val/dfl_loss', 'value': 0.84179},\n  {'tag': 'lr/pg0', 'value': 0.00077582},\n  {'tag': 'lr/pg1', 'value': 0.00077582},\n  {'tag': 'lr/pg2', 'value': 0.00077582}],\n [{'tag': 'epoch', 'value': 30.0},\n  {'tag': 'train/box_loss', 'value': 0.8249},\n  {'tag': 'train/cls_loss', 'value': 1.3682},\n  {'tag': 'train/dfl_loss', 'value': 0.94273},\n  {'tag': 'metrics/precision(B)', 'value': 0.98969},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.9036},\n  {'tag': 'val/box_loss', 'value': 0.39666},\n  {'tag': 'val/cls_loss', 'value': 1.053},\n  {'tag': 'val/dfl_loss', 'value': 0.82851},\n  {'tag': 'lr/pg0', 'value': 0.00074282},\n  {'tag': 'lr/pg1', 'value': 0.00074282},\n  {'tag': 'lr/pg2', 'value': 0.00074282}],\n [{'tag': 'epoch', 'value': 31.0},\n  {'tag': 'train/box_loss', 'value': 0.73144},\n  {'tag': 'train/cls_loss', 'value': 1.3732},\n  {'tag': 'train/dfl_loss', 'value': 0.90753},\n  {'tag': 'metrics/precision(B)', 'value': 0.98757},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.88781},\n  {'tag': 'val/box_loss', 'value': 0.375},\n  {'tag': 'val/cls_loss', 'value': 0.99855},\n  {'tag': 'val/dfl_loss', 'value': 0.83017},\n  {'tag': 'lr/pg0', 'value': 0.00070981},\n  {'tag': 'lr/pg1', 'value': 0.00070981},\n  {'tag': 'lr/pg2', 'value': 0.00070981}],\n [{'tag': 'epoch', 'value': 32.0},\n  {'tag': 'train/box_loss', 'value': 0.75478},\n  {'tag': 'train/cls_loss', 'value': 1.3006},\n  {'tag': 'train/dfl_loss', 'value': 0.92523},\n  {'tag': 'metrics/precision(B)', 'value': 0.98351},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.91202},\n  {'tag': 'val/box_loss', 'value': 0.43955},\n  {'tag': 'val/cls_loss', 'value': 1.0266},\n  {'tag': 'val/dfl_loss', 'value': 0.84016},\n  {'tag': 'lr/pg0', 'value': 0.0006768},\n  {'tag': 'lr/pg1', 'value': 0.0006768},\n  {'tag': 'lr/pg2', 'value': 0.0006768}],\n [{'tag': 'epoch', 'value': 33.0},\n  {'tag': 'train/box_loss', 'value': 0.75876},\n  {'tag': 'train/cls_loss', 'value': 1.5963},\n  {'tag': 'train/dfl_loss', 'value': 0.91352},\n  {'tag': 'metrics/precision(B)', 'value': 0.97136},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.88963},\n  {'tag': 'val/box_loss', 'value': 0.49852},\n  {'tag': 'val/cls_loss', 'value': 1.1063},\n  {'tag': 'val/dfl_loss', 'value': 0.85433},\n  {'tag': 'lr/pg0', 'value': 0.0006438},\n  {'tag': 'lr/pg1', 'value': 0.0006438},\n  {'tag': 'lr/pg2', 'value': 0.0006438}],\n [{'tag': 'epoch', 'value': 34.0},\n  {'tag': 'train/box_loss', 'value': 0.78078},\n  {'tag': 'train/cls_loss', 'value': 1.4324},\n  {'tag': 'train/dfl_loss', 'value': 0.92701},\n  {'tag': 'metrics/precision(B)', 'value': 0.9645},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.83881},\n  {'tag': 'val/box_loss', 'value': 0.60238},\n  {'tag': 'val/cls_loss', 'value': 1.1641},\n  {'tag': 'val/dfl_loss', 'value': 0.87747},\n  {'tag': 'lr/pg0', 'value': 0.00061079},\n  {'tag': 'lr/pg1', 'value': 0.00061079},\n  {'tag': 'lr/pg2', 'value': 0.00061079}],\n [{'tag': 'epoch', 'value': 35.0},\n  {'tag': 'train/box_loss', 'value': 0.8292},\n  {'tag': 'train/cls_loss', 'value': 1.5066},\n  {'tag': 'train/dfl_loss', 'value': 0.96952},\n  {'tag': 'metrics/precision(B)', 'value': 0.97829},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.84816},\n  {'tag': 'val/box_loss', 'value': 0.56216},\n  {'tag': 'val/cls_loss', 'value': 1.1453},\n  {'tag': 'val/dfl_loss', 'value': 0.86508},\n  {'tag': 'lr/pg0', 'value': 0.00057778},\n  {'tag': 'lr/pg1', 'value': 0.00057778},\n  {'tag': 'lr/pg2', 'value': 0.00057778}],\n [{'tag': 'epoch', 'value': 36.0},\n  {'tag': 'train/box_loss', 'value': 0.74242},\n  {'tag': 'train/cls_loss', 'value': 1.3477},\n  {'tag': 'train/dfl_loss', 'value': 0.94292},\n  {'tag': 'metrics/precision(B)', 'value': 0.98707},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.86303},\n  {'tag': 'val/box_loss', 'value': 0.48702},\n  {'tag': 'val/cls_loss', 'value': 1.1534},\n  {'tag': 'val/dfl_loss', 'value': 0.85386},\n  {'tag': 'lr/pg0', 'value': 0.00054478},\n  {'tag': 'lr/pg1', 'value': 0.00054478},\n  {'tag': 'lr/pg2', 'value': 0.00054478}],\n [{'tag': 'epoch', 'value': 37.0},\n  {'tag': 'train/box_loss', 'value': 0.8563},\n  {'tag': 'train/cls_loss', 'value': 1.2671},\n  {'tag': 'train/dfl_loss', 'value': 0.96367},\n  {'tag': 'metrics/precision(B)', 'value': 0.9853},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.88155},\n  {'tag': 'val/box_loss', 'value': 0.46772},\n  {'tag': 'val/cls_loss', 'value': 1.109},\n  {'tag': 'val/dfl_loss', 'value': 0.85329},\n  {'tag': 'lr/pg0', 'value': 0.00051177},\n  {'tag': 'lr/pg1', 'value': 0.00051177},\n  {'tag': 'lr/pg2', 'value': 0.00051177}],\n [{'tag': 'epoch', 'value': 38.0},\n  {'tag': 'train/box_loss', 'value': 0.75051},\n  {'tag': 'train/cls_loss', 'value': 1.2677},\n  {'tag': 'train/dfl_loss', 'value': 0.89221},\n  {'tag': 'metrics/precision(B)', 'value': 0.98462},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.89094},\n  {'tag': 'val/box_loss', 'value': 0.45846},\n  {'tag': 'val/cls_loss', 'value': 1.0294},\n  {'tag': 'val/dfl_loss', 'value': 0.85682},\n  {'tag': 'lr/pg0', 'value': 0.00047876},\n  {'tag': 'lr/pg1', 'value': 0.00047876},\n  {'tag': 'lr/pg2', 'value': 0.00047876}],\n [{'tag': 'epoch', 'value': 39.0},\n  {'tag': 'train/box_loss', 'value': 0.68843},\n  {'tag': 'train/cls_loss', 'value': 1.2692},\n  {'tag': 'train/dfl_loss', 'value': 0.9136},\n  {'tag': 'metrics/precision(B)', 'value': 0.97703},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.87248},\n  {'tag': 'val/box_loss', 'value': 0.44022},\n  {'tag': 'val/cls_loss', 'value': 1.07},\n  {'tag': 'val/dfl_loss', 'value': 0.85327},\n  {'tag': 'lr/pg0', 'value': 0.00044576},\n  {'tag': 'lr/pg1', 'value': 0.00044576},\n  {'tag': 'lr/pg2', 'value': 0.00044576}],\n [{'tag': 'epoch', 'value': 40.0},\n  {'tag': 'train/box_loss', 'value': 0.76343},\n  {'tag': 'train/cls_loss', 'value': 1.2374},\n  {'tag': 'train/dfl_loss', 'value': 0.91103},\n  {'tag': 'metrics/precision(B)', 'value': 0.96992},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.88185},\n  {'tag': 'val/box_loss', 'value': 0.40082},\n  {'tag': 'val/cls_loss', 'value': 1.0924},\n  {'tag': 'val/dfl_loss', 'value': 0.84257},\n  {'tag': 'lr/pg0', 'value': 0.00041275},\n  {'tag': 'lr/pg1', 'value': 0.00041275},\n  {'tag': 'lr/pg2', 'value': 0.00041275}],\n [{'tag': 'epoch', 'value': 41.0},\n  {'tag': 'train/box_loss', 'value': 0.65702},\n  {'tag': 'train/cls_loss', 'value': 1.3044},\n  {'tag': 'train/dfl_loss', 'value': 0.92026},\n  {'tag': 'metrics/precision(B)', 'value': 0.96291},\n  {'tag': 'metrics/recall(B)', 'value': 0.99873},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.90155},\n  {'tag': 'val/box_loss', 'value': 0.40349},\n  {'tag': 'val/cls_loss', 'value': 0.99385},\n  {'tag': 'val/dfl_loss', 'value': 0.84281},\n  {'tag': 'lr/pg0', 'value': 0.00037974},\n  {'tag': 'lr/pg1', 'value': 0.00037974},\n  {'tag': 'lr/pg2', 'value': 0.00037974}],\n [{'tag': 'epoch', 'value': 42.0},\n  {'tag': 'train/box_loss', 'value': 0.63936},\n  {'tag': 'train/cls_loss', 'value': 1.2483},\n  {'tag': 'train/dfl_loss', 'value': 0.9003},\n  {'tag': 'metrics/precision(B)', 'value': 0.9642},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.89963},\n  {'tag': 'val/box_loss', 'value': 0.41567},\n  {'tag': 'val/cls_loss', 'value': 0.95405},\n  {'tag': 'val/dfl_loss', 'value': 0.83693},\n  {'tag': 'lr/pg0', 'value': 0.00034674},\n  {'tag': 'lr/pg1', 'value': 0.00034674},\n  {'tag': 'lr/pg2', 'value': 0.00034674}],\n [{'tag': 'epoch', 'value': 43.0},\n  {'tag': 'train/box_loss', 'value': 0.64237},\n  {'tag': 'train/cls_loss', 'value': 1.2701},\n  {'tag': 'train/dfl_loss', 'value': 0.87913},\n  {'tag': 'metrics/precision(B)', 'value': 0.97005},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.89963},\n  {'tag': 'val/box_loss', 'value': 0.4301},\n  {'tag': 'val/cls_loss', 'value': 0.96179},\n  {'tag': 'val/dfl_loss', 'value': 0.83769},\n  {'tag': 'lr/pg0', 'value': 0.00031373},\n  {'tag': 'lr/pg1', 'value': 0.00031373},\n  {'tag': 'lr/pg2', 'value': 0.00031373}],\n [{'tag': 'epoch', 'value': 44.0},\n  {'tag': 'train/box_loss', 'value': 0.57941},\n  {'tag': 'train/cls_loss', 'value': 1.1566},\n  {'tag': 'train/dfl_loss', 'value': 0.89615},\n  {'tag': 'metrics/precision(B)', 'value': 0.97691},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.9414},\n  {'tag': 'val/box_loss', 'value': 0.45878},\n  {'tag': 'val/cls_loss', 'value': 0.95365},\n  {'tag': 'val/dfl_loss', 'value': 0.84326},\n  {'tag': 'lr/pg0', 'value': 0.00028072},\n  {'tag': 'lr/pg1', 'value': 0.00028072},\n  {'tag': 'lr/pg2', 'value': 0.00028072}],\n [{'tag': 'epoch', 'value': 45.0},\n  {'tag': 'train/box_loss', 'value': 0.62247},\n  {'tag': 'train/cls_loss', 'value': 1.2098},\n  {'tag': 'train/dfl_loss', 'value': 0.88644},\n  {'tag': 'metrics/precision(B)', 'value': 0.9817},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.90222},\n  {'tag': 'val/box_loss', 'value': 0.43521},\n  {'tag': 'val/cls_loss', 'value': 0.96194},\n  {'tag': 'val/dfl_loss', 'value': 0.83812},\n  {'tag': 'lr/pg0', 'value': 0.00024772},\n  {'tag': 'lr/pg1', 'value': 0.00024772},\n  {'tag': 'lr/pg2', 'value': 0.00024772}],\n [{'tag': 'epoch', 'value': 46.0},\n  {'tag': 'train/box_loss', 'value': 0.60818},\n  {'tag': 'train/cls_loss', 'value': 1.2013},\n  {'tag': 'train/dfl_loss', 'value': 0.8573},\n  {'tag': 'metrics/precision(B)', 'value': 0.9889},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.89776},\n  {'tag': 'val/box_loss', 'value': 0.38069},\n  {'tag': 'val/cls_loss', 'value': 0.95059},\n  {'tag': 'val/dfl_loss', 'value': 0.83151},\n  {'tag': 'lr/pg0', 'value': 0.00021471},\n  {'tag': 'lr/pg1', 'value': 0.00021471},\n  {'tag': 'lr/pg2', 'value': 0.00021471}],\n [{'tag': 'epoch', 'value': 47.0},\n  {'tag': 'train/box_loss', 'value': 0.55504},\n  {'tag': 'train/cls_loss', 'value': 1.1902},\n  {'tag': 'train/dfl_loss', 'value': 0.87212},\n  {'tag': 'metrics/precision(B)', 'value': 0.9898},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.92709},\n  {'tag': 'val/box_loss', 'value': 0.35229},\n  {'tag': 'val/cls_loss', 'value': 0.92473},\n  {'tag': 'val/dfl_loss', 'value': 0.82766},\n  {'tag': 'lr/pg0', 'value': 0.0001817},\n  {'tag': 'lr/pg1', 'value': 0.0001817},\n  {'tag': 'lr/pg2', 'value': 0.0001817}],\n [{'tag': 'epoch', 'value': 48.0},\n  {'tag': 'train/box_loss', 'value': 0.54536},\n  {'tag': 'train/cls_loss', 'value': 1.1609},\n  {'tag': 'train/dfl_loss', 'value': 0.83567},\n  {'tag': 'metrics/precision(B)', 'value': 0.99},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.93022},\n  {'tag': 'val/box_loss', 'value': 0.36754},\n  {'tag': 'val/cls_loss', 'value': 0.91815},\n  {'tag': 'val/dfl_loss', 'value': 0.8254},\n  {'tag': 'lr/pg0', 'value': 0.0001487},\n  {'tag': 'lr/pg1', 'value': 0.0001487},\n  {'tag': 'lr/pg2', 'value': 0.0001487}],\n [{'tag': 'epoch', 'value': 49.0},\n  {'tag': 'train/box_loss', 'value': 0.53891},\n  {'tag': 'train/cls_loss', 'value': 1.1296},\n  {'tag': 'train/dfl_loss', 'value': 0.84148},\n  {'tag': 'metrics/precision(B)', 'value': 0.98987},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.91172},\n  {'tag': 'val/box_loss', 'value': 0.37659},\n  {'tag': 'val/cls_loss', 'value': 0.9197},\n  {'tag': 'val/dfl_loss', 'value': 0.82518},\n  {'tag': 'lr/pg0', 'value': 0.00011569},\n  {'tag': 'lr/pg1', 'value': 0.00011569},\n  {'tag': 'lr/pg2', 'value': 0.00011569}],\n [{'tag': 'epoch', 'value': 50.0},\n  {'tag': 'train/box_loss', 'value': 0.54389},\n  {'tag': 'train/cls_loss', 'value': 1.111},\n  {'tag': 'train/dfl_loss', 'value': 0.8559},\n  {'tag': 'metrics/precision(B)', 'value': 0.98916},\n  {'tag': 'metrics/recall(B)', 'value': 1.0},\n  {'tag': 'metrics/mAP50(B)', 'value': 0.995},\n  {'tag': 'metrics/mAP50-95(B)', 'value': 0.92422},\n  {'tag': 'val/box_loss', 'value': 0.37283},\n  {'tag': 'val/cls_loss', 'value': 0.92134},\n  {'tag': 'val/dfl_loss', 'value': 0.82441},\n  {'tag': 'lr/pg0', 'value': 8.2683e-05},\n  {'tag': 'lr/pg1', 'value': 8.2683e-05},\n  {'tag': 'lr/pg2', 'value': 8.2683e-05}]]</pre> In\u00a0[25]: Copied! <pre>result = ultralytics_hub.evaluate(\n    dataset=dataset,\n    batch_size=4,\n)\nresult\n</pre> result = ultralytics_hub.evaluate(     dataset=dataset,     batch_size=4, ) result  <pre> 33%|\u2588\u2588\u2588\u258e      | 1/3 [00:00&lt;00:00,  6.56it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 11.56it/s]\n</pre> Out[25]: <pre>EvaluateResult(eval_metrics=[{'tag': 'mAP', 'value': 0.835066020488739}, {'tag': 'mAP_50', 'value': 1.0}, {'tag': 'mAP_75', 'value': 1.0}, {'tag': 'mAP_small', 'value': 0.7205445766448975}, {'tag': 'mAP_medium', 'value': 0.871039628982544}, {'tag': 'mAP_large', 'value': -1.0}, {'tag': 'mAR_1', 'value': 0.8500000238418579}, {'tag': 'mAR_10', 'value': 0.8500000238418579}, {'tag': 'mAR_100', 'value': 0.8500000238418579}, {'tag': 'mAR_small', 'value': 0.7250000238418579}, {'tag': 'mAR_medium', 'value': 0.871039628982544}, {'tag': 'mAR_large', 'value': -1.0}, {'tag': 'mAP_per_class', 'value': [{'class_name': '1', 'value': 0.7533003091812134}, {'class_name': '2', 'value': 0.9168316721916199}]}, {'tag': 'mAR_100_per_class', 'value': [{'class_name': '1', 'value': 0.7666666507720947}, {'class_name': '2', 'value': 0.9333333373069763}]}])</pre> In\u00a0[26]: Copied! <pre>result = ultralytics_hub.evaluate(\n    dataset=dataset,\n    set_name=\"val\",\n    batch_size=4,\n)\nresult\n</pre> result = ultralytics_hub.evaluate(     dataset=dataset,     set_name=\"val\",     batch_size=4, ) result  <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 11.39it/s]\n</pre> Out[26]: <pre>EvaluateResult(eval_metrics=[{'tag': 'mAP', 'value': 0.9183168411254883}, {'tag': 'mAP_50', 'value': 1.0}, {'tag': 'mAP_75', 'value': 1.0}, {'tag': 'mAP_small', 'value': 0.8554455637931824}, {'tag': 'mAP_medium', 'value': 0.9678217768669128}, {'tag': 'mAP_large', 'value': -1.0}, {'tag': 'mAR_1', 'value': 0.9424999952316284}, {'tag': 'mAR_10', 'value': 0.9424999952316284}, {'tag': 'mAR_100', 'value': 0.9424999952316284}, {'tag': 'mAR_small', 'value': 0.8999999761581421}, {'tag': 'mAR_medium', 'value': 0.9678217768669128}, {'tag': 'mAR_large', 'value': -1.0}, {'tag': 'mAP_per_class', 'value': [{'class_name': '1', 'value': 0.9009901285171509}, {'class_name': '2', 'value': 0.9356435537338257}]}, {'tag': 'mAR_100_per_class', 'value': [{'class_name': '1', 'value': 0.925000011920929}, {'class_name': '2', 'value': 0.9599999785423279}]}])</pre> In\u00a0[27]: Copied! <pre>ultralytics_hub.get_evaluate_result()\n</pre> ultralytics_hub.get_evaluate_result() Out[27]: <pre>[{'tag': 'mAP', 'value': 0.9183168411254883},\n {'tag': 'mAP_50', 'value': 1.0},\n {'tag': 'mAP_75', 'value': 1.0},\n {'tag': 'mAP_small', 'value': 0.8554455637931824},\n {'tag': 'mAP_medium', 'value': 0.9678217768669128},\n {'tag': 'mAP_large', 'value': -1.0},\n {'tag': 'mAR_1', 'value': 0.9424999952316284},\n {'tag': 'mAR_10', 'value': 0.9424999952316284},\n {'tag': 'mAR_100', 'value': 0.9424999952316284},\n {'tag': 'mAR_small', 'value': 0.8999999761581421},\n {'tag': 'mAR_medium', 'value': 0.9678217768669128},\n {'tag': 'mAR_large', 'value': -1.0},\n {'tag': 'mAP_per_class',\n  'value': [{'class_name': '1', 'value': 0.9009901285171509},\n   {'class_name': '2', 'value': 0.9356435537338257}]},\n {'tag': 'mAR_100_per_class',\n  'value': [{'class_name': '1', 'value': 0.925000011920929},\n   {'class_name': '2', 'value': 0.9599999785423279}]}]</pre> In\u00a0[28]: Copied! <pre>ultralytics_hub.get_evaluate_state()\n</pre> ultralytics_hub.get_evaluate_state() Out[28]: <pre>{'status': 'success',\n 'error_type': None,\n 'error_msg': None,\n 'step': 4,\n 'total_step': 4}</pre> In\u00a0[29]: Copied! <pre>import PIL.Image\n</pre> import PIL.Image In\u00a0[30]: Copied! <pre>ultralytics_hub.inference(\n    source=\"datasets/mnist_det/raw/10.png\",\n    draw=True,\n)\nPIL.Image.open(ultralytics_hub.draw_dir / \"10.png\")\n</pre> ultralytics_hub.inference(     source=\"datasets/mnist_det/raw/10.png\",     draw=True, ) PIL.Image.open(ultralytics_hub.draw_dir / \"10.png\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00,  5.79it/s]\n</pre> Out[30]: In\u00a0[31]: Copied! <pre>ultralytics_hub.inference(\n    source=\"datasets/mnist_det/raw\",\n    recursive=True,\n    draw=True,\n)\nPIL.Image.open(ultralytics_hub.draw_dir / \"1.png\")\n</pre> ultralytics_hub.inference(     source=\"datasets/mnist_det/raw\",     recursive=True,     draw=True, ) PIL.Image.open(ultralytics_hub.draw_dir / \"1.png\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25/25 [00:00&lt;00:00, 27.37it/s]\n</pre> Out[31]: In\u00a0[32]: Copied! <pre>ultralytics_hub.get_inference_result()\n</pre> ultralytics_hub.get_inference_result() Out[32]: <pre>[{'1.png': [{'category_id': 1,\n    'bbox': [107.37403869628906,\n     91.69528198242188,\n     26.16375732421875,\n     46.10255432128906],\n    'area': 1206.2160432888195,\n    'iscrowd': 0,\n    'score': 0.9146654605865479}]},\n {'2.png': [{'category_id': 1,\n    'bbox': [149.558349609375,\n     177.26950073242188,\n     15.940292358398438,\n     42.1663818359375],\n    'area': 672.1444541607052,\n    'iscrowd': 0,\n    'score': 0.9036419987678528}]},\n {'3.png': [{'category_id': 1,\n    'bbox': [58.5820198059082,\n     88.27410125732422,\n     12.61246109008789,\n     37.57154083251953],\n    'area': 473.869596844801,\n    'iscrowd': 0,\n    'score': 0.8641519546508789}]},\n {'4.png': [{'category_id': 2,\n    'bbox': [121.241455078125,\n     158.77667236328125,\n     40.83848571777344,\n     47.66691589355469],\n    'area': 1946.6446639292408,\n    'iscrowd': 0,\n    'score': 0.9752923846244812}]},\n {'5.png': [{'category_id': 2,\n    'bbox': [248.9892120361328,\n     16.775619506835938,\n     28.735427856445312,\n     40.469242095947266],\n    'area': 1162.9009866531123,\n    'iscrowd': 0,\n    'score': 0.8770548701286316},\n   {'category_id': 1,\n    'bbox': [248.9248809814453,\n     17.079862594604492,\n     28.106918334960938,\n     38.899362564086914],\n    'area': 1093.3412068708276,\n    'iscrowd': 0,\n    'score': 0.29374971985816956}]},\n {'6.png': [{'category_id': 2,\n    'bbox': [29.183879852294922,\n     139.53492736816406,\n     50.67433547973633,\n     49.83283996582031],\n    'area': 2525.2460503359907,\n    'iscrowd': 0,\n    'score': 0.9912328124046326}]},\n {'7.png': [{'category_id': 1,\n    'bbox': [202.42071533203125,\n     97.07789611816406,\n     11.417724609375,\n     45.277740478515625],\n    'area': 516.9687717184424,\n    'iscrowd': 0,\n    'score': 0.8939312696456909}]},\n {'8.png': [{'category_id': 1,\n    'bbox': [253.1036834716797,\n     162.79286193847656,\n     26.246261596679688,\n     40.791046142578125],\n    'area': 1070.6124678603373,\n    'iscrowd': 0,\n    'score': 0.9028500318527222}]},\n {'9.png': [{'category_id': 2,\n    'bbox': [188.5682830810547,\n     50.26176834106445,\n     41.66490173339844,\n     36.03895950317383],\n    'area': 1501.5597062736633,\n    'iscrowd': 0,\n    'score': 0.9900986552238464}]},\n {'10.png': [{'category_id': 2,\n    'bbox': [72.91927337646484,\n     149.81422424316406,\n     41.76502227783203,\n     40.40257263183594],\n    'area': 1687.4143460503547,\n    'iscrowd': 0,\n    'score': 0.9770092368125916}]},\n {'11.png': [{'category_id': 2,\n    'bbox': [181.47659301757812,\n     207.53712463378906,\n     36.23258972167969,\n     45.81675720214844],\n    'area': 1660.0597660832573,\n    'iscrowd': 0,\n    'score': 0.7444103360176086}]},\n {'12.png': [{'category_id': 2,\n    'bbox': [114.2760009765625,\n     155.0713348388672,\n     47.544708251953125,\n     46.71159362792969],\n    'area': 2220.8890910237096,\n    'iscrowd': 0,\n    'score': 0.8842176198959351}]},\n {'13.png': [{'category_id': 1,\n    'bbox': [74.66617584228516,\n     13.339277267456055,\n     18.842987060546875,\n     39.500226974487305],\n    'area': 744.3022657689289,\n    'iscrowd': 0,\n    'score': 0.8572077751159668}]},\n {'14.png': [{'category_id': 1,\n    'bbox': [68.97553253173828,\n     137.81602478027344,\n     16.25658416748047,\n     41.9713134765625],\n    'area': 682.3101901514456,\n    'iscrowd': 0,\n    'score': 0.8666486740112305}]},\n {'15.png': [{'category_id': 2,\n    'bbox': [241.01937866210938,\n     52.2274169921875,\n     40.807647705078125,\n     37.952613830566406],\n    'area': 1548.7568946846295,\n    'iscrowd': 0,\n    'score': 0.8967580795288086}]},\n {'16.png': [{'category_id': 2,\n    'bbox': [218.94894409179688,\n     117.2512435913086,\n     35.18284606933594,\n     39.972023010253906],\n    'area': 1406.3295326497173,\n    'iscrowd': 0,\n    'score': 0.8826867341995239}]},\n {'17.png': [{'category_id': 2,\n    'bbox': [114.06609344482422,\n     66.23987579345703,\n     37.96564483642578,\n     40.78736877441406],\n    'area': 1548.5187567017274,\n    'iscrowd': 0,\n    'score': 0.9661129713058472}]},\n {'18.png': [{'category_id': 2,\n    'bbox': [162.17263793945312,\n     87.8706283569336,\n     47.76727294921875,\n     47.47876739501953],\n    'area': 2267.9312414503656,\n    'iscrowd': 0,\n    'score': 0.9773440957069397}]},\n {'19.png': [{'category_id': 1,\n    'bbox': [61.05482864379883,\n     132.39859008789062,\n     30.27657699584961,\n     43.60919189453125],\n    'area': 1320.337056121556,\n    'iscrowd': 0,\n    'score': 0.9044147729873657}]},\n {'20.png': [{'category_id': 2,\n    'bbox': [83.48413848876953,\n     175.60198974609375,\n     32.19489288330078,\n     49.08256530761719],\n    'area': 1580.2079325163504,\n    'iscrowd': 0,\n    'score': 0.6971146464347839}]},\n {'21.png': [{'category_id': 1,\n    'bbox': [249.01663208007812,\n     92.16047668457031,\n     21.70361328125,\n     50.19775390625],\n    'area': 1089.4726383686066,\n    'iscrowd': 0,\n    'score': 0.9800584316253662}]},\n {'22.png': [{'category_id': 2,\n    'bbox': [85.35608673095703,\n     104.4917984008789,\n     37.25572204589844,\n     39.359947204589844],\n    'area': 1466.3832527954364,\n    'iscrowd': 0,\n    'score': 0.7034189105033875}]},\n {'23.png': [{'category_id': 1,\n    'bbox': [150.69219970703125,\n     58.751651763916016,\n     29.8643798828125,\n     43.18845748901367],\n    'area': 1289.7965010046028,\n    'iscrowd': 0,\n    'score': 0.9177032709121704}]},\n {'24.png': [{'category_id': 1,\n    'bbox': [224.95980834960938,\n     225.2217254638672,\n     14.434768676757812,\n     42.85612487792969],\n    'area': 618.6182489951607,\n    'iscrowd': 0,\n    'score': 0.8671126961708069}]},\n {'25.png': [{'category_id': 1,\n    'bbox': [178.1912841796875,\n     139.74893188476562,\n     16.872390747070312,\n     42.18693542480469],\n    'area': 711.7944589087274,\n    'iscrowd': 0,\n    'score': 0.8748034238815308}]},\n {'26.png': [{'category_id': 2,\n    'bbox': [39.13764572143555,\n     179.34515380859375,\n     35.42953872680664,\n     39.82804870605469],\n    'area': 1411.0893940443057,\n    'iscrowd': 0,\n    'score': 0.9176478385925293}]},\n {'27.png': [{'category_id': 1,\n    'bbox': [208.67160034179688,\n     67.70893859863281,\n     24.71368408203125,\n     39.23912811279297],\n    'area': 969.7434158339165,\n    'iscrowd': 0,\n    'score': 0.8112889528274536}]},\n {'28.png': [{'category_id': 1,\n    'bbox': [103.03473663330078,\n     174.98130798339844,\n     32.78600311279297,\n     52.71205139160156],\n    'area': 1728.2174810067518,\n    'iscrowd': 0,\n    'score': 0.774827241897583},\n   {'category_id': 2,\n    'bbox': [102.87519073486328,\n     174.97119140625,\n     33.978355407714844,\n     51.84465026855469],\n    'area': 1761.59595281363,\n    'iscrowd': 0,\n    'score': 0.3328860104084015}]},\n {'29.png': [{'category_id': 1,\n    'bbox': [167.11505126953125,\n     137.48397827148438,\n     19.749038696289062,\n     48.76881408691406],\n    'area': 963.137196574593,\n    'iscrowd': 0,\n    'score': 0.9745906591415405}]},\n {'30.png': [{'category_id': 2,\n    'bbox': [32.97163009643555,\n     19.205474853515625,\n     45.2025260925293,\n     49.95311737060547],\n    'area': 2258.007091347972,\n    'iscrowd': 0,\n    'score': 0.973502516746521}]},\n {'31.png': [{'category_id': 2,\n    'bbox': [238.7873992919922,\n     101.14745330810547,\n     38.87806701660156,\n     37.378318786621094],\n    'area': 1453.196782754152,\n    'iscrowd': 0,\n    'score': 0.9764174222946167}]},\n {'32.png': [{'category_id': 2,\n    'bbox': [12.323423385620117,\n     170.16522216796875,\n     44.53322410583496,\n     50.89341735839844],\n    'area': 2266.4479607333487,\n    'iscrowd': 0,\n    'score': 0.9471334218978882}]},\n {'33.png': [{'category_id': 2,\n    'bbox': [145.00057983398438,\n     50.29595947265625,\n     51.73492431640625,\n     50.75120544433594],\n    'area': 2625.6097726291046,\n    'iscrowd': 0,\n    'score': 0.9951984286308289}]},\n {'34.png': [{'category_id': 1,\n    'bbox': [154.5885009765625,\n     129.84249877929688,\n     15.209091186523438,\n     44.91650390625],\n    'area': 683.1392036899924,\n    'iscrowd': 0,\n    'score': 0.9187330603599548}]},\n {'35.png': [{'category_id': 1,\n    'bbox': [36.00315475463867,\n     179.88201904296875,\n     16.43838882446289,\n     43.817413330078125],\n    'area': 720.2876776020275,\n    'iscrowd': 0,\n    'score': 0.8357078433036804}]},\n {'36.png': [{'category_id': 1,\n    'bbox': [209.523193359375,\n     212.6623992919922,\n     18.87774658203125,\n     46.86231994628906],\n    'area': 884.6550001921132,\n    'iscrowd': 0,\n    'score': 0.9083700776100159}]},\n {'37.png': [{'category_id': 1,\n    'bbox': [143.8166961669922,\n     69.47636413574219,\n     19.218582153320312,\n     45.813995361328125],\n    'area': 880.4800336235203,\n    'iscrowd': 0,\n    'score': 0.9707226157188416}]},\n {'38.png': [{'category_id': 2,\n    'bbox': [88.7427749633789,\n     245.09063720703125,\n     34.688575744628906,\n     43.751190185546875],\n    'area': 1517.6664746690076,\n    'iscrowd': 0,\n    'score': 0.7821991443634033}]},\n {'39.png': [{'category_id': 1,\n    'bbox': [111.13388061523438,\n     154.28460693359375,\n     16.073875427246094,\n     50.523712158203125],\n    'area': 812.1118553529959,\n    'iscrowd': 0,\n    'score': 0.9123628735542297}]},\n {'40.png': [{'category_id': 1,\n    'bbox': [45.19650650024414,\n     203.94586181640625,\n     10.051929473876953,\n     39.9873046875],\n    'area': 401.9495665691793,\n    'iscrowd': 0,\n    'score': 0.8097560405731201}]},\n {'41.png': [{'category_id': 2,\n    'bbox': [176.89141845703125,\n     181.70675659179688,\n     45.50318908691406,\n     39.93782043457031],\n    'area': 1817.2981949534733,\n    'iscrowd': 0,\n    'score': 0.9695444107055664}]},\n {'42.png': [{'category_id': 2,\n    'bbox': [22.23501205444336,\n     152.77041625976562,\n     52.76359176635742,\n     51.85157775878906],\n    'area': 2735.875481306284,\n    'iscrowd': 0,\n    'score': 0.9921773076057434}]},\n {'43.png': [{'category_id': 1,\n    'bbox': [83.2344741821289,\n     21.205223083496094,\n     12.344818115234375,\n     37.381874084472656],\n    'area': 461.47243637940846,\n    'iscrowd': 0,\n    'score': 0.8283985257148743}]},\n {'44.png': [{'category_id': 2,\n    'bbox': [72.7606201171875,\n     244.7490692138672,\n     43.55078125,\n     44.07633972167969],\n    'area': 1919.559029519558,\n    'iscrowd': 0,\n    'score': 0.950958788394928}]},\n {'45.png': [{'category_id': 1,\n    'bbox': [242.43003845214844,\n     119.60758209228516,\n     30.480667114257812,\n     43.018577575683594],\n    'area': 1311.2349428132875,\n    'iscrowd': 0,\n    'score': 0.5536258220672607},\n   {'category_id': 2,\n    'bbox': [242.8927764892578,\n     119.67522430419922,\n     28.949417114257812,\n     43.22026824951172],\n    'area': 1251.201573345228,\n    'iscrowd': 0,\n    'score': 0.30987676978111267}]},\n {'46.png': [{'category_id': 2,\n    'bbox': [122.6753158569336,\n     159.79185485839844,\n     37.938941955566406,\n     36.49320983886719],\n    'area': 1384.513769849087,\n    'iscrowd': 0,\n    'score': 0.783037006855011}]},\n {'47.png': [{'category_id': 1,\n    'bbox': [251.1743927001953,\n     89.07243347167969,\n     9.666580200195312,\n     51.3333740234375],\n    'area': 496.2181769441813,\n    'iscrowd': 0,\n    'score': 0.7216965556144714}]},\n {'48.png': [{'category_id': 1,\n    'bbox': [60.358619689941406,\n     48.780311584472656,\n     23.34404754638672,\n     42.855995178222656],\n    'area': 1000.4323890881496,\n    'iscrowd': 0,\n    'score': 0.9197735786437988}]},\n {'49.png': [{'category_id': 1,\n    'bbox': [204.15185546875,\n     40.413787841796875,\n     26.206787109375,\n     45.655967712402344],\n    'area': 1196.496226111427,\n    'iscrowd': 0,\n    'score': 0.8905629515647888}]},\n {'50.png': [{'category_id': 2,\n    'bbox': [184.3700408935547,\n     28.903593063354492,\n     42.231903076171875,\n     48.39151191711426],\n    'area': 2043.6656409929856,\n    'iscrowd': 0,\n    'score': 0.985537588596344}]},\n {'51.png': [{'category_id': 2,\n    'bbox': [189.86114501953125,\n     137.86434936523438,\n     42.288604736328125,\n     38.41999816894531],\n    'area': 1624.7281165369786,\n    'iscrowd': 0,\n    'score': 0.9883555173873901}]},\n {'52.png': [{'category_id': 1,\n    'bbox': [57.15843200683594,\n     126.12716674804688,\n     32.2767333984375,\n     47.89598083496094],\n    'area': 1545.925804266706,\n    'iscrowd': 0,\n    'score': 0.9491451978683472}]},\n {'53.png': [{'category_id': 2,\n    'bbox': [26.10584831237793,\n     154.68820190429688,\n     43.225175857543945,\n     46.04075622558594],\n    'area': 1990.1197844652634,\n    'iscrowd': 0,\n    'score': 0.9862293004989624}]},\n {'54.png': [{'category_id': 1,\n    'bbox': [135.35313415527344,\n     127.70972442626953,\n     13.209609985351562,\n     37.846824645996094],\n    'area': 499.9417927575996,\n    'iscrowd': 0,\n    'score': 0.8370304703712463}]},\n {'55.png': [{'category_id': 1,\n    'bbox': [88.0989761352539,\n     139.73898315429688,\n     15.9249267578125,\n     42.171844482421875],\n    'area': 671.5835346244276,\n    'iscrowd': 0,\n    'score': 0.8043140769004822}]},\n {'56.png': [{'category_id': 2,\n    'bbox': [123.42178344726562,\n     242.4699249267578,\n     33.06404113769531,\n     45.26365661621094],\n    'area': 1496.599404400913,\n    'iscrowd': 0,\n    'score': 0.7499813437461853},\n   {'category_id': 1,\n    'bbox': [124.26764678955078,\n     242.78201293945312,\n     32.600669860839844,\n     43.958282470703125],\n    'area': 1433.0694544769358,\n    'iscrowd': 0,\n    'score': 0.26298636198043823}]},\n {'57.png': [{'category_id': 1,\n    'bbox': [164.83331298828125,\n     191.68023681640625,\n     24.921920776367188,\n     41.82810974121094],\n    'area': 1042.4368371956516,\n    'iscrowd': 0,\n    'score': 0.8885893821716309}]},\n {'58.png': [{'category_id': 2,\n    'bbox': [49.28673553466797,\n     95.11132049560547,\n     40.41609191894531,\n     35.98188018798828],\n    'area': 1454.2469770942116,\n    'iscrowd': 0,\n    'score': 0.9681341052055359}]},\n {'59.png': [{'category_id': 2,\n    'bbox': [10.382562637329102,\n     167.63961791992188,\n     39.652883529663086,\n     38.39898681640625],\n    'area': 1522.6305518880254,\n    'iscrowd': 0,\n    'score': 0.7519280910491943}]},\n {'60.png': [{'category_id': 1,\n    'bbox': [51.150665283203125,\n     199.77760314941406,\n     15.622909545898438,\n     37.87689208984375],\n    'area': 591.7472589993849,\n    'iscrowd': 0,\n    'score': 0.850445032119751}]},\n {'61.png': [{'category_id': 1,\n    'bbox': [163.78573608398438,\n     31.228673934936523,\n     29.0887451171875,\n     47.60717964172363],\n    'area': 1384.8331143462565,\n    'iscrowd': 0,\n    'score': 0.9522654414176941}]},\n {'62.png': [{'category_id': 1,\n    'bbox': [204.52627563476562,\n     107.98429870605469,\n     22.91351318359375,\n     49.35980224609375],\n    'area': 1131.0064795054495,\n    'iscrowd': 0,\n    'score': 0.9181255102157593}]},\n {'63.png': [{'category_id': 2,\n    'bbox': [10.435223579406738,\n     17.031118392944336,\n     52.494540214538574,\n     52.03397560119629],\n    'area': 2731.4996247193176,\n    'iscrowd': 0,\n    'score': 0.9948779344558716}]},\n {'64.png': [{'category_id': 1,\n    'bbox': [15.732364654541016,\n     221.81759643554688,\n     30.714698791503906,\n     42.142608642578125],\n    'area': 1294.3975307450164,\n    'iscrowd': 0,\n    'score': 0.8979506492614746}]},\n {'65.png': [{'category_id': 2,\n    'bbox': [199.841796875,\n     200.8621063232422,\n     47.19219970703125,\n     31.709335327148438],\n    'area': 1496.4332853360102,\n    'iscrowd': 0,\n    'score': 0.9224246144294739}]},\n {'66.png': [{'category_id': 1,\n    'bbox': [210.6031036376953,\n     188.3267822265625,\n     14.677871704101562,\n     43.9296875],\n    'area': 644.7943171262741,\n    'iscrowd': 0,\n    'score': 0.8851460814476013}]},\n {'67.png': [{'category_id': 1,\n    'bbox': [209.68040466308594,\n     39.04540252685547,\n     16.01416015625,\n     48.287574768066406],\n    'area': 773.2849558927119,\n    'iscrowd': 0,\n    'score': 0.9033970236778259}]},\n {'68.png': [{'category_id': 2,\n    'bbox': [54.796775817871094,\n     210.0718994140625,\n     32.08604431152344,\n     44.29510498046875],\n    'area': 1421.2547011869028,\n    'iscrowd': 0,\n    'score': 0.35110288858413696},\n   {'category_id': 1,\n    'bbox': [54.89453125,\n     210.43556213378906,\n     31.707603454589844,\n     44.33732604980469],\n    'area': 1405.8303526240634,\n    'iscrowd': 0,\n    'score': 0.2791428864002228}]},\n {'69.png': [{'category_id': 2,\n    'bbox': [92.98287963867188,\n     170.0443572998047,\n     53.80865478515625,\n     51.82710266113281],\n    'area': 2788.7466756077483,\n    'iscrowd': 0,\n    'score': 0.9365528225898743}]},\n {'70.png': [{'category_id': 2,\n    'bbox': [192.94163513183594,\n     152.8800811767578,\n     25.331512451171875,\n     41.056915283203125],\n    'area': 1040.0337607031688,\n    'iscrowd': 0,\n    'score': 0.814900815486908},\n   {'category_id': 1,\n    'bbox': [193.26611328125,\n     152.70285034179688,\n     25.513534545898438,\n     39.45664978027344],\n    'area': 1006.6785972344223,\n    'iscrowd': 0,\n    'score': 0.42624369263648987}]},\n {'71.png': [{'category_id': 2,\n    'bbox': [115.85311889648438,\n     155.74920654296875,\n     41.26081848144531,\n     35.41496276855469],\n    'area': 1461.250350320479,\n    'iscrowd': 0,\n    'score': 0.9794883728027344}]},\n {'72.png': [{'category_id': 2,\n    'bbox': [193.9483642578125,\n     51.05951690673828,\n     29.519546508789062,\n     45.99345397949219],\n    'area': 1357.705903847469,\n    'iscrowd': 0,\n    'score': 0.6929978132247925},\n   {'category_id': 1,\n    'bbox': [194.43197631835938,\n     51.683074951171875,\n     28.517364501953125,\n     44.04004669189453],\n    'area': 1255.9060641957913,\n    'iscrowd': 0,\n    'score': 0.4813160002231598}]},\n {'73.png': [{'category_id': 1,\n    'bbox': [238.67420959472656,\n     143.2823486328125,\n     17.854141235351562,\n     43.13890075683594],\n    'area': 770.2080268503632,\n    'iscrowd': 0,\n    'score': 0.9100496172904968}]},\n {'74.png': [{'category_id': 1,\n    'bbox': [37.128990173339844,\n     89.09979248046875,\n     29.686721801757812,\n     49.94813537597656],\n    'area': 1482.796399423154,\n    'iscrowd': 0,\n    'score': 0.9360374212265015}]},\n {'75.png': [{'category_id': 1,\n    'bbox': [252.85675048828125,\n     16.63373565673828,\n     19.74774169921875,\n     40.738712310791016],\n    'area': 804.497567872284,\n    'iscrowd': 0,\n    'score': 0.9473363161087036}]},\n {'76.png': [{'category_id': 2,\n    'bbox': [152.66172790527344,\n     145.0689697265625,\n     40.05964660644531,\n     46.9720458984375],\n    'area': 1881.6835590731353,\n    'iscrowd': 0,\n    'score': 0.9745892286300659}]},\n {'77.png': [{'category_id': 1,\n    'bbox': [111.6373291015625,\n     223.0884552001953,\n     22.346221923828125,\n     44.26402282714844],\n    'area': 989.133677336853,\n    'iscrowd': 0,\n    'score': 0.9015690684318542}]},\n {'78.png': [{'category_id': 2,\n    'bbox': [173.3302001953125,\n     136.73617553710938,\n     28.863006591796875,\n     39.04048156738281],\n    'area': 1126.8256768262945,\n    'iscrowd': 0,\n    'score': 0.7732616066932678}]},\n {'79.png': [{'category_id': 2,\n    'bbox': [17.396434783935547,\n     147.78359985351562,\n     41.42130661010742,\n     33.62599182128906],\n    'area': 1392.8325172985788,\n    'iscrowd': 0,\n    'score': 0.9623602032661438}]},\n {'80.png': [{'category_id': 2,\n    'bbox': [33.682830810546875,\n     42.548892974853516,\n     41.72947692871094,\n     50.5017204284668],\n    'area': 2107.410377479915,\n    'iscrowd': 0,\n    'score': 0.9930168390274048}]},\n {'81.png': [{'category_id': 1,\n    'bbox': [163.64999389648438,\n     114.89497375488281,\n     25.357070922851562,\n     43.878814697265625],\n    'area': 1112.638216289226,\n    'iscrowd': 0,\n    'score': 0.9388719797134399}]},\n {'82.png': [{'category_id': 2,\n    'bbox': [211.39463806152344,\n     78.27284240722656,\n     50.35270690917969,\n     51.39952087402344],\n    'area': 2588.1050098419655,\n    'iscrowd': 0,\n    'score': 0.9929288029670715}]},\n {'83.png': [{'category_id': 2,\n    'bbox': [166.95484924316406,\n     162.65234375,\n     49.92976379394531,\n     41.776214599609375],\n    'area': 2085.8765271636657,\n    'iscrowd': 0,\n    'score': 0.9740182161331177}]},\n {'84.png': [{'category_id': 2,\n    'bbox': [196.47779846191406,\n     155.66781616210938,\n     40.4298095703125,\n     38.794189453125],\n    'area': 1568.4416920244694,\n    'iscrowd': 0,\n    'score': 0.7136573195457458}]},\n {'85.png': [{'category_id': 2,\n    'bbox': [81.44833374023438,\n     214.91146850585938,\n     46.43236541748047,\n     44.502227783203125],\n    'area': 2066.3437023216393,\n    'iscrowd': 0,\n    'score': 0.9942675828933716}]},\n {'86.png': [{'category_id': 2,\n    'bbox': [196.27178955078125,\n     129.69923400878906,\n     43.492645263671875,\n     44.449005126953125],\n    'area': 1933.2048123097047,\n    'iscrowd': 0,\n    'score': 0.9973962306976318}]},\n {'87.png': [{'category_id': 2,\n    'bbox': [141.00062561035156,\n     94.76145935058594,\n     47.42060852050781,\n     49.42402648925781],\n    'area': 2343.717411654303,\n    'iscrowd': 0,\n    'score': 0.9930880665779114}]},\n {'88.png': [{'category_id': 2,\n    'bbox': [233.72686767578125,\n     28.955320358276367,\n     39.38140869140625,\n     48.67087745666504],\n    'area': 1916.727716490277,\n    'iscrowd': 0,\n    'score': 0.9703794121742249}]},\n {'89.png': [{'category_id': 2,\n    'bbox': [176.89276123046875,\n     89.12840270996094,\n     52.4542236328125,\n     50.76036071777344],\n    'area': 2662.5953127723187,\n    'iscrowd': 0,\n    'score': 0.9938546419143677}]},\n {'90.png': [{'category_id': 1,\n    'bbox': [81.19241333007812,\n     170.617919921875,\n     21.43170928955078,\n     48.68070983886719],\n    'area': 1043.310821275576,\n    'iscrowd': 0,\n    'score': 0.9071353673934937}]},\n {'91.png': [{'category_id': 1,\n    'bbox': [215.1730499267578,\n     53.64192199707031,\n     15.685211181640625,\n     45.9864501953125],\n    'area': 721.3071828074753,\n    'iscrowd': 0,\n    'score': 0.8564525246620178}]},\n {'92.png': [{'category_id': 2,\n    'bbox': [9.404844284057617,\n     76.97827911376953,\n     35.04997444152832,\n     38.06425476074219],\n    'area': 1334.1511564998364,\n    'iscrowd': 0,\n    'score': 0.9217996001243591}]},\n {'93.png': [{'category_id': 2,\n    'bbox': [182.91607666015625,\n     230.1783905029297,\n     38.117919921875,\n     33.28953552246094],\n    'area': 1268.9278492815793,\n    'iscrowd': 0,\n    'score': 0.8403367400169373}]},\n {'94.png': [{'category_id': 2,\n    'bbox': [57.97791290283203,\n     157.17276000976562,\n     33.613319396972656,\n     47.48931884765625],\n    'area': 1596.273642370943,\n    'iscrowd': 0,\n    'score': 0.706148087978363}]},\n {'95.png': [{'category_id': 2,\n    'bbox': [135.2042694091797,\n     185.5912322998047,\n     49.87428283691406,\n     49.677337646484375],\n    'area': 2477.6215883656405,\n    'iscrowd': 0,\n    'score': 0.9631057977676392}]},\n {'96.png': [{'category_id': 1,\n    'bbox': [43.464149475097656,\n     60.07721710205078,\n     36.08668518066406,\n     40.61408233642578],\n    'area': 1465.6276031761663,\n    'iscrowd': 0,\n    'score': 0.7510821223258972}]},\n {'97.png': [{'category_id': 2,\n    'bbox': [142.5912322998047,\n     137.80557250976562,\n     34.836395263671875,\n     47.76679992675781],\n    'area': 1664.023122729268,\n    'iscrowd': 0,\n    'score': 0.7539824843406677},\n   {'category_id': 1,\n    'bbox': [143.40261840820312,\n     137.6202392578125,\n     34.34614562988281,\n     46.98149108886719],\n    'area': 1613.633134847274,\n    'iscrowd': 0,\n    'score': 0.5318959355354309}]},\n {'98.png': [{'category_id': 1,\n    'bbox': [148.62164306640625,\n     50.803401947021484,\n     22.096435546875,\n     52.5422248840332],\n    'area': 1160.9958856394514,\n    'iscrowd': 0,\n    'score': 0.9605138301849365}]},\n {'99.png': [{'category_id': 2,\n    'bbox': [122.67571258544922,\n     222.01400756835938,\n     35.56623077392578,\n     42.501190185546875],\n    'area': 1511.6071383056697,\n    'iscrowd': 0,\n    'score': 0.8884586691856384}]},\n {'100.png': [{'category_id': 1,\n    'bbox': [88.93431091308594,\n     94.1872329711914,\n     19.821212768554688,\n     45.44658660888672],\n    'area': 900.8064627792919,\n    'iscrowd': 0,\n    'score': 0.9099769592285156}]}]</pre> In\u00a0[33]: Copied! <pre>ultralytics_hub.get_inference_state()\n</pre> ultralytics_hub.get_inference_state() Out[33]: <pre>{'status': 'success',\n 'error_type': None,\n 'error_msg': None,\n 'step': 26,\n 'total_step': 26}</pre> In\u00a0[34]: Copied! <pre>ultralytics_hub.export_onnx()\n</pre> ultralytics_hub.export_onnx() <pre>/home/snuailab/anaconda3/envs/waffle-refactor/lib/python3.10/site-packages/ultralytics/nn/modules/head.py:49: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  elif self.dynamic or self.shape != shape:\n/home/snuailab/anaconda3/envs/waffle-refactor/lib/python3.10/site-packages/ultralytics/utils/tal.py:254: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n  for i, stride in enumerate(strides):\n/home/snuailab/anaconda3/envs/waffle-refactor/lib/python3.10/site-packages/torch/onnx/utils.py:617: UserWarning: ONNX Preprocess - Removing mutation from node aten::sub_ on block input: 'tensor.1'. This changes graph semantics. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp:335.)\n  _C._jit_pass_onnx_remove_inplace_ops_for_onnx(graph, module)\n</pre> Out[34]: <pre>ExportOnnxResult(onnx_file=PosixPath('hubs/ultralytics_mnist_detection/weights/model.onnx'))</pre> In\u00a0[35]: Copied! <pre>ultralytics_hub.benchmark()\n</pre> ultralytics_hub.benchmark() <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:03&lt;00:00, 32.73it/s]\n</pre> Out[35]: <pre>{'inference_time': 3.0563507080078125,\n 'fps': 523.5001323008871,\n 'image_size': [640, 640],\n 'batch_size': 16,\n 'precision': 'fp32',\n 'device': 'cuda:0',\n 'cpu_name': 'Intel(R) Core(TM) i7-10700K CPU @ 3.80GHz',\n 'gpu_name': 'NVIDIA GeForce RTX 3070'}</pre> In\u00a0[37]: Copied! <pre>ultralytics_hub.export_waffle()\n</pre> ultralytics_hub.export_waffle() Out[37]: <pre>ExportWaffleResult(waffle_file=PosixPath('hubs/ultralytics_mnist_detection/ultralytics_mnist_detection.waffle'))</pre> In\u00a0[38]: Copied! <pre>ultralytics_hub.get_export_waffle_state()\n</pre> ultralytics_hub.get_export_waffle_state() Out[38]: <pre>{'status': 'success',\n 'error_type': None,\n 'error_msg': None,\n 'step': None,\n 'total_step': None}</pre> In\u00a0[41]: Copied! <pre>import_hub = Hub.from_waffle_file(\n    name=\"waffle_mnist_detection\",\n    waffle_file=\"hubs/ultralytics_mnist_detection/ultralytics_mnist_detection.waffle\",\n)\n</pre> import_hub = Hub.from_waffle_file(     name=\"waffle_mnist_detection\",     waffle_file=\"hubs/ultralytics_mnist_detection/ultralytics_mnist_detection.waffle\", ) In\u00a0[42]: Copied! <pre>import_hub.inference(\n    source=\"datasets/mnist_det/raw/10.png\",\n    draw=True,\n)\nPIL.Image.open(ultralytics_hub.draw_dir / \"10.png\")\n</pre> import_hub.inference(     source=\"datasets/mnist_det/raw/10.png\",     draw=True, ) PIL.Image.open(ultralytics_hub.draw_dir / \"10.png\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00,  5.32it/s]\n</pre> Out[42]:"},{"location":"tutorials/hub/using_hub/#hub","title":"Hub\u00b6","text":"<p>Hub provides same interface for several backends. Let see how it works.</p>"},{"location":"tutorials/hub/using_hub/#select-backends","title":"Select Backends\u00b6","text":"<p>You can check what frameworks and models the <code>waffle_hub</code> provides.</p>"},{"location":"tutorials/hub/using_hub/#ultraytics","title":"Ultraytics\u00b6","text":""},{"location":"tutorials/hub/using_hub/#transformers","title":"Transformers\u00b6","text":""},{"location":"tutorials/hub/using_hub/#autocare-dlt","title":"Autocare DLT\u00b6","text":""},{"location":"tutorials/hub/using_hub/#create-new-hub-ultraytics","title":"Create New Hub (Ultraytics)\u00b6","text":"<p>By calling <code>Hub.new()</code> method you can simply create an hub instance.</p> <p></p>"},{"location":"tutorials/hub/using_hub/#create-transformershuggingface-hub","title":"Create transformers(huggingface) Hub\u00b6","text":""},{"location":"tutorials/hub/using_hub/#create-autocaredlt-hub","title":"Create AutocareDLT Hub\u00b6","text":"<p><code>AutocareDLT</code> Model is a private deep learning framework of SNUAILAB. You can use it by asking our team!  You can also create <code>AutocareDLT</code> Hub instance with exactly same way.</p> <p></p>"},{"location":"tutorials/hub/using_hub/#train","title":"Train\u00b6","text":""},{"location":"tutorials/hub/using_hub/#load-dataset","title":"Load Dataset\u00b6","text":"<p>To be replaced (with waffle_dough)</p>"},{"location":"tutorials/hub/using_hub/#train","title":"train\u00b6","text":""},{"location":"tutorials/hub/using_hub/#get-train-infomations","title":"get train infomations\u00b6","text":""},{"location":"tutorials/hub/using_hub/#evaluate","title":"Evaluate\u00b6","text":""},{"location":"tutorials/hub/using_hub/#get-evaluate-informations","title":"get evaluate informations\u00b6","text":""},{"location":"tutorials/hub/using_hub/#inference","title":"Inference\u00b6","text":""},{"location":"tutorials/hub/using_hub/#get-inference-informations","title":"get inference informations\u00b6","text":""},{"location":"tutorials/hub/using_hub/#export-to-onnx","title":"Export to onnx\u00b6","text":""},{"location":"tutorials/hub/using_hub/#benchmark","title":"Benchmark\u00b6","text":""},{"location":"tutorials/hub/using_hub/#export-to-waffle-file","title":"Export to waffle file\u00b6","text":""},{"location":"tutorials/hub/using_hub/#import-waffle-file","title":"import waffle file\u00b6","text":""},{"location":"tutorials/hubs/ultralytics_mnist_detection/ultralytics_train/","title":"Ultralytics train","text":"In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n        from ultralytics import YOLO\n        import os\n        os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n        try:\n            model = YOLO(\"yolov8n.pt\", task=\"detect\")\n            model.train(\n                **{'data': '/home/snuailab/Desktop/waffle_hub/docs/tutorials/datasets/mnist_det/exports/ULTRALYTICS/data.yaml', 'epochs': 50, 'batch': 4, 'imgsz': [640, 640], 'lr0': 0.01, 'lrf': 0.01, 'rect': False, 'device': '0', 'workers': 2, 'seed': 0, 'verbose': True, 'project': 'hubs/ultralytics_mnist_detection', 'name': 'artifacts'}\n            )\n        except Exception as e:\n            print(e)\n            raise e\n</pre> if __name__ == \"__main__\":         from ultralytics import YOLO         import os         os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"         try:             model = YOLO(\"yolov8n.pt\", task=\"detect\")             model.train(                 **{'data': '/home/snuailab/Desktop/waffle_hub/docs/tutorials/datasets/mnist_det/exports/ULTRALYTICS/data.yaml', 'epochs': 50, 'batch': 4, 'imgsz': [640, 640], 'lr0': 0.01, 'lrf': 0.01, 'rect': False, 'device': '0', 'workers': 2, 'seed': 0, 'verbose': True, 'project': 'hubs/ultralytics_mnist_detection', 'name': 'artifacts'}             )         except Exception as e:             print(e)             raise e"},{"location":"waffle_hub/","title":"Waffle Hub","text":"<p><code>Waffle Hub</code> provide two key component classes: <code>Hub</code> and <code>Dataset</code>.</p>"},{"location":"waffle_hub/#hub","title":"Hub","text":"<p><code>Hub</code> provides same interface for various powerfull Deep Learning Frameworks. Here is our brief system architecture.</p> <p></p> <p>Each input and output adapter is responsible for converting our interface to the framework's interface. For example, <code>Ultralytics</code> uses <code>imgsz</code> for image size parameter, but <code>detectron2</code> uses <code>IMAGE_SIZE</code>. So, we need to convert our interface to the framework's interface. <code>waffle_hub</code> provides <code>InputAdapter</code> and <code>OutputAdapter</code> for this purpose.</p>"},{"location":"waffle_hub/#dataset","title":"Dataset","text":"<p><code>Dataset</code> class support many types of data format such as <code>coco</code>, <code>yolo</code>. You can use it to convert dataset or manage dataset.</p>"},{"location":"waffle_hub/dataset/dataset/","title":"Dataset","text":""},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.add_annotations","title":"<code>add_annotations(annotations)</code>","text":"<p>Add \"Annotation\"s to dataset.</p> <p>Parameters:</p> Name Type Description Default <code>annotations</code> <code>Union[Annotation, list[Annotation]]</code> <p>list of \"Annotation\"s</p> required"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.add_categories","title":"<code>add_categories(categories)</code>","text":"<p>Add \"Category\"s to dataset.</p> <p>Parameters:</p> Name Type Description Default <code>categories</code> <code>Union[Category, list[Category]]</code> <p>list of \"Category\"s</p> required"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.add_images","title":"<code>add_images(images)</code>","text":"<p>Add \"Image\"s to dataset.</p> <p>Parameters:</p> Name Type Description Default <code>images</code> <code>Union[Image, list[Image]]</code> <p>list of \"Image\"s</p> required"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.add_predictions","title":"<code>add_predictions(predictions)</code>","text":"<p>Add \"Annotation\"s to dataset.</p> <p>Parameters:</p> Name Type Description Default <code>annotations</code> <code>Union[Annotation, list[Annotation]]</code> <p>list of \"Annotation\"s</p> required"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.clone","title":"<code>clone(src_name, name, src_root_dir=None, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Clone Existing Dataset. This method clones an existing dataset.</p> <p>Parameters:</p> Name Type Description Default <code>src_name</code> <code>str</code> <p>Dataset name to clone. It should be Waffle Created Dataset.</p> required <code>name</code> <code>str</code> <p>New Dataset name</p> required <code>src_root_dir</code> <code>str</code> <p>Source Dataset root directory. Defaults to None.</p> <code>None</code> <code>root_dir</code> <code>str</code> <p>New Dataset root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if source dataset does not exist.</p> <code>FileExistsError</code> <p>if new dataset name already exist.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = Dataset.clone(\"my_dataset\", \"my_dataset_clone\")\n&gt;&gt;&gt; ds.name\n'my_dataset_clone'  # cloned dataset name\n&gt;&gt;&gt; ds.task\n'CLASSIFICATION'   # original dataset task\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.create_index","title":"<code>create_index()</code>","text":"<p>Create index for faster search.</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.delete","title":"<code>delete()</code>","text":"<p>Delete Dataset</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.draw_annotations","title":"<code>draw_annotations(image_ids=None)</code>","text":"<p>Draw annotations on images Save drawn images to draw_dir</p> <p>Parameters:</p> Name Type Description Default <code>image_ids</code> <code>list[int]</code> <p>image ids to draw. Defaults to None.</p> <code>None</code>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.dummy","title":"<code>dummy(name, task, image_num=100, category_num=10, unlabeled_image_num=0, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Create Dummy Dataset (for debugging).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>task</code> <code>str</code> <p>Dataset task</p> required <code>image_num</code> <code>int</code> <p>Number of images. Defaults to 100.</p> <code>100</code> <code>category_num</code> <code>int</code> <p>Number of categories. Defaults to 10.</p> <code>10</code> <code>unlabeld_image_num</code> <code>int</code> <p>Number of unlabeled images. Defaults to 0.</p> required <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>if dataset name already exists</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = Dataset.dummy(\"my_dataset\", \"CLASSIFICATION\", image_num=100, category_num=10)\n&gt;&gt;&gt; len(ds.get_images())\n100\n&gt;&gt;&gt; len(ds.get_categories())\n10\n</code></pre>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.export","title":"<code>export(data_type)</code>","text":"<p>Export Dataset to Specific data formats</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>Union[str, DataType]</code> <p>export data type. one of [\"YOLO\", \"COCO\"].</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if data_type is not one of DataType.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = Dataset.load(\"some_dataset\")\n&gt;&gt;&gt; dataset.export(data_type=\"YOLO\")\npath/to/dataset_dir/exports/yolo\n</code></pre>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.export--you-can-train-with-exported-dataset","title":"You can train with exported dataset","text":"<pre><code>&gt;&gt;&gt; hub.train(\"path/to/dataset_dir/exports/yolo\", ...)\n</code></pre> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>exported dataset directory</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.extract_by_categories","title":"<code>extract_by_categories(new_name, category_ids, root_dir=None)</code>","text":"<p>Extract a new dataset by categories</p> <p>Parameters:</p> Name Type Description Default <code>new_name</code> <code>str</code> <p>Name of the new dataset</p> required <code>category_ids</code> <code>list[int]</code> <p>Category IDs to extract</p> required <code>root_dir</code> <code>str</code> <p>Root directory of the new dataset. Defaults to None.</p> <code>None</code> <p>Returns (Dataset): New dataset</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.extract_by_image_ids","title":"<code>extract_by_image_ids(new_name, image_ids, root_dir=None)</code>","text":"<p>Extract a new dataset by image ids</p> <p>Parameters:</p> Name Type Description Default <code>new_name</code> <code>str</code> <p>Name of the new dataset</p> required <code>image_ids</code> <code>list[int]</code> <p>Image ids to extract</p> required <code>root_dir</code> <code>str</code> <p>Root directory of the new dataset. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Extracted dataset</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.from_autocare_dlt","title":"<code>from_autocare_dlt(name, task, coco_file, coco_root_dir, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Import dataset from autocare dlt format. This method is used for importing dataset from autocare dlt format.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of dataset.</p> required <code>task</code> <code>str</code> <p>task of dataset.</p> required <code>coco_file</code> <code>Union[str, list[str]]</code> <p>coco annotation file path.</p> required <code>coco_root_dir</code> <code>Union[str, list[str]]</code> <p>root directory of coco dataset.</p> required <code>root_dir</code> <code>str</code> <p>root directory of dataset. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>if new dataset name already exist.</p> <p>Examples:</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.from_autocare_dlt--import-one-coco-json-file","title":"Import one coco json file.","text":"<pre><code>&gt;&gt;&gt; ds = Dataset.from_coco(\"my_dataset\", \"object_detection\", \"path/to/coco.json\", \"path/to/coco_root\")\n&gt;&gt;&gt; ds.get_images()\n{&lt;Image: 1&gt;, &lt;Image: 2&gt;, &lt;Image: 3&gt;, &lt;Image: 4&gt;, &lt;Image: 5&gt;}\n&gt;&gt;&gt; ds.get_annotations()\n{&lt;Annotation: 1&gt;, &lt;Annotation: 2&gt;, &lt;Annotation: 3&gt;, &lt;Annotation: 4&gt;, &lt;Annotation: 5&gt;}\n&gt;&gt;&gt; ds.get_categories()\n{&lt;Category: 1&gt;, &lt;Category: 2&gt;, &lt;Category: 3&gt;, &lt;Category: 4&gt;, &lt;Category: 5&gt;}\n&gt;&gt;&gt; ds.get_category_names()\n['person', 'bicycle', 'car', 'motorcycle', 'airplane']\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class.</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.from_coco","title":"<code>from_coco(name, task, coco_file, coco_root_dir, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Import Dataset from coco format. This method imports coco format dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name.</p> required <code>task</code> <code>str</code> <p>Dataset task.</p> required <code>coco_file</code> <code>Union[str, list[str]]</code> <p>Coco json file path. If given list, it will be regarded as [train, val, test] json file.</p> required <code>coco_root_dir</code> <code>Union[str, list[str]]</code> <p>Coco image root directory. If given list, it will be regarded as [train, val, test] coco root file.</p> required <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>if new dataset name already exist.</p> <p>Examples:</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.from_coco--import-one-coco-json-file","title":"Import one coco json file.","text":"<pre><code>&gt;&gt;&gt; ds = Dataset.from_coco(\"my_dataset\", \"object_detection\", \"path/to/coco.json\", \"path/to/coco_root\")\n&gt;&gt;&gt; ds.get_images()\n{&lt;Image: 1&gt;, &lt;Image: 2&gt;, &lt;Image: 3&gt;, &lt;Image: 4&gt;, &lt;Image: 5&gt;}\n&gt;&gt;&gt; ds.get_annotations()\n{&lt;Annotation: 1&gt;, &lt;Annotation: 2&gt;, &lt;Annotation: 3&gt;, &lt;Annotation: 4&gt;, &lt;Annotation: 5&gt;}\n&gt;&gt;&gt; ds.get_categories()\n{&lt;Category: 1&gt;, &lt;Category: 2&gt;, &lt;Category: 3&gt;, &lt;Category: 4&gt;, &lt;Category: 5&gt;}\n&gt;&gt;&gt; ds.get_category_names()\n['person', 'bicycle', 'car', 'motorcycle', 'airplane']\n</code></pre>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.from_coco--import-multiple-coco-json-files","title":"Import multiple coco json files.","text":""},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.from_coco--you-can-give-coco_file-as-list","title":"You can give coco_file as list.","text":""},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.from_coco--given-coco-files-are-regarded-as-train-val-test-json-files","title":"Given coco files are regarded as [train, [val, [test]]] json files.","text":"<pre><code>&gt;&gt;&gt; ds = Dataset.from_coco(\"my_dataset\", \"object_detection\", [\"coco_train.json\", \"coco_val.json\"], [\"coco_train_root\", \"coco_val_root\"])\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.from_label_studio","title":"<code>from_label_studio(name, task, json_file, image_dir=None, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Import Dataset from label_studio format. This method imports dataset from label_studio exported json file (the first one).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name.</p> required <code>task</code> <code>str</code> <p>Dataset task.</p> required <code>json_file</code> <code>str</code> <p>Label studio json file path.</p> required <code>image_dir</code> <code>str</code> <p>Label studio image directory.</p> <code>None</code> <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = Dataset.from_label_studio(\n    \"label_studio\",\n    \"classification\",\n    \"path/to/label_studio/json/export/file.json\",\n    \"path/to/image_dir\"\n)\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Imported dataset.</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.from_transformers","title":"<code>from_transformers(name, task, dataset_dir, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Import Dataset from transformers datasets. This method imports transformers dataset from directory.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name.</p> required <code>dataset_dir</code> <code>str</code> <p>Transformers dataset directory.</p> required <code>task</code> <code>str</code> <p>Task name.</p> required <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>if dataset name already exists</p> <code>ValueError</code> <p>if dataset is not Dataset or DatasetDict</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = Dataset.from_transformers(\"transformers\", \"object_detection\", \"path/to/transformers/dataset\")\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.from_yolo","title":"<code>from_yolo(name, task, yolo_root_dir, yaml_path=None, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Import Dataset from yolo format. This method imports dataset from yolo(ultralytics) yaml file.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name.</p> required <code>task</code> <code>str</code> <p>Dataset task.</p> required <code>yolo_root_dir</code> <code>str</code> <p>Yolo dataset root directory.</p> required <code>yaml_path</code> <code>str</code> <p>Yolo yaml file path. when task is classification, yaml_path is not required.</p> <code>None</code> <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = Dataset.from_yolo(\"yolo\", \"classification\", \"path/to/yolo_root_dir\")\n&gt;&gt;&gt; ds = Dataset.from_yolo(\"yolo\", \"object_detection\", \"path/to/yolo_root_dir\", \"path/to/yolo.yaml\")\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Imported dataset.</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.get_annotations","title":"<code>get_annotations(image_id=None)</code>","text":"<p>Get \"Annotation\"s.</p> <p>Parameters:</p> Name Type Description Default <code>image_id</code> <code>int</code> <p>image id. None for all \"Annotation\"s. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Annotation]</code> <p>list[Annotation]: \"Annotation\" list</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.get_categories","title":"<code>get_categories(category_ids=None)</code>","text":"<p>Get \"Category\"s.</p> <p>Parameters:</p> Name Type Description Default <code>category_ids</code> <code>list[int]</code> <p>id list. None for all \"Category\"s. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Category]</code> <p>list[Category]: \"Category\" list</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.get_dataset_info","title":"<code>get_dataset_info()</code>","text":"<p>Get DatasetInfo.</p> <p>Returns:</p> Name Type Description <code>DatasetInfo</code> <code>DatasetInfo</code> <p>DatasetInfo</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.get_dataset_list","title":"<code>get_dataset_list(root_dir=None)</code>  <code>classmethod</code>","text":"<p>Get dataset name list in root_dir.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>str</code> <p>dataset root directory. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: dataset name list.</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.get_images","title":"<code>get_images(image_ids=None, labeled=True)</code>","text":"<p>Get \"Image\"s.</p> <p>Parameters:</p> Name Type Description Default <code>image_ids</code> <code>list[int]</code> <p>id list. None for all \"Image\"s. Defaults to None.</p> <code>None</code> <code>labeled</code> <code>bool</code> <p>get labeled images. False for unlabeled images. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[Image]</code> <p>list[Image]: \"Image\" list</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.get_predictions","title":"<code>get_predictions(image_id=None)</code>","text":"<p>Get \"Prediction\"s.</p> <p>Parameters:</p> Name Type Description Default <code>image_id</code> <code>int</code> <p>image id. None for all \"Prediction\"s. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Annotation]</code> <p>list[Annotation]: \"Prediction\" list</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.get_split_ids","title":"<code>get_split_ids()</code>","text":"<p>Get split ids</p> <p>Returns:</p> Type Description <code>list[list[int]]</code> <p>list[list[int]]: split ids</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.initialized","title":"<code>initialized()</code>","text":"<p>Check if Dataset has been initialized or not.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>initialized -&gt; True not initialized -&gt; False</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.load","title":"<code>load(name, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Load Dataset. This method loads an existing dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name that Waffle Created</p> required <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if source dataset does not exist.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = Dataset.load(\"my_dataset\")\n&gt;&gt;&gt; ds.name\n'my_dataset'  # dataset name\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.merge","title":"<code>merge(name, root_dir, src_names, src_root_dirs, task)</code>  <code>classmethod</code>","text":"<p>Merge Datasets. This method merges multiple datasets into one dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>New Dataset name</p> required <code>root_dir</code> <code>str</code> <p>New Dataset root directory</p> required <code>src_names</code> <code>list[str]</code> <p>Source Dataset names</p> required <code>src_root_dirs</code> <code>Union[str, list[str]]</code> <p>Source Dataset root directories</p> required <code>task</code> <code>str</code> <p>Dataset task</p> required <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.new","title":"<code>new(name, task, categories=None, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Create New Dataset. This method creates a new dataset directory and initialize dataset info file. If you have other types of data, you can use from_* methods to create a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>task</code> <code>str</code> <p>Dataset task</p> required <code>categories</code> <code>list[Union[str, int, float, dict, Category]]</code> <p>Dataset categories</p> <code>None</code> <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>if dataset name already exists</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ds = Dataset.new(\"my_dataset\", \"CLASSIFICATION\")\n&gt;&gt;&gt; ds.name\n'my_dataset'  # dataset name\n&gt;&gt;&gt; ds.task  # dataset task\n'CLASSIFICATION'\n</code></pre> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.sample","title":"<code>sample(name, task, root_dir=None)</code>  <code>classmethod</code>","text":"<p>Import sample Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name.</p> required <code>task</code> <code>str</code> <p>Task name.</p> required <code>root_dir</code> <code>str</code> <p>Dataset root directory. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Dataset</code> <code>Dataset</code> <p>Dataset Class</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.save_dataset_info","title":"<code>save_dataset_info()</code>","text":"<p>Save DatasetInfo.</p>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.split","title":"<code>split(train_ratio, val_ratio=0.0, test_ratio=0.0, method=SplitMethod.RANDOM, seed=0)</code>","text":"<p>Split Dataset to train, validation, test, (unlabeled) sets.</p> <p>Parameters:</p> Name Type Description Default <code>train_ratio</code> <code>float</code> <p>train num ratio (0 ~ 1).</p> required <code>val_ratio</code> <code>float</code> <p>val num ratio (0 ~ 1).</p> <code>0.0</code> <code>test_ratio</code> <code>float</code> <p>test num ratio (0 ~ 1).</p> <code>0.0</code> <code>method</code> <code>Union[str, SplitMethod]</code> <p>split method. Defaults to SplitMethod.RANDOM.</p> <code>RANDOM</code> <code>seed</code> <code>int</code> <p>random seed. Defaults to 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if train_ratio is not between 0.0 and 1.0.</p> <code>ValueError</code> <p>if train_ratio + val_ratio + test_ratio is not 1.0.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = Dataset.load(\"some_dataset\")\n&gt;&gt;&gt; dataset.split(train_ratio=0.8, val_ratio=0.1, test_ratio=0.1)\n&gt;&gt;&gt; dataset.get_split_ids()\n[[1, 2, 3, 4, 5, 6, 7, 8], [9], [10], []]  # train, val, test, unlabeled image ids\n</code></pre>"},{"location":"waffle_hub/dataset/dataset/#waffle_hub.dataset.Dataset.trainable","title":"<code>trainable()</code>","text":"<p>Check if Dataset is trainable or not.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>trainable -&gt; True not trainable -&gt; False</p>"},{"location":"waffle_hub/evaluator/callbacks/","title":"EvaluateCallback","text":"<p>             Bases: <code>BaseCallback</code>, <code>ABC</code></p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>class BaseEvaluateCallback(BaseCallback, ABC):\n    def __init__(self):\n        pass\n\n    def setup(self, evaluator: Evaluator) -&gt; None:\n        \"\"\"Called when worker starts.\"\"\"\n\n    def teardown(self, evaluator: Evaluator) -&gt; None:\n        \"\"\"Called when worker ends.\"\"\"\n\n    def before_evaluate(self, evaluator: Evaluator) -&gt; None:\n        \"\"\"Called when the evaluate begins.\"\"\"\n\n    def on_evaluate_start(self, evaluator: Evaluator) -&gt; None:\n        \"\"\"Called when the evaluate function begins.\"\"\"\n\n    def on_evaluate_loop_start(self, evaluator: Evaluator, dataloader: DataLoader) -&gt; None:\n        \"\"\"Called when the evaluate loop begins.\"\"\"\n\n    def on_evaluate_step_start(self, evaluator: Evaluator, step: int, batch: Any) -&gt; None:\n        \"\"\"Called when the evaluate loop step begins.\"\"\"\n\n    def on_evaluate_step_end(\n        self, evaluator: Evaluator, step: int, batch: Any, result_batch: Any\n    ) -&gt; None:\n        \"\"\"Called when the evaluate loop step ends.\"\"\"\n\n    def on_evaluate_loop_end(self, evaluator: Evaluator, preds: Any) -&gt; None:\n        \"\"\"Called when the evaluate loop ends.\"\"\"\n\n    def on_evaluate_end(self, evaluator: Evaluator, result_metrics: list[dict]) -&gt; None:\n        \"\"\"Called when the evaluate function ends.\"\"\"\n\n    def after_evaluate(self, evaluator: Evaluator) -&gt; None:\n        \"\"\"Called when the evaluate ends.\"\"\"\n\n    def on_exception_stopped(self, evaluator: Evaluator, e: Exception) -&gt; None:\n        \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n\n    def on_exception_failed(self, evaluator: Evaluator, e: Exception) -&gt; None:\n        \"\"\"Called when an error occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.after_evaluate","title":"<code>after_evaluate(evaluator)</code>","text":"<p>Called when the evaluate ends.</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def after_evaluate(self, evaluator: Evaluator) -&gt; None:\n    \"\"\"Called when the evaluate ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.before_evaluate","title":"<code>before_evaluate(evaluator)</code>","text":"<p>Called when the evaluate begins.</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def before_evaluate(self, evaluator: Evaluator) -&gt; None:\n    \"\"\"Called when the evaluate begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.on_evaluate_end","title":"<code>on_evaluate_end(evaluator, result_metrics)</code>","text":"<p>Called when the evaluate function ends.</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def on_evaluate_end(self, evaluator: Evaluator, result_metrics: list[dict]) -&gt; None:\n    \"\"\"Called when the evaluate function ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.on_evaluate_loop_end","title":"<code>on_evaluate_loop_end(evaluator, preds)</code>","text":"<p>Called when the evaluate loop ends.</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def on_evaluate_loop_end(self, evaluator: Evaluator, preds: Any) -&gt; None:\n    \"\"\"Called when the evaluate loop ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.on_evaluate_loop_start","title":"<code>on_evaluate_loop_start(evaluator, dataloader)</code>","text":"<p>Called when the evaluate loop begins.</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def on_evaluate_loop_start(self, evaluator: Evaluator, dataloader: DataLoader) -&gt; None:\n    \"\"\"Called when the evaluate loop begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.on_evaluate_start","title":"<code>on_evaluate_start(evaluator)</code>","text":"<p>Called when the evaluate function begins.</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def on_evaluate_start(self, evaluator: Evaluator) -&gt; None:\n    \"\"\"Called when the evaluate function begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.on_evaluate_step_end","title":"<code>on_evaluate_step_end(evaluator, step, batch, result_batch)</code>","text":"<p>Called when the evaluate loop step ends.</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def on_evaluate_step_end(\n    self, evaluator: Evaluator, step: int, batch: Any, result_batch: Any\n) -&gt; None:\n    \"\"\"Called when the evaluate loop step ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.on_evaluate_step_start","title":"<code>on_evaluate_step_start(evaluator, step, batch)</code>","text":"<p>Called when the evaluate loop step begins.</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def on_evaluate_step_start(self, evaluator: Evaluator, step: int, batch: Any) -&gt; None:\n    \"\"\"Called when the evaluate loop step begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.on_exception_failed","title":"<code>on_exception_failed(evaluator, e)</code>","text":"<p>Called when an error occurs</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def on_exception_failed(self, evaluator: Evaluator, e: Exception) -&gt; None:\n    \"\"\"Called when an error occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.on_exception_stopped","title":"<code>on_exception_stopped(evaluator, e)</code>","text":"<p>Called when SIGTERM or SIGINT occurs</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def on_exception_stopped(self, evaluator: Evaluator, e: Exception) -&gt; None:\n    \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.setup","title":"<code>setup(evaluator)</code>","text":"<p>Called when worker starts.</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def setup(self, evaluator: Evaluator) -&gt; None:\n    \"\"\"Called when worker starts.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/callbacks/#waffle_hub.hub.evaluator.callbacks.BaseEvaluateCallback.teardown","title":"<code>teardown(evaluator)</code>","text":"<p>Called when worker ends.</p> Source code in <code>waffle_hub/hub/evaluator/callbacks/base_callback.py</code> <pre><code>def teardown(self, evaluator: Evaluator) -&gt; None:\n    \"\"\"Called when worker ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/evaluator/","title":"Evaluator","text":"<p>             Bases: <code>BaseEvaluateHook</code></p> <p>Evaluation manager class</p> Source code in <code>waffle_hub/hub/evaluator/evaluator.py</code> <pre><code>class Evaluator(BaseEvaluateHook):\n    \"\"\"\n    Evaluation manager class\n    \"\"\"\n\n    # evaluate results file name\n    EVALUATE_FILE = \"evaluate.json\"\n\n    def __init__(\n        self,\n        root_dir: Path,\n        model: ModelWrapper,\n        callbacks: list[BaseCallback] = None,\n    ):\n        super().__init__(callbacks)\n        self.root_dir = Path(root_dir)\n        self.model = model\n\n        # state\n        self.state = EvaluateState(status=EvaluateStatus.INIT)\n        # result\n        self.result = EvaluateResult()\n\n    @property\n    def evaluate_file(self) -&gt; Path:\n        \"\"\"Evaluate File\"\"\"\n        return self.root_dir / self.EVALUATE_FILE\n\n    @classmethod\n    def get_evaluate_result(cls, root_dir: Union[str, Path]) -&gt; list[dict]:\n        \"\"\"Get evaluate result from evaluate file.\n\n        Args:\n            root_dir (Union[str, Path]): root directory of evaluate file\n\n        Examples:\n            &gt;&gt;&gt; Evaluator.get_evaluate_result()\n            [\n                {\n                    \"tag\": \"mAP\",\n                    \"value\": 0.5,\n                },\n            ]\n\n        Returns:\n            list[dict]: evaluate result\n        \"\"\"\n        evluate_file_path = Path(root_dir) / cls.EVALUATE_FILE\n        if not evluate_file_path.exists():\n            warnings.warn(f\"Evaluate file {evluate_file_path} is not exist. Evaluate First.\")\n            return []\n        return io.load_json(evluate_file_path)\n\n    # methods\n    @device_context\n    def evaluate(\n        self,\n        dataset: Union[Dataset, Path, str],\n        dataset_root_dir: Union[Path, str] = None,\n        set_name: str = \"test\",\n        batch_size: int = 4,\n        image_size: Union[int, list[int]] = [640, 640],\n        letter_box: bool = True,\n        confidence_threshold: float = 0.25,\n        iou_threshold: float = 0.5,\n        half: bool = False,\n        workers: int = 2,\n        device: str = \"0\",\n    ) -&gt; EvaluateResult:\n        \"\"\"Start Evaluate\n\n        Args:\n            dataset (Union[Dataset, Path, str]): Waffle Dataset object or path or name.\n            dataset_root_dir (Union[Path, str], optional): Waffle Dataset root directory. Defaults to None.\n            set_name (str, optional): Eval set name. Defaults to \"test\".\n            batch_size (int, optional): batch size. Defaults to 4.\n            image_size (Union[int, list[int]], optional): image size. Defaults to [640, 640].\n            letter_box (bool, optional): letter box. Defaults to True.\n            confidence_threshold (float, optional): confidence threshold. Defaults to 0.25.\n            iou_threshold (float, optional): iou threshold. Defaults to 0.5.\n            half (bool, optional): half. Defaults to False.\n            workers (int, optional): workers. Defaults to 2.\n            device (str, optional): device. Defaults to \"0\".\n\n        Raises:\n            FileNotFoundError: if can not detect appropriate dataset.\n\n        Examples:\n            &gt;&gt;&gt; evaluate_result = hub.evaluate(\n                    dataset=detection_dataset,\n                    batch_size=4,\n                    image_size=640,\n                    letterbox=False,\n                    confidence_threshold=0.25,\n                    iou_threshold=0.5,\n                    workers=4,\n                    device=\"0\",\n                )\n            # or you can use train option by passing None\n            &gt;&gt;&gt; evaluate_result = hub.evaluate(\n                    ...\n                    image_size=None,  # use train option\n                    letterbox=None,  # use train option\n                    ...\n                )\n            &gt;&gt;&gt; evaluate_result.metrics\n            [{\"tag\": \"mAP\", \"value\": 0.1}, ...]\n\n        Returns:\n            EvaluateResult: evaluate result\n        \"\"\"\n\n        try:\n            self.run_default_hook(\"setup\")\n            self.run_callback_hooks(\"setup\", self)\n\n            # load dataset\n            if isinstance(dataset, (str, Path)):\n                dataset = self._load_dataset(dataset, dataset_root_dir)\n\n            self.is_valid_dataset(dataset)\n\n            # config setting\n            # check device\n            if \",\" in device:\n                warnings.warn(\"multi-gpu is not supported in evaluation. use first gpu only.\")\n                device = device.split(\",\")[0]\n\n            if set_name == \"test\" and len(dataset.get_split_ids()[2]) == 0:\n                set_name = \"val\"\n                # logger.warning(\"test set is not exist. use val set instead.\")\n\n            self.cfg = EvaluateConfig(\n                dataset_name=dataset.name,\n                dataset_root_dir=dataset.root_dir,\n                set_name=set_name,\n                batch_size=batch_size,\n                image_size=image_size if isinstance(image_size, list) else [image_size, image_size],\n                letter_box=letter_box,\n                confidence_threshold=confidence_threshold,\n                iou_threshold=iou_threshold,\n                half=half,\n                workers=workers,\n                device=\"cpu\" if device == \"cpu\" else f\"cuda:{device}\",\n            )\n\n            self.run_default_hook(\"before_evaluate\")\n            self.run_callback_hooks(\"before_evaluate\", self)\n\n            # evaluate run\n            self._evaluate(dataset)\n\n            self.run_default_hook(\"after_evaluate\")\n            self.run_callback_hooks(\"after_evaluate\", self)\n\n        except (KeyboardInterrupt, SystemExit) as e:\n            self.run_default_hook(\"on_exception_stopped\", e)\n            self.run_callback_hooks(\"on_exception_stopped\", self, e)\n            raise e\n        except Exception as e:\n            self.run_default_hook(\"on_exception_failed\", e)\n            self.run_callback_hooks(\"on_exception_failed\", self, e)\n            if self.evaluate_file.exists():\n                io.remove_file(self.evaluate_file)\n            raise e\n        finally:\n            self.run_default_hook(\"teardown\")\n            self.run_callback_hooks(\"teardown\", self)\n\n        return self.result\n\n    def _load_dataset(self, dataset: Union[str, Path], dataset_root_dir: str) -&gt; Dataset:\n        if Path(dataset).exists():\n            dataset = Path(dataset)\n            dataset = Dataset.load(name=dataset.parts[-1], root_dir=dataset.parents[0].absolute())\n        elif dataset in Dataset.get_dataset_list(dataset_root_dir):\n            dataset = Dataset.load(name=dataset, root_dir=dataset_root_dir)\n        else:\n            raise FileNotFoundError(f\"Dataset {dataset} is not exist.\")\n        return dataset\n\n    def _evaluate(self, dataset: Dataset):\n        self.run_default_hook(\"on_evaluate_start\")\n        self.run_callback_hooks(\"on_evaluate_start\", self)\n\n        device = self.cfg.device\n        model = self.model.to(device)\n        dataloader = get_dataset_class(\"dataset\")(\n            dataset,\n            self.cfg.image_size,\n            letter_box=self.cfg.letter_box,\n            set_name=self.cfg.set_name,\n        ).get_dataloader(self.cfg.batch_size, self.cfg.workers)\n\n        result_parser = get_parser(self.model.task)(\n            **self.cfg.to_dict(), categories=dataset.get_categories()\n        )\n\n        self.run_default_hook(\"on_evaluate_loop_start\", dataloader)\n        self.run_callback_hooks(\"on_evaluate_loop_start\", self, dataloader)\n\n        preds = []\n        labels = []\n        for i, batch in tqdm.tqdm(enumerate(dataloader, start=1), total=len(dataloader)):\n            self.run_default_hook(\"on_evaluate_step_start\", i, batch)\n            self.run_callback_hooks(\"on_evaluate_step_start\", self, i, batch)\n            images, image_infos, annotations = batch\n\n            result_batch = model(images.to(device))\n            result_batch = result_parser(result_batch, image_infos)\n\n            preds.extend(result_batch)\n            labels.extend(annotations)\n\n            self.run_default_hook(\"on_evaluate_step_end\", i, batch, result_batch)\n            self.run_callback_hooks(\"on_evaluate_step_end\", self, i, batch, result_batch)\n\n        self.run_default_hook(\"on_evaluate_loop_end\", preds)\n        self.run_callback_hooks(\"on_evaluate_loop_end\", self, preds)\n\n        metrics = evaluate_function(\n            preds,\n            labels,\n            self.model.task,\n            len(dataset.get_categories()),\n            image_size=self.cfg.image_size,\n        )\n        result_metrics = []\n        for tag, value in metrics.to_dict().items():\n            if isinstance(value, list):\n                values = [\n                    {\n                        \"class_name\": cat,\n                        \"value\": cat_value,\n                    }\n                    for cat, cat_value in zip(dataset.get_category_names(), value)\n                ]\n            else:\n                values = value\n            result_metrics.append({\"tag\": tag, \"value\": values})\n        io.save_json(result_metrics, self.evaluate_file)\n\n        self.run_default_hook(\"on_evaluate_end\", result_metrics)\n        self.run_callback_hooks(\"on_evaluate_end\", self, result_metrics)\n\n    def is_valid_dataset(self, dataset: Dataset) -&gt; bool:\n        \"\"\"Check dataset is valid for model.\n\n        Args:\n            dataset (Dataset): dataset\n\n        Returns:\n            bool: is valid\n        \"\"\"\n        # check task\n        if self.model.task != dataset.task:\n            return False\n\n        # check categories\n        if [category.name for category in self.model.categories] != dataset.get_category_names():\n            return False\n\n        return True\n</code></pre>"},{"location":"waffle_hub/evaluator/evaluator/#waffle_hub.hub.evaluator.evaluator.Evaluator.evaluate_file","title":"<code>evaluate_file: Path</code>  <code>property</code>","text":"<p>Evaluate File</p>"},{"location":"waffle_hub/evaluator/evaluator/#waffle_hub.hub.evaluator.evaluator.Evaluator.evaluate","title":"<code>evaluate(dataset, dataset_root_dir=None, set_name='test', batch_size=4, image_size=[640, 640], letter_box=True, confidence_threshold=0.25, iou_threshold=0.5, half=False, workers=2, device='0')</code>","text":"<p>Start Evaluate</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[Dataset, Path, str]</code> <p>Waffle Dataset object or path or name.</p> required <code>dataset_root_dir</code> <code>Union[Path, str]</code> <p>Waffle Dataset root directory. Defaults to None.</p> <code>None</code> <code>set_name</code> <code>str</code> <p>Eval set name. Defaults to \"test\".</p> <code>'test'</code> <code>batch_size</code> <code>int</code> <p>batch size. Defaults to 4.</p> <code>4</code> <code>image_size</code> <code>Union[int, list[int]]</code> <p>image size. Defaults to [640, 640].</p> <code>[640, 640]</code> <code>letter_box</code> <code>bool</code> <p>letter box. Defaults to True.</p> <code>True</code> <code>confidence_threshold</code> <code>float</code> <p>confidence threshold. Defaults to 0.25.</p> <code>0.25</code> <code>iou_threshold</code> <code>float</code> <p>iou threshold. Defaults to 0.5.</p> <code>0.5</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>workers</code> <code>int</code> <p>workers. Defaults to 2.</p> <code>2</code> <code>device</code> <code>str</code> <p>device. Defaults to \"0\".</p> <code>'0'</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if can not detect appropriate dataset.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; evaluate_result = hub.evaluate(\n        dataset=detection_dataset,\n        batch_size=4,\n        image_size=640,\n        letterbox=False,\n        confidence_threshold=0.25,\n        iou_threshold=0.5,\n        workers=4,\n        device=\"0\",\n    )\n# or you can use train option by passing None\n&gt;&gt;&gt; evaluate_result = hub.evaluate(\n        ...\n        image_size=None,  # use train option\n        letterbox=None,  # use train option\n        ...\n    )\n&gt;&gt;&gt; evaluate_result.metrics\n[{\"tag\": \"mAP\", \"value\": 0.1}, ...]\n</code></pre> <p>Returns:</p> Name Type Description <code>EvaluateResult</code> <code>EvaluateResult</code> <p>evaluate result</p> Source code in <code>waffle_hub/hub/evaluator/evaluator.py</code> <pre><code>@device_context\ndef evaluate(\n    self,\n    dataset: Union[Dataset, Path, str],\n    dataset_root_dir: Union[Path, str] = None,\n    set_name: str = \"test\",\n    batch_size: int = 4,\n    image_size: Union[int, list[int]] = [640, 640],\n    letter_box: bool = True,\n    confidence_threshold: float = 0.25,\n    iou_threshold: float = 0.5,\n    half: bool = False,\n    workers: int = 2,\n    device: str = \"0\",\n) -&gt; EvaluateResult:\n    \"\"\"Start Evaluate\n\n    Args:\n        dataset (Union[Dataset, Path, str]): Waffle Dataset object or path or name.\n        dataset_root_dir (Union[Path, str], optional): Waffle Dataset root directory. Defaults to None.\n        set_name (str, optional): Eval set name. Defaults to \"test\".\n        batch_size (int, optional): batch size. Defaults to 4.\n        image_size (Union[int, list[int]], optional): image size. Defaults to [640, 640].\n        letter_box (bool, optional): letter box. Defaults to True.\n        confidence_threshold (float, optional): confidence threshold. Defaults to 0.25.\n        iou_threshold (float, optional): iou threshold. Defaults to 0.5.\n        half (bool, optional): half. Defaults to False.\n        workers (int, optional): workers. Defaults to 2.\n        device (str, optional): device. Defaults to \"0\".\n\n    Raises:\n        FileNotFoundError: if can not detect appropriate dataset.\n\n    Examples:\n        &gt;&gt;&gt; evaluate_result = hub.evaluate(\n                dataset=detection_dataset,\n                batch_size=4,\n                image_size=640,\n                letterbox=False,\n                confidence_threshold=0.25,\n                iou_threshold=0.5,\n                workers=4,\n                device=\"0\",\n            )\n        # or you can use train option by passing None\n        &gt;&gt;&gt; evaluate_result = hub.evaluate(\n                ...\n                image_size=None,  # use train option\n                letterbox=None,  # use train option\n                ...\n            )\n        &gt;&gt;&gt; evaluate_result.metrics\n        [{\"tag\": \"mAP\", \"value\": 0.1}, ...]\n\n    Returns:\n        EvaluateResult: evaluate result\n    \"\"\"\n\n    try:\n        self.run_default_hook(\"setup\")\n        self.run_callback_hooks(\"setup\", self)\n\n        # load dataset\n        if isinstance(dataset, (str, Path)):\n            dataset = self._load_dataset(dataset, dataset_root_dir)\n\n        self.is_valid_dataset(dataset)\n\n        # config setting\n        # check device\n        if \",\" in device:\n            warnings.warn(\"multi-gpu is not supported in evaluation. use first gpu only.\")\n            device = device.split(\",\")[0]\n\n        if set_name == \"test\" and len(dataset.get_split_ids()[2]) == 0:\n            set_name = \"val\"\n            # logger.warning(\"test set is not exist. use val set instead.\")\n\n        self.cfg = EvaluateConfig(\n            dataset_name=dataset.name,\n            dataset_root_dir=dataset.root_dir,\n            set_name=set_name,\n            batch_size=batch_size,\n            image_size=image_size if isinstance(image_size, list) else [image_size, image_size],\n            letter_box=letter_box,\n            confidence_threshold=confidence_threshold,\n            iou_threshold=iou_threshold,\n            half=half,\n            workers=workers,\n            device=\"cpu\" if device == \"cpu\" else f\"cuda:{device}\",\n        )\n\n        self.run_default_hook(\"before_evaluate\")\n        self.run_callback_hooks(\"before_evaluate\", self)\n\n        # evaluate run\n        self._evaluate(dataset)\n\n        self.run_default_hook(\"after_evaluate\")\n        self.run_callback_hooks(\"after_evaluate\", self)\n\n    except (KeyboardInterrupt, SystemExit) as e:\n        self.run_default_hook(\"on_exception_stopped\", e)\n        self.run_callback_hooks(\"on_exception_stopped\", self, e)\n        raise e\n    except Exception as e:\n        self.run_default_hook(\"on_exception_failed\", e)\n        self.run_callback_hooks(\"on_exception_failed\", self, e)\n        if self.evaluate_file.exists():\n            io.remove_file(self.evaluate_file)\n        raise e\n    finally:\n        self.run_default_hook(\"teardown\")\n        self.run_callback_hooks(\"teardown\", self)\n\n    return self.result\n</code></pre>"},{"location":"waffle_hub/evaluator/evaluator/#waffle_hub.hub.evaluator.evaluator.Evaluator.get_evaluate_result","title":"<code>get_evaluate_result(root_dir)</code>  <code>classmethod</code>","text":"<p>Get evaluate result from evaluate file.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>Union[str, Path]</code> <p>root directory of evaluate file</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; Evaluator.get_evaluate_result()\n[\n    {\n        \"tag\": \"mAP\",\n        \"value\": 0.5,\n    },\n]\n</code></pre> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: evaluate result</p> Source code in <code>waffle_hub/hub/evaluator/evaluator.py</code> <pre><code>@classmethod\ndef get_evaluate_result(cls, root_dir: Union[str, Path]) -&gt; list[dict]:\n    \"\"\"Get evaluate result from evaluate file.\n\n    Args:\n        root_dir (Union[str, Path]): root directory of evaluate file\n\n    Examples:\n        &gt;&gt;&gt; Evaluator.get_evaluate_result()\n        [\n            {\n                \"tag\": \"mAP\",\n                \"value\": 0.5,\n            },\n        ]\n\n    Returns:\n        list[dict]: evaluate result\n    \"\"\"\n    evluate_file_path = Path(root_dir) / cls.EVALUATE_FILE\n    if not evluate_file_path.exists():\n        warnings.warn(f\"Evaluate file {evluate_file_path} is not exist. Evaluate First.\")\n        return []\n    return io.load_json(evluate_file_path)\n</code></pre>"},{"location":"waffle_hub/evaluator/evaluator/#waffle_hub.hub.evaluator.evaluator.Evaluator.is_valid_dataset","title":"<code>is_valid_dataset(dataset)</code>","text":"<p>Check dataset is valid for model.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>dataset</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>is valid</p> Source code in <code>waffle_hub/hub/evaluator/evaluator.py</code> <pre><code>def is_valid_dataset(self, dataset: Dataset) -&gt; bool:\n    \"\"\"Check dataset is valid for model.\n\n    Args:\n        dataset (Dataset): dataset\n\n    Returns:\n        bool: is valid\n    \"\"\"\n    # check task\n    if self.model.task != dataset.task:\n        return False\n\n    # check categories\n    if [category.name for category in self.model.categories] != dataset.get_category_names():\n        return False\n\n    return True\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/","title":"EvaluateHook","text":"<p>             Bases: <code>BaseHook</code></p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>class BaseEvaluateHook(BaseHook):\n    def __init__(self, callbacks: list[BaseCallback] = None):\n        super().__init__(callbacks)\n\n    def setup(self) -&gt; None:\n        \"\"\"Called when worker starts.\"\"\"\n        _register_signal_handler()\n\n    def teardown(self) -&gt; None:\n        \"\"\"Called when worker ends.\"\"\"\n\n    def before_evaluate(self) -&gt; None:\n        \"\"\"Called when the evaluate begins.\"\"\"\n\n    def on_evaluate_start(self) -&gt; None:\n        \"\"\"Called when the evaluate function begins.\"\"\"\n        self.state.status = EvaluateStatus.RUNNING\n        self.state.clear_error()\n\n    def on_evaluate_loop_start(self, dataloader: DataLoader) -&gt; None:\n        \"\"\"Called when the evaluate loop begins.\"\"\"\n        self.state.total_step = len(dataloader) + 1\n        self.state.step = 0\n\n    def on_evaluate_step_start(self, step: int, batch: Any) -&gt; None:\n        \"\"\"Called when the evaluate loop step begins.\"\"\"\n\n    def on_evaluate_step_end(self, step: int, batch: Any, result_batch: Any) -&gt; None:\n        \"\"\"Called when the evaluate loop step ends.\"\"\"\n        self.state.step = step\n\n    def on_evaluate_loop_end(self, preds: Any) -&gt; None:\n        \"\"\"Called when the evaluate loop ends.\"\"\"\n\n    def on_evaluate_end(self, result_metrics: list[dict]) -&gt; None:\n        \"\"\"Called when the evaluate function ends.\"\"\"\n        self.result.eval_metrics = result_metrics\n\n    def after_evaluate(self) -&gt; None:\n        \"\"\"Called when the evaluate ends.\"\"\"\n        self.state.step = self.state.total_step\n        self.state.status = EvaluateStatus.SUCCESS\n\n    def on_exception_stopped(self, e: Exception) -&gt; None:\n        \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n        self.state.status = EvaluateStatus.STOPPED\n        self.state.set_error(e)\n\n    def on_exception_failed(self, e: Exception) -&gt; None:\n        \"\"\"Called when an error occurs\"\"\"\n        self.state.status = EvaluateStatus.FAILED\n        self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.after_evaluate","title":"<code>after_evaluate()</code>","text":"<p>Called when the evaluate ends.</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def after_evaluate(self) -&gt; None:\n    \"\"\"Called when the evaluate ends.\"\"\"\n    self.state.step = self.state.total_step\n    self.state.status = EvaluateStatus.SUCCESS\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.before_evaluate","title":"<code>before_evaluate()</code>","text":"<p>Called when the evaluate begins.</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def before_evaluate(self) -&gt; None:\n    \"\"\"Called when the evaluate begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.on_evaluate_end","title":"<code>on_evaluate_end(result_metrics)</code>","text":"<p>Called when the evaluate function ends.</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def on_evaluate_end(self, result_metrics: list[dict]) -&gt; None:\n    \"\"\"Called when the evaluate function ends.\"\"\"\n    self.result.eval_metrics = result_metrics\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.on_evaluate_loop_end","title":"<code>on_evaluate_loop_end(preds)</code>","text":"<p>Called when the evaluate loop ends.</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def on_evaluate_loop_end(self, preds: Any) -&gt; None:\n    \"\"\"Called when the evaluate loop ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.on_evaluate_loop_start","title":"<code>on_evaluate_loop_start(dataloader)</code>","text":"<p>Called when the evaluate loop begins.</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def on_evaluate_loop_start(self, dataloader: DataLoader) -&gt; None:\n    \"\"\"Called when the evaluate loop begins.\"\"\"\n    self.state.total_step = len(dataloader) + 1\n    self.state.step = 0\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.on_evaluate_start","title":"<code>on_evaluate_start()</code>","text":"<p>Called when the evaluate function begins.</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def on_evaluate_start(self) -&gt; None:\n    \"\"\"Called when the evaluate function begins.\"\"\"\n    self.state.status = EvaluateStatus.RUNNING\n    self.state.clear_error()\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.on_evaluate_step_end","title":"<code>on_evaluate_step_end(step, batch, result_batch)</code>","text":"<p>Called when the evaluate loop step ends.</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def on_evaluate_step_end(self, step: int, batch: Any, result_batch: Any) -&gt; None:\n    \"\"\"Called when the evaluate loop step ends.\"\"\"\n    self.state.step = step\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.on_evaluate_step_start","title":"<code>on_evaluate_step_start(step, batch)</code>","text":"<p>Called when the evaluate loop step begins.</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def on_evaluate_step_start(self, step: int, batch: Any) -&gt; None:\n    \"\"\"Called when the evaluate loop step begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.on_exception_failed","title":"<code>on_exception_failed(e)</code>","text":"<p>Called when an error occurs</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def on_exception_failed(self, e: Exception) -&gt; None:\n    \"\"\"Called when an error occurs\"\"\"\n    self.state.status = EvaluateStatus.FAILED\n    self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.on_exception_stopped","title":"<code>on_exception_stopped(e)</code>","text":"<p>Called when SIGTERM or SIGINT occurs</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def on_exception_stopped(self, e: Exception) -&gt; None:\n    \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n    self.state.status = EvaluateStatus.STOPPED\n    self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.setup","title":"<code>setup()</code>","text":"<p>Called when worker starts.</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def setup(self) -&gt; None:\n    \"\"\"Called when worker starts.\"\"\"\n    _register_signal_handler()\n</code></pre>"},{"location":"waffle_hub/evaluator/hook/#waffle_hub.hub.evaluator.hook.BaseEvaluateHook.teardown","title":"<code>teardown()</code>","text":"<p>Called when worker ends.</p> Source code in <code>waffle_hub/hub/evaluator/hook.py</code> <pre><code>def teardown(self) -&gt; None:\n    \"\"\"Called when worker ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/hub/hub/","title":"Hub","text":"Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>class Hub:\n    # directory settings\n    DEFAULT_HUB_ROOT_DIR = Path(\"./hubs\")\n\n    # train files ##--\n    TRAIN_CONFIG_FILE = BaseManager.CONFIG_DIR / BaseManager.TRAIN_CONFIG_FILE\n    MODEL_CONFIG_FILE = BaseManager.CONFIG_DIR / BaseManager.MODEL_CONFIG_FILE\n\n    # State files\n    STATE_DIR = Path(\"states\")\n    TRAIN_STATE_FILE = STATE_DIR / \"train_state.json\"\n    EVALUATE_STATE_FILE = STATE_DIR / \"evaluate_state.json\"\n    EXPORT_ONNX_STATE_FILE = STATE_DIR / \"export_onnx_state.json\"\n    EXPORT_WAFFLE_STATE_FILE = STATE_DIR / \"export_waffle_state.json\"\n    INFERENCE_STATE_FILE = STATE_DIR / \"inference_state.json\"\n\n    def __init__(\n        self,\n        name: str,\n        backend: str = None,\n        task: Union[str, TaskType] = None,\n        model_type: str = None,\n        model_size: str = None,\n        categories: list[Union[str, int, float, dict, Category]] = None,\n        root_dir: str = None,\n        train_callbacks: list[BaseTrainCallback] = None,\n        *args,\n        **kwargs,\n    ):\n\n        self.root_dir: Path = root_dir\n\n        self.name: str = name\n        self.task: str = task\n        self.model_type: str = model_type\n        self.model_size: str = model_size\n        self.categories: list[Category] = categories\n\n        default_train_callbacks = [\n            TrainStateWriterCallback(self.train_state_file, self.evaluate_state_file)\n        ]\n        if train_callbacks is not None:\n            default_train_callbacks.extend(train_callbacks)\n\n        train_state = self.get_train_state()\n        self.manager = (\n            self.get_manager_class(backend).load(\n                root_dir=self.hub_dir,\n                train_state=TrainState.from_dict(train_state) if train_state is not None else None,\n                callbacks=default_train_callbacks,\n            )\n            if BaseManager.is_exists(root_dir=self.hub_dir)\n            else self.get_manager_class(backend)(\n                root_dir=self.hub_dir,\n                name=self.name,\n                task=self.task,\n                model_type=self.model_type,\n                model_size=self.model_size,\n                categories=self.categories,\n                callbacks=default_train_callbacks,\n            )\n        )\n        if self.manager.name != self.name:\n            self.manager.set_model_name(self.name)\n\n        self.backend: str = self.manager.backend\n        self.backend_version: str = self.manager.BACKEND_VERSION\n\n    def __repr__(self):\n        return self.get_model_config().__repr__()\n\n    @classmethod\n    def get_manager_class(cls, backend: str = None) -&gt; \"BaseManager\":\n        \"\"\"\n        Get training manager class\n\n        Args:\n            backend (str): Backend name\n\n        Raises:\n            ModuleNotFoundError: If backend is not supported\n\n        Returns:\n            BaseManager: Backend training manager Class\n        \"\"\"\n        if backend not in list(BACKEND_MAP.keys()):\n            raise ModuleNotFoundError(f\"Backend {backend} is not supported\")\n\n        backend_info = BACKEND_MAP[backend]\n        module = importlib.import_module(backend_info[\"adapter_import_path\"])\n        adapter_class = getattr(module, backend_info[\"adapter_class_name\"])\n        return adapter_class\n\n    @classmethod\n    def get_available_backends(cls) -&gt; list[str]:\n        \"\"\"\n        Get available backends\n\n        Returns:\n            list[str]: Available backends\n        \"\"\"\n        return list(BACKEND_MAP.keys())\n\n    @classmethod\n    def get_available_tasks(cls, backend: str) -&gt; list[str]:\n        \"\"\"\n        Get available tasks\n\n        Args:\n            backend (str): Backend name\n\n        Raises:\n            ModuleNotFoundError: If backend is not supported\n\n        Returns:\n            list[str]: Available tasks\n        \"\"\"\n        backend = backend if backend else cls.BACKEND_NAME\n        manager = cls.get_manager_class(backend)\n        return list(manager.MODEL_TYPES.keys())\n\n    @classmethod\n    def get_available_model_types(cls, backend: str, task: str) -&gt; list[str]:\n        \"\"\"\n        Get available model types\n\n        Args:\n            backend (str): Backend name\n            task (str): Task name\n\n        Raises:\n            ModuleNotFoundError: If backend is not supported\n\n        Returns:\n            list[str]: Available model types\n        \"\"\"\n\n        manager = cls.get_manager_class(backend)\n        if task not in list(manager.MODEL_TYPES.keys()):\n            raise ValueError(f\"{task} is not supported with {backend}\")\n        task = TaskType.from_str(task).value\n        return list(manager.MODEL_TYPES[task].keys())\n\n    @classmethod\n    def get_available_model_sizes(cls, backend: str, task: str, model_type: str) -&gt; list[str]:\n        \"\"\"\n        Get available model sizes\n\n        Args:\n            backend (str): Backend name\n            task (str): Task name\n            model_type (str): Model type\n\n        Raises:\n            ModuleNotFoundError: If backend is not supported\n\n        Returns:\n            list[str]: Available model sizes\n        \"\"\"\n        manager = cls.get_manager_class(backend)\n        if task not in list(manager.MODEL_TYPES.keys()):\n            raise ValueError(f\"{task} is not supported with {backend}\")\n        task = TaskType.from_str(task).value\n        if model_type not in manager.MODEL_TYPES[task]:\n            raise ValueError(f\"{model_type} is not supported with {backend}\")\n        model_sizes = manager.MODEL_TYPES[task][model_type]\n        return model_sizes if isinstance(model_sizes, list) else list(model_sizes.keys())\n\n    @classmethod\n    def get_default_train_params(\n        cls, backend: str, task: str, model_type: str, model_size: str\n    ) -&gt; dict:\n        \"\"\"\n        Get default train params\n\n        Args:\n            backend (str): Backend name\n            task (str): Task name\n            model_type (str): Model type\n            model_size (str): Model size\n\n        Raises:\n            ModuleNotFoundError: If backend is not supported\n\n        Returns:\n            dict: Default train params\n        \"\"\"\n        manager = cls.get_manager_class(backend)\n        if task not in list(manager.MODEL_TYPES.keys()):\n            raise ValueError(f\"{task} is not supported with {backend}\")\n        task = TaskType.from_str(task).value\n        if model_type not in manager.MODEL_TYPES[task]:\n            raise ValueError(f\"{model_type} is not supported with {backend}\")\n        if model_size not in manager.MODEL_TYPES[task][model_type]:\n            raise ValueError(f\"{model_size} is not supported with {backend}\")\n        return manager.DEFAULT_PARAMS[task][model_type][model_size]\n\n    @classmethod\n    def new(\n        cls,\n        name: str,\n        backend: str = None,\n        task: str = None,\n        model_type: str = None,\n        model_size: str = None,\n        categories: Union[list[dict], list] = None,\n        root_dir: str = None,\n        train_callbacks: list[BaseTrainCallback] = None,\n        *args,\n        **kwargs,\n    ) -&gt; \"Hub\":\n        \"\"\"Create Hub.\n\n        Args:\n            name (str): Hub name\n            backend (str, optional): Backend name. See Hub.get_available_backends. Defaults to None.\n            task (str, optional): Task Name. See Hub.get_available_tasks. Defaults to None.\n            model_type (str, optional): Model Type. See Hub.get_available_model_types. Defaults to None.\n            model_size (str, optional): Model Size. See Hub.get_available_model_sizes. Defaults to None.\n            categories (Union[list[dict], list], optional): class dictionary or list. [{\"supercategory\": \"name\"}, ] or [\"name\",]. Defaults to None.\n            root_dir (str, optional): Root directory of hub repository. Defaults to None.\n            train_callbacks (list[BaseTrainCallback], optional): Train callbacks. Defaults to None.\n\n        Returns:\n            Hub: Hub instance\n        \"\"\"\n        root_dir = Hub.parse_root_dir(root_dir)\n\n        if name in cls.get_hub_list(root_dir):\n            raise FileExistsError(f\"{name} already exists. Try another name.\")\n\n        try:\n            backend = backend if backend else cls.get_available_backends()[0]\n            task = TaskType.from_str(task).value if task else cls.get_available_tasks(backend)[0]\n            model_type = (\n                model_type if model_type else cls.get_available_model_types(backend, task)[0]\n            )\n            model_size = (\n                model_size\n                if model_size\n                else cls.get_available_model_sizes(backend, task, model_type)[0]\n            )\n\n            return cls(\n                name=name,\n                backend=backend,\n                task=task,\n                model_type=model_type,\n                model_size=model_size,\n                categories=categories,\n                root_dir=root_dir,\n                train_callbacks=train_callbacks,\n            )\n        except Exception as e:\n            if (root_dir / name).exists():\n                io.remove_directory(root_dir / name, recursive=True)\n            raise e\n\n    @classmethod\n    def load(\n        cls, name: str, root_dir: str = None, train_callbacks: list[BaseTrainCallback] = None\n    ) -&gt; \"Hub\":\n        \"\"\"Load Hub by name.\n\n        Args:\n            name (str): hub name.\n            root_dir (str, optional): hub root directory. Defaults to None.\n            train_callbacks (list[BaseTrainCallback], optional): Train callbacks. Defaults to None.\n\n        Raises:\n            FileNotFoundError: if hub is not exist in root_dir\n\n        Returns:\n            Hub: Hub instance\n        \"\"\"\n        root_dir = Hub.parse_root_dir(root_dir)\n        model_config_file = root_dir / name / BaseManager.CONFIG_DIR / BaseManager.MODEL_CONFIG_FILE\n        if not model_config_file.exists():\n            raise FileNotFoundError(f\"Model[{name}] does not exists. {model_config_file}\")\n        model_config = ModelConfig.load(model_config_file)\n        return cls(\n            **{\n                **model_config.to_dict(),\n                \"root_dir\": root_dir,\n                \"train_callbacks\": train_callbacks,\n            }\n        )\n\n    @classmethod\n    def from_model_config(\n        cls,\n        name: str,\n        model_config_file: str,\n        root_dir: str = None,\n        train_callbacks: list[BaseTrainCallback] = None,\n    ) -&gt; \"Hub\":\n        \"\"\"Create new Hub with model config.\n\n        Args:\n            name (str): hub name.\n            model_config_file (str): model config yaml file.\n            root_dir (str, optional): hub root directory. Defaults to None.\n            train_callbacks (list[BaseTrainCallback], optional): Train callbacks. Defaults to None.\n\n        Returns:\n            Hub: New Hub instance\n        \"\"\"\n        root_dir = Hub.parse_root_dir(root_dir)\n        try:\n            if name in cls.get_hub_list(root_dir):\n                raise ValueError(f\"{name} already exists. Try another name.\")\n\n            model_config = io.load_yaml(model_config_file)\n            return cls.new(\n                **{\n                    **model_config,\n                    \"name\": name,\n                    \"root_dir\": root_dir,\n                    \"train_callbacks\": train_callbacks,\n                }\n            )\n        except Exception as e:\n            if (root_dir / name).exists():\n                io.remove_directory(root_dir / name, recursive=True)\n            raise e\n\n    @classmethod\n    def get_hub_list(cls, root_dir: str = None) -&gt; list[str]:\n        \"\"\"\n        Get hub name list in root_dir.\n\n        Args:\n            root_dir (str, optional): hub root directory. Defaults to None.\n\n        Returns:\n            list[str]: hub name list\n        \"\"\"\n        root_dir = Hub.parse_root_dir(root_dir)\n\n        if not root_dir.exists():\n            return []\n\n        hub_name_list = []\n        for hub_dir in root_dir.iterdir():\n            if hub_dir.is_dir():\n                model_config_file = hub_dir / BaseManager.CONFIG_DIR / BaseManager.MODEL_CONFIG_FILE\n                if model_config_file.exists():\n                    hub_name_list.append(hub_dir.name)\n        return hub_name_list\n\n    @classmethod\n    def from_waffle_file(\n        cls,\n        name: str,\n        waffle_file: str,\n        root_dir: str = None,\n        train_callbacks: list[BaseTrainCallback] = None,\n    ) -&gt; \"Hub\":\n        \"\"\"Import new Hub with waffle file for inference.\n\n        Args:\n            name (str): hub name.\n            waffle_file (str): waffle file path.\n            root_dir (str, optional): hub root directory. Defaults to None.\n            train_callbacks (list[BaseTrainCallback], optional): Train callbacks. Defaults to None.\n\n        Returns:\n            Hub: New Hub instance\n        \"\"\"\n        root_dir = Hub.parse_root_dir(root_dir)\n\n        if name in cls.get_hub_list(root_dir):\n            raise FileExistsError(f\"{name} already exists. Try another name.\")\n\n        if not os.path.exists(waffle_file):\n            raise FileNotFoundError(f\"Waffle file {waffle_file} is not exist.\")\n\n        if os.path.splitext(waffle_file)[1] != \".waffle\":\n            raise ValueError(\n                f\"Invalid waffle file: {waffle_file}, Waffle File extension must be .waffle.\"\n            )\n\n        try:\n            io.unzip(waffle_file, root_dir / name, create_directory=True)\n            model_config_file = (\n                root_dir / name / BaseManager.CONFIG_DIR / BaseManager.MODEL_CONFIG_FILE\n            )\n            if not model_config_file.exists():\n                raise FileNotFoundError(\n                    f\"{model_config_file} does not exists. Please check waffle file.\"\n                )\n            model_config = io.load_yaml(model_config_file)\n            return cls(\n                **{\n                    **model_config,\n                    \"name\": name,\n                    \"root_dir\": root_dir,\n                    \"train_callbacks\": train_callbacks,\n                }\n            )\n\n        except Exception as e:\n            if (root_dir / name).exists():\n                io.remove_directory(root_dir / name, recursive=True)\n            raise e\n\n    # properties\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Hub name\"\"\"\n        return self.__name\n\n    @name.setter\n    @setter_type_validator(str)\n    def name(self, v):\n        self.__name = v\n\n    @property\n    def root_dir(self) -&gt; Path:\n        \"\"\"Root Directory\"\"\"\n        return self.__root_dir\n\n    @root_dir.setter\n    @setter_type_validator(Path, strict=False)\n    def root_dir(self, v):\n        self.__root_dir = Hub.parse_root_dir(v)\n        logger.info(f\"Hub root directory: {self.root_dir}\")\n\n    @classmethod\n    def parse_root_dir(cls, v):\n        if v:\n            return Path(v)\n        elif os.getenv(\"WAFFLE_HUB_ROOT_DIR\", None):\n            return Path(os.getenv(\"WAFFLE_HUB_ROOT_DIR\"))\n        else:\n            return Hub.DEFAULT_HUB_ROOT_DIR\n\n    @property\n    def backend(self) -&gt; str:\n        \"\"\"Backend name\"\"\"\n        return self.__backend\n\n    @backend.setter\n    @setter_type_validator(str, strict=False)\n    def backend(self, v):\n        if v not in list(BACKEND_MAP.keys()):\n            raise ValueError(\n                f\"Backend {v} is not supported. Choose one of {list(BACKEND_MAP.keys())}\"\n            )\n        self.__backend = str(v.value) if isinstance(v, BackendType) else str(v)\n\n    # path properties\n    @property\n    def hub_dir(self) -&gt; Path:\n        \"\"\"Hub(Model) Directory\"\"\"\n        return self.root_dir / self.name\n\n    @property\n    def state_dir(self) -&gt; Path:\n        \"\"\"State Directory\"\"\"\n        return self.hub_dir / self.STATE_DIR\n\n    @property\n    def waffle_file(self) -&gt; Path:\n        \"\"\"Export Waffle file\"\"\"\n        return self.hub_dir / f\"{self.name}.waffle\"\n\n    # state\n    @property\n    def train_state_file(self) -&gt; Path:\n        \"\"\"Train State Json File\"\"\"\n        return self.hub_dir / self.TRAIN_STATE_FILE\n\n    @property\n    def evaluate_state_file(self) -&gt; Path:\n        \"\"\"Evaluate State Json File\"\"\"\n        return self.hub_dir / self.EVALUATE_STATE_FILE\n\n    @property\n    def export_onnx_state_file(self) -&gt; Path:\n        \"\"\"Export ONNX State Json File\"\"\"\n        return self.hub_dir / self.EXPORT_ONNX_STATE_FILE\n\n    @property\n    def export_waffle_state_file(self) -&gt; Path:\n        \"\"\"Export Waffle State Json File\"\"\"\n        return self.hub_dir / self.EXPORT_WAFFLE_STATE_FILE\n\n    @property\n    def inference_state_file(self) -&gt; Path:\n        \"\"\"Inference State Json File\"\"\"\n        return self.hub_dir / self.INFERENCE_STATE_FILE\n\n    ## model\n    @property\n    def config_dir(self) -&gt; Path:\n        \"\"\"Config Directory (model config, train config)\"\"\"\n        return self.manager.config_dir\n\n    @property\n    def model_config_file(self) -&gt; Path:\n        \"\"\"Model Config yaml File\"\"\"\n        return self.manager.model_config_file\n\n    ## trainer\n    @property\n    def weights_dir(self) -&gt; Path:\n        return self.manager.weights_dir\n\n    @property\n    def artifacts_dir(self) -&gt; Path:\n        \"\"\"Artifact Directory. This is raw output of each backend.\"\"\"\n        return self.manager.artifacts_dir\n\n    @property\n    def train_config_file(self) -&gt; Path:\n        \"\"\"Train Config yaml File\"\"\"\n        return self.manager.train_config_file\n\n    @property\n    def best_ckpt_file(self) -&gt; Path:\n        \"\"\"Best Checkpoint File\"\"\"\n        return self.manager.best_ckpt_file\n\n    @property\n    def last_ckpt_file(self) -&gt; Path:\n        \"\"\"Last Checkpoint File\"\"\"\n        return self.manager.last_ckpt_file\n\n    @property\n    def metrics_file(self) -&gt; Path:\n        \"\"\"Metrics File\"\"\"\n        return self.manager.metric_file\n\n    ## evaluator\n    @property\n    def evaluate_file(self) -&gt; Path:\n        \"\"\"Evaluate Json File\"\"\"\n        return self.hub_dir / Evaluator.EVALUATE_FILE\n\n    ## inferencer\n    @property\n    def inference_dir(self) -&gt; Path:\n        \"\"\"Inference Results Directory\"\"\"\n        return self.hub_dir / Inferencer.INFERENCE_DIR\n\n    @property\n    def inference_file(self) -&gt; Path:\n        \"\"\"Inference Results File\"\"\"\n        return self.hub_dir / Inferencer.INFERENCE_FILE\n\n    @property\n    def draw_dir(self) -&gt; Path:\n        \"\"\"Draw Results Directory\"\"\"\n        return self.hub_dir / Inferencer.DRAW_DIR\n\n    ## exporter\n    @property\n    def onnx_file(self) -&gt; Path:\n        \"\"\"Best Checkpoint ONNX File\"\"\"\n        return self.hub_dir / OnnxExporter.ONNX_FILE\n\n    # getters\n    def get_model_config(self) -&gt; ModelConfig:\n        \"\"\"Get model config from model config file.\n\n        Returns:\n            ModelConfig: model config\n        \"\"\"\n        return self.manager.get_model_config(root_dir=self.hub_dir)\n\n    def get_train_config(self) -&gt; TrainConfig:\n        \"\"\"Get train config from train config file.\n\n        Returns:\n            TrainConfig: train config\n        \"\"\"\n\n        return self.manager.get_train_config(root_dir=self.hub_dir)\n\n    def get_categories(self) -&gt; list[Category]:\n        return self.manager.categories\n\n    def get_category_names(self) -&gt; list[str]:\n        return [category.name for category in self.manager.categories]\n\n    def get_default_advance_train_params(\n        self, task: str = None, model_type: str = None, model_size: str = None\n    ) -&gt; dict:\n        return self.manager.get_default_advance_train_params(task, model_type, model_size)\n\n    # get state\n    def get_train_state(self) -&gt; dict:\n        \"\"\"Get train state from train state file.\n\n        Returns:\n            dict: train state\n        \"\"\"\n        if self.train_state_file.exists():\n            return io.load_json(self.train_state_file)\n        else:\n            # TODO: Warning\n            return None\n\n    def get_evaluate_state(self) -&gt; dict:\n        \"\"\"Get evaluate state from evaluate state file.\n\n        Returns:\n            dict: evaluate state\n        \"\"\"\n        if self.evaluate_state_file.exists():\n            return io.load_json(self.evaluate_state_file)\n        else:\n            # TODO: Warning\n            return None\n\n    def get_export_onnx_state(self) -&gt; dict:\n        \"\"\"Get export onnx state from export onnx state file.\n\n        Returns:\n            dict: export onnx state\n        \"\"\"\n        if self.export_onnx_state_file.exists():\n            return io.load_json(self.export_onnx_state_file)\n        else:\n            return None\n\n    def get_export_waffle_state(self) -&gt; dict:\n        \"\"\"Get export waffle state from export waffle state file.\n\n        Returns:\n            dict: export waffle state\n        \"\"\"\n        if self.export_waffle_state_file.exists():\n            return io.load_json(self.export_waffle_state_file)\n        else:\n            return None\n\n    def get_inference_state(self) -&gt; dict:\n        \"\"\"Get inference state from inference state file.\n\n        Returns:\n            dict: inference state\n        \"\"\"\n        if self.inference_state_file.exists():\n            return io.load_json(self.inference_state_file)\n        else:\n            return None\n\n    # get results\n    def get_metrics(self) -&gt; list[list[dict]]:\n        \"\"\"Get metrics per epoch from metric file.\n\n        Examples:\n            &gt;&gt;&gt; hub.get_metrics()\n            [\n                [\n                    {\n                        \"tag\": \"epoch\",\n                        \"value\": \"1\",\n                    },\n                    {\n                        \"tag\": \"train_loss\",\n                        \"value\": \"0.0012\",\n                    }\n                ],\n            ]\n\n        Returns:\n            list[dict]: metrics per epoch\n        \"\"\"\n        return self.manager.get_metrics()\n        # if not self.metric_file.exists(): ##--\n        #     raise FileNotFoundError(\"Metric file is not exist. Train first!\")\n\n        # if not self.evaluate_file.exists():\n        #     raise FileNotFoundError(\"Evaluate file is not exist. Train first!\")\n\n        # return io.load_json(self.metric_file)\n\n    def get_evaluate_result(self) -&gt; list[dict]:\n        \"\"\"Get evaluate result from evaluate file.\n\n        Examples:\n            &gt;&gt;&gt; hub.get_evaluate_result()\n            [\n                {\n                    \"tag\": \"mAP\",\n                    \"value\": 0.5,\n                },\n            ]\n\n        Returns:\n            list[dict]: evaluate result\n        \"\"\"\n        return Evaluator.get_evaluate_result(root_dir=self.hub_dir)\n\n    def get_inference_result(self) -&gt; list[dict]:\n        \"\"\"Get inference result from inference file.\n\n        Examples:\n            &gt;&gt;&gt; hub.get_inference_result()\n            [\n                {\n                    \"id\": \"00000001\",\n                    \"category\": \"person\",\n                    \"bbox\": [0.1, 0.2, 0.3, 0.4],\n                    \"score\": 0.9,\n                },\n            ]\n\n        Returns:\n            list[dict]: inference result\n        \"\"\"\n        return Inferencer.get_inference_result(root_dir=self.hub_dir)\n\n    # common functions\n    def delete_hub(self):\n        \"\"\"Delete Hub. Hub name can be used again.\"\"\"\n        self.manager.delete_manager()\n        del self\n        return None\n\n    def delete_artifacts(self):\n        \"\"\"Delete Artifacts Directory. It can be trained again.\"\"\"\n        self.manager.delete_artifacts()\n        if self.train_state_file.exists():\n            io.remove_file(self.train_state_file)\n\n    def check_train_sanity(self) -&gt; bool:\n        \"\"\"Check if all essential files are exist.\n\n        Returns:\n            bool: True if all files are exist else False\n        \"\"\"\n        return self.manager.check_train_sanity()\n\n    def save_model_config(self):\n        \"\"\"Save ModelConfig.\"\"\"\n        self.manager.save_model_config(self.model_config_file)\n\n    # Hub Utils\n    def get_model(self) -&gt; ModelWrapper:\n        return self.manager.get_model()\n\n    def train(\n        self,\n        dataset: Union[Dataset, str, Path],\n        dataset_root_dir: str = None,\n        epochs: int = None,\n        batch_size: int = None,\n        image_size: Union[int, list[int]] = None,\n        learning_rate: float = None,\n        letter_box: bool = None,\n        pretrained_model: str = None,\n        device: str = \"0\",\n        workers: int = 2,\n        seed: int = 0,\n        advance_params: Union[dict, str] = None,\n        verbose: bool = True,\n    ) -&gt; TrainResult:\n        \"\"\"Start Train\n\n        Args:\n            dataset (Union[Dataset, str]): Waffle Dataset object or path or name.\n            dataset_root_dir (str, optional): Waffle Dataset root directory. Defaults to None.\n            epochs (int, optional): number of epochs. None to use default. Defaults to None.\n            batch_size (int, optional): batch size. None to use default. Defaults to None.\n            image_size (Union[int, list[int]], optional): image size. None to use default. Defaults to None.\n            learning_rate (float, optional): learning rate. None to use default. Defaults to None.\n            letter_box (bool, optional): letter box. None to use default. Defaults to None.\n            pretrained_model (str, optional): pretrained model. None to use default. Defaults to None.\n            device (str, optional):\n                \"cpu\" or \"gpu_id\" or comma seperated \"gpu_ids\". Defaults to \"0\".\n            workers (int, optional): number of workers. Defaults to 2.\n            seed (int, optional): random seed. Defaults to 0.\n            advance_params (Union[dict, str], optional): advance params dictionary or file (yaml, json) path. Defaults to None.\n            verbose (bool, optional): verbose. Defaults to True.\n\n        Raises:\n            FileExistsError: if trained artifact exists.\n            FileNotFoundError: if can not detect appropriate dataset.\n            ValueError: if can not detect appropriate dataset.\n            e: something gone wrong with ultralytics\n\n        Examples:\n            &gt;&gt;&gt; train_result = hub.train(\n                    dataset=dataset,\n                    epochs=100,\n                    batch_size=16,\n                    image_size=640,\n                    learning_rate=0.001,\n                    letterbox=False,\n                    device=\"0\",  # use gpu 0\n                    # device=\"0,1,2,3\",  # use gpu 0,1,2,3\n                    # device=\"cpu\",  # use cpu\n                    workers=2,\n                    seed=123\n                )\n            &gt;&gt;&gt; train_result.best_ckpt_file\n            hubs/my_hub/weights/best_ckpt.pt\n            &gt;&gt;&gt; train_result.metrics\n            [[{\"tag\": \"epoch\", \"value\": 1}, {\"tag\": \"train/loss\", \"value\": 0.1}, ...], ...]\n\n        Returns:\n            TrainResult: train result\n        \"\"\"\n\n        return self.manager.train(\n            dataset=dataset,\n            dataset_root_dir=dataset_root_dir,\n            epochs=epochs,\n            batch_size=batch_size,\n            image_size=image_size,\n            learning_rate=learning_rate,\n            letter_box=letter_box,\n            pretrained_model=pretrained_model,\n            device=device,\n            workers=workers,\n            seed=seed,\n            advance_params=advance_params,\n            verbose=verbose,\n        )\n\n    # Evaluation\n    def evaluate(\n        self,\n        dataset: Union[Dataset, str, Path],\n        dataset_root_dir: str = None,\n        set_name: str = \"test\",\n        batch_size: int = 4,\n        image_size: Union[int, list[int]] = None,\n        letter_box: bool = None,\n        confidence_threshold: float = 0.25,\n        iou_threshold: float = 0.5,\n        half: bool = False,\n        workers: int = 2,\n        device: str = \"0\",\n        callbacks: list[BaseEvaluateCallback] = None,\n    ) -&gt; EvaluateResult:\n        \"\"\"Start Evaluate\n\n        Args:\n            dataset (Union[Dataset, str]): Waffle Dataset object or path or name.\n            dataset_root_dir (str, optional): Waffle Dataset root directory. Defaults to None.\n            set_name (str, optional): Waffle Dataset evalutation set name. Defaults to \"test\".\n            batch_size (int, optional): batch size. Defaults to 4.\n            image_size (Union[int, list[int]], optional): image size. If None, use train config or defaults to 224.\n            letter_box (bool, optional): letter box. If None, use train config or defaults to True.\n            confidence_threshold (float, optional): confidence threshold. Not required in classification. Defaults to 0.25.\n            iou_threshold (float, optional): iou threshold. Not required in classification. Defaults to 0.5.\n            half (bool, optional): half. Defaults to False.\n            workers (int, optional): workers. Defaults to 2.\n            device (str, optional): device. Defaults to \"0\".\n            callbacks (list[BaseEvaluateCallback], optional): evaluate callbacks. Defaults to None.\n\n        Examples:\n            &gt;&gt;&gt; evaluate_result = hub.evaluate(\n                    dataset=detection_dataset,\n                    batch_size=4,\n                    image_size=640,\n                    letterbox=False,\n                    confidence_threshold=0.25,\n                    iou_threshold=0.5,\n                    workers=4,\n                    device=\"0\",\n                )\n            # or you can use train option by passing None\n            &gt;&gt;&gt; evaluate_result = hub.evaluate(\n                    ...\n                    image_size=None,  # use train option or default to 224\n                    letterbox=None,  # use train option or default to True\n                    ...\n                )\n            &gt;&gt;&gt; evaluate_result.metrics\n            [{\"tag\": \"mAP\", \"value\": 0.1}, ...]\n\n        Returns:\n            EvaluateResult: evaluate result\n        \"\"\"\n        default_callbacks = [EvaluateStateWriterCallback(save_path=self.evaluate_state_file)]\n        if callbacks is not None:\n            default_callbacks.extend(callbacks)\n\n        evaluator = Evaluator(\n            root_dir=self.hub_dir,\n            model=self.manager.get_model(),\n            callbacks=default_callbacks,\n        )\n\n        # config setting\n        # overwrite training config\n        train_config = self.get_train_config()\n        if image_size is None and train_config is not None:\n            image_size = train_config.image_size\n        if letter_box is None and train_config is not None:\n            letter_box = train_config.letter_box\n\n        return evaluator.evaluate(\n            dataset=dataset,\n            dataset_root_dir=dataset_root_dir,\n            set_name=set_name,\n            batch_size=batch_size,\n            image_size=image_size,\n            letter_box=letter_box,\n            confidence_threshold=confidence_threshold,\n            iou_threshold=iou_threshold,\n            half=half,\n            workers=workers,\n            device=device,\n        )\n\n    def inference(\n        self,\n        source: Union[str, Path],\n        recursive: bool = True,\n        image_size: Union[int, list[int]] = None,\n        letter_box: bool = None,\n        batch_size: int = 4,\n        confidence_threshold: float = 0.25,\n        iou_threshold: float = 0.5,\n        half: bool = False,\n        workers: int = 2,\n        device: str = \"0\",\n        draw: bool = False,\n        show: bool = False,\n        callbacks: list[BaseInferenceCallback] = None,\n    ) -&gt; InferenceResult:\n        \"\"\"Start Inference\n\n        Args:\n            source (Union[str, Path]): image directory or image path or video path.\n            recursive (bool, optional): recursive. Defaults to True.\n            image_size (Union[int, list[int]], optional): image size. If None, use train config.\n            letter_box (bool, optional): letter box. If None, use train config.\n            batch_size (int, optional): batch size. Defaults to 4.\n            confidence_threshold (float, optional): confidence threshold. Not required in classification. Defaults to 0.25.\n            iou_threshold (float, optional): iou threshold. Not required in classification. Defaults to 0.5.\n            half (bool, optional): half. Defaults to False.\n            workers (int, optional): workers. Defaults to 2.\n            device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n            draw (bool, optional): register draw callback. Defaults to False.\n            show (bool, optional): register show callback. Defaults to False.\n            callbacks (list[BaseInferenceCallback], optional): inference callbacks. Defaults to None.\n\n\n        Raises:\n            FileNotFoundError: if can not detect appropriate dataset.\n            e: something gone wrong with ultralytics\n\n        Examples:\n            &gt;&gt;&gt; inference_result = hub.inference(\n                    source=\"path/to/images\",\n                    batch_size=4,\n                    image_size=640,\n                    letterbox=False,\n                    confidence_threshold=0.25,\n                    iou_threshold=0.5,\n                    workers=4,\n                    device=\"0\",\n                    draw=True,\n                )\n            # or simply use train option by passing None\n            &gt;&gt;&gt; inference_result = hub.inference(\n                    ...\n                    image_size=None,  # use train option or default to 224\n                    letterbox=None,  # use train option or default to True\n                    ...\n                )\n            &gt;&gt;&gt; inference_result.predictions\n            [{\"relative/path/to/image/file\": [{\"category\": \"1\", \"bbox\": [0, 0, 100, 100], \"score\": 0.9}, ...]}, ...]\n\n        Returns:\n            InferenceResult: inference result\n        \"\"\"\n        default_callbacks = [InferenceStateWriterCallback(save_path=self.inference_state_file)]\n        if callbacks is not None:\n            default_callbacks.extend(callbacks)\n\n        inferencer = Inferencer(\n            root_dir=self.hub_dir,\n            model=self.manager.get_model(),\n            callbacks=default_callbacks,\n        )\n        # draw option\n        if draw:\n            inferencer.register_callback(InferenceDrawCallback(self.draw_dir))\n        # show option\n        if show:\n            inferencer.register_callback(InferenceShowCallback())\n\n        # overwrite training config\n        train_config = self.get_train_config()\n        if image_size is None and train_config is not None:\n            image_size = train_config.image_size\n        if letter_box is None and train_config is not None:\n            letter_box = train_config.letter_box\n\n        return inferencer.inference(\n            source=source,\n            recursive=recursive,\n            image_size=image_size,\n            letter_box=letter_box,\n            batch_size=batch_size,\n            confidence_threshold=confidence_threshold,\n            iou_threshold=iou_threshold,\n            half=half,\n            workers=workers,\n            device=device,\n        )\n\n    def benchmark(\n        self,\n        image_size: Union[int, list[int]] = None,\n        batch_size: int = 16,\n        device: str = \"0\",\n        half: bool = False,\n        trial: int = 100,\n    ) -&gt; dict:\n        \"\"\"Benchmark Model\n\n        Args:\n            image_size (Union[int, list[int]], optional): inference image size. None for same with train_config (recommended).\n            batch_size (int, optional): dynamic batch size. Defaults to 16.\n            device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n            half (bool, optional): half. Defaults to False.\n            trial (int, optional): number of trials. Defaults to 100.\n\n        Examples:\n            &gt;&gt;&gt; hub.benchmark(\n                    image_size=640,\n                    batch_size=16,\n                    device=\"0\",\n                    half=False,\n                    trial=100,\n                )\n            {\n                \"inference_time\": 0.123,\n                \"fps\": 123.123,\n                \"image_size\": [640, 640],\n                \"batch_size\": 16,\n                \"device\": \"0\",\n                \"cpu_name\": \"Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz\",\n                \"gpu_name\": \"GeForce GTX 1080 Ti\",\n            }\n\n        Returns:\n            dict: benchmark result\n        \"\"\"\n        inferencer = Inferencer(\n            root_dir=self.hub_dir,\n            model=self.manager.get_model(),\n        )\n        # overwrite training config or default\n        train_config = self.get_train_config()\n        if image_size is None and train_config is not None:\n            image_size = train_config.image_size\n\n        return inferencer.benchmark(\n            image_size=image_size,\n            batch_size=batch_size,\n            device=device,\n            half=half,\n            trial=trial,\n        )\n\n    def export_onnx(\n        self,\n        image_size: Union[int, list[int]] = None,\n        batch_size: int = 16,\n        opset_version: int = 11,\n        half: bool = False,\n        device: str = \"0\",\n        callbacks: list[BaseExportOnnxCallback] = None,\n    ) -&gt; ExportOnnxResult:\n        \"\"\"Export Onnx Model\n\n        Args:\n            image_size (Union[int, list[int]], optional): image size. If None, same train config (recommended).\n            batch_size (int, optional): dynamic batch size. Defaults to 16.\n            opset_version (int, optional): onnx opset version. Defaults to 11.\n            half (bool, optional): half. Defaults to False.\n            device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n            callbacks (list[BaseExportOnnxCallback], optional): export onnx callbacks. Defaults to None.\n\n        Examples:\n            &gt;&gt;&gt; export_onnx_result = hub.export_onnx(\n                image_size=640,\n                batch_size=16,\n                opset_version=11,\n            )\n            # or simply use train option by passing None\n            &gt;&gt;&gt; export_onnx_result = hub.export_onnx(\n                ...,\n                image_size=None,  # use train option\n                ...\n            )\n            &gt;&gt;&gt; export_onnx_result.onnx_file\n            hubs/my_hub/weights/model.onnx\n\n        Returns:\n            ExportOnnxResult: export onnx result\n        \"\"\"\n        default_callbacks = [ExportOnnxStateWriterCallback(save_path=self.export_onnx_state_file)]\n        if callbacks is not None:\n            default_callbacks.extend(callbacks)\n\n        onnx_exporter = OnnxExporter(\n            root_dir=self.hub_dir,\n            model=self.manager.get_model(),\n            callbacks=default_callbacks,\n        )\n\n        # overwrite training config\n        train_config = self.get_train_config()\n        if image_size is None and train_config is not None:\n            image_size = train_config.image_size\n\n        return onnx_exporter.export(\n            image_size=image_size,\n            batch_size=batch_size,\n            opset_version=opset_version,\n            half=half,\n            device=device,\n        )\n\n    def export_waffle(self) -&gt; ExportWaffleResult:\n        \"\"\"Export Waffle Model\n        Examples:\n            &gt;&gt;&gt; export_waffle_result = hub.export_waffle()\n            &gt;&gt;&gt; export_waffle_result.waffle_file\n            hubs/my_hub/my_hub.waffle\n        Returns:\n            ExportWaffleResult: export waffle result\n        \"\"\"\n        self.check_train_sanity()\n\n        try:\n            state = ExportWaffleState(status=ExportWaffleStatus.INIT)\n            state.save_json(self.export_waffle_state_file)\n            result = ExportWaffleResult()\n\n            io.zip([self.weights_dir, self.config_dir], self.waffle_file, recursive=True)\n            result.waffle_file = self.waffle_file\n\n            state.status = ExportWaffleStatus.SUCCESS\n            state.save_json(self.export_waffle_state_file)\n\n        except (KeyboardInterrupt, SystemExit) as e:\n            state.status = ExportWaffleStatus.STOPPED\n            state.save_json(self.export_waffle_state_file)\n            if self.waffle_file.exists():\n                io.remove_file(self.waffle_file)\n        except Exception as e:\n            state.status = ExportWaffleStatus.FAILED\n            state.save_json(self.export_waffle_state_file)\n            if self.waffle_file.exists():\n                io.remove_file(self.waffle_file)\n            raise e\n\n        return result\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.artifacts_dir","title":"<code>artifacts_dir: Path</code>  <code>property</code>","text":"<p>Artifact Directory. This is raw output of each backend.</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.backend","title":"<code>backend: str</code>  <code>property</code> <code>writable</code>","text":"<p>Backend name</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.best_ckpt_file","title":"<code>best_ckpt_file: Path</code>  <code>property</code>","text":"<p>Best Checkpoint File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.config_dir","title":"<code>config_dir: Path</code>  <code>property</code>","text":"<p>Config Directory (model config, train config)</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.draw_dir","title":"<code>draw_dir: Path</code>  <code>property</code>","text":"<p>Draw Results Directory</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.evaluate_file","title":"<code>evaluate_file: Path</code>  <code>property</code>","text":"<p>Evaluate Json File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.evaluate_state_file","title":"<code>evaluate_state_file: Path</code>  <code>property</code>","text":"<p>Evaluate State Json File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.export_onnx_state_file","title":"<code>export_onnx_state_file: Path</code>  <code>property</code>","text":"<p>Export ONNX State Json File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.export_waffle_state_file","title":"<code>export_waffle_state_file: Path</code>  <code>property</code>","text":"<p>Export Waffle State Json File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.hub_dir","title":"<code>hub_dir: Path</code>  <code>property</code>","text":"<p>Hub(Model) Directory</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.inference_dir","title":"<code>inference_dir: Path</code>  <code>property</code>","text":"<p>Inference Results Directory</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.inference_file","title":"<code>inference_file: Path</code>  <code>property</code>","text":"<p>Inference Results File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.inference_state_file","title":"<code>inference_state_file: Path</code>  <code>property</code>","text":"<p>Inference State Json File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.last_ckpt_file","title":"<code>last_ckpt_file: Path</code>  <code>property</code>","text":"<p>Last Checkpoint File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.metrics_file","title":"<code>metrics_file: Path</code>  <code>property</code>","text":"<p>Metrics File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.model_config_file","title":"<code>model_config_file: Path</code>  <code>property</code>","text":"<p>Model Config yaml File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.name","title":"<code>name: str</code>  <code>property</code> <code>writable</code>","text":"<p>Hub name</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.onnx_file","title":"<code>onnx_file: Path</code>  <code>property</code>","text":"<p>Best Checkpoint ONNX File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.root_dir","title":"<code>root_dir: Path</code>  <code>property</code> <code>writable</code>","text":"<p>Root Directory</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.state_dir","title":"<code>state_dir: Path</code>  <code>property</code>","text":"<p>State Directory</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.train_config_file","title":"<code>train_config_file: Path</code>  <code>property</code>","text":"<p>Train Config yaml File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.train_state_file","title":"<code>train_state_file: Path</code>  <code>property</code>","text":"<p>Train State Json File</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.waffle_file","title":"<code>waffle_file: Path</code>  <code>property</code>","text":"<p>Export Waffle file</p>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.benchmark","title":"<code>benchmark(image_size=None, batch_size=16, device='0', half=False, trial=100)</code>","text":"<p>Benchmark Model</p> <p>Parameters:</p> Name Type Description Default <code>image_size</code> <code>Union[int, list[int]]</code> <p>inference image size. None for same with train_config (recommended).</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>dynamic batch size. Defaults to 16.</p> <code>16</code> <code>device</code> <code>str</code> <p>device. \"cpu\" or \"gpu_id\". Defaults to \"0\".</p> <code>'0'</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>trial</code> <code>int</code> <p>number of trials. Defaults to 100.</p> <code>100</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; hub.benchmark(\n        image_size=640,\n        batch_size=16,\n        device=\"0\",\n        half=False,\n        trial=100,\n    )\n{\n    \"inference_time\": 0.123,\n    \"fps\": 123.123,\n    \"image_size\": [640, 640],\n    \"batch_size\": 16,\n    \"device\": \"0\",\n    \"cpu_name\": \"Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz\",\n    \"gpu_name\": \"GeForce GTX 1080 Ti\",\n}\n</code></pre> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>benchmark result</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def benchmark(\n    self,\n    image_size: Union[int, list[int]] = None,\n    batch_size: int = 16,\n    device: str = \"0\",\n    half: bool = False,\n    trial: int = 100,\n) -&gt; dict:\n    \"\"\"Benchmark Model\n\n    Args:\n        image_size (Union[int, list[int]], optional): inference image size. None for same with train_config (recommended).\n        batch_size (int, optional): dynamic batch size. Defaults to 16.\n        device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n        half (bool, optional): half. Defaults to False.\n        trial (int, optional): number of trials. Defaults to 100.\n\n    Examples:\n        &gt;&gt;&gt; hub.benchmark(\n                image_size=640,\n                batch_size=16,\n                device=\"0\",\n                half=False,\n                trial=100,\n            )\n        {\n            \"inference_time\": 0.123,\n            \"fps\": 123.123,\n            \"image_size\": [640, 640],\n            \"batch_size\": 16,\n            \"device\": \"0\",\n            \"cpu_name\": \"Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz\",\n            \"gpu_name\": \"GeForce GTX 1080 Ti\",\n        }\n\n    Returns:\n        dict: benchmark result\n    \"\"\"\n    inferencer = Inferencer(\n        root_dir=self.hub_dir,\n        model=self.manager.get_model(),\n    )\n    # overwrite training config or default\n    train_config = self.get_train_config()\n    if image_size is None and train_config is not None:\n        image_size = train_config.image_size\n\n    return inferencer.benchmark(\n        image_size=image_size,\n        batch_size=batch_size,\n        device=device,\n        half=half,\n        trial=trial,\n    )\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.check_train_sanity","title":"<code>check_train_sanity()</code>","text":"<p>Check if all essential files are exist.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if all files are exist else False</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def check_train_sanity(self) -&gt; bool:\n    \"\"\"Check if all essential files are exist.\n\n    Returns:\n        bool: True if all files are exist else False\n    \"\"\"\n    return self.manager.check_train_sanity()\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.delete_artifacts","title":"<code>delete_artifacts()</code>","text":"<p>Delete Artifacts Directory. It can be trained again.</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def delete_artifacts(self):\n    \"\"\"Delete Artifacts Directory. It can be trained again.\"\"\"\n    self.manager.delete_artifacts()\n    if self.train_state_file.exists():\n        io.remove_file(self.train_state_file)\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.delete_hub","title":"<code>delete_hub()</code>","text":"<p>Delete Hub. Hub name can be used again.</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def delete_hub(self):\n    \"\"\"Delete Hub. Hub name can be used again.\"\"\"\n    self.manager.delete_manager()\n    del self\n    return None\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.evaluate","title":"<code>evaluate(dataset, dataset_root_dir=None, set_name='test', batch_size=4, image_size=None, letter_box=None, confidence_threshold=0.25, iou_threshold=0.5, half=False, workers=2, device='0', callbacks=None)</code>","text":"<p>Start Evaluate</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[Dataset, str]</code> <p>Waffle Dataset object or path or name.</p> required <code>dataset_root_dir</code> <code>str</code> <p>Waffle Dataset root directory. Defaults to None.</p> <code>None</code> <code>set_name</code> <code>str</code> <p>Waffle Dataset evalutation set name. Defaults to \"test\".</p> <code>'test'</code> <code>batch_size</code> <code>int</code> <p>batch size. Defaults to 4.</p> <code>4</code> <code>image_size</code> <code>Union[int, list[int]]</code> <p>image size. If None, use train config or defaults to 224.</p> <code>None</code> <code>letter_box</code> <code>bool</code> <p>letter box. If None, use train config or defaults to True.</p> <code>None</code> <code>confidence_threshold</code> <code>float</code> <p>confidence threshold. Not required in classification. Defaults to 0.25.</p> <code>0.25</code> <code>iou_threshold</code> <code>float</code> <p>iou threshold. Not required in classification. Defaults to 0.5.</p> <code>0.5</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>workers</code> <code>int</code> <p>workers. Defaults to 2.</p> <code>2</code> <code>device</code> <code>str</code> <p>device. Defaults to \"0\".</p> <code>'0'</code> <code>callbacks</code> <code>list[BaseEvaluateCallback]</code> <p>evaluate callbacks. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; evaluate_result = hub.evaluate(\n        dataset=detection_dataset,\n        batch_size=4,\n        image_size=640,\n        letterbox=False,\n        confidence_threshold=0.25,\n        iou_threshold=0.5,\n        workers=4,\n        device=\"0\",\n    )\n# or you can use train option by passing None\n&gt;&gt;&gt; evaluate_result = hub.evaluate(\n        ...\n        image_size=None,  # use train option or default to 224\n        letterbox=None,  # use train option or default to True\n        ...\n    )\n&gt;&gt;&gt; evaluate_result.metrics\n[{\"tag\": \"mAP\", \"value\": 0.1}, ...]\n</code></pre> <p>Returns:</p> Name Type Description <code>EvaluateResult</code> <code>EvaluateResult</code> <p>evaluate result</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def evaluate(\n    self,\n    dataset: Union[Dataset, str, Path],\n    dataset_root_dir: str = None,\n    set_name: str = \"test\",\n    batch_size: int = 4,\n    image_size: Union[int, list[int]] = None,\n    letter_box: bool = None,\n    confidence_threshold: float = 0.25,\n    iou_threshold: float = 0.5,\n    half: bool = False,\n    workers: int = 2,\n    device: str = \"0\",\n    callbacks: list[BaseEvaluateCallback] = None,\n) -&gt; EvaluateResult:\n    \"\"\"Start Evaluate\n\n    Args:\n        dataset (Union[Dataset, str]): Waffle Dataset object or path or name.\n        dataset_root_dir (str, optional): Waffle Dataset root directory. Defaults to None.\n        set_name (str, optional): Waffle Dataset evalutation set name. Defaults to \"test\".\n        batch_size (int, optional): batch size. Defaults to 4.\n        image_size (Union[int, list[int]], optional): image size. If None, use train config or defaults to 224.\n        letter_box (bool, optional): letter box. If None, use train config or defaults to True.\n        confidence_threshold (float, optional): confidence threshold. Not required in classification. Defaults to 0.25.\n        iou_threshold (float, optional): iou threshold. Not required in classification. Defaults to 0.5.\n        half (bool, optional): half. Defaults to False.\n        workers (int, optional): workers. Defaults to 2.\n        device (str, optional): device. Defaults to \"0\".\n        callbacks (list[BaseEvaluateCallback], optional): evaluate callbacks. Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; evaluate_result = hub.evaluate(\n                dataset=detection_dataset,\n                batch_size=4,\n                image_size=640,\n                letterbox=False,\n                confidence_threshold=0.25,\n                iou_threshold=0.5,\n                workers=4,\n                device=\"0\",\n            )\n        # or you can use train option by passing None\n        &gt;&gt;&gt; evaluate_result = hub.evaluate(\n                ...\n                image_size=None,  # use train option or default to 224\n                letterbox=None,  # use train option or default to True\n                ...\n            )\n        &gt;&gt;&gt; evaluate_result.metrics\n        [{\"tag\": \"mAP\", \"value\": 0.1}, ...]\n\n    Returns:\n        EvaluateResult: evaluate result\n    \"\"\"\n    default_callbacks = [EvaluateStateWriterCallback(save_path=self.evaluate_state_file)]\n    if callbacks is not None:\n        default_callbacks.extend(callbacks)\n\n    evaluator = Evaluator(\n        root_dir=self.hub_dir,\n        model=self.manager.get_model(),\n        callbacks=default_callbacks,\n    )\n\n    # config setting\n    # overwrite training config\n    train_config = self.get_train_config()\n    if image_size is None and train_config is not None:\n        image_size = train_config.image_size\n    if letter_box is None and train_config is not None:\n        letter_box = train_config.letter_box\n\n    return evaluator.evaluate(\n        dataset=dataset,\n        dataset_root_dir=dataset_root_dir,\n        set_name=set_name,\n        batch_size=batch_size,\n        image_size=image_size,\n        letter_box=letter_box,\n        confidence_threshold=confidence_threshold,\n        iou_threshold=iou_threshold,\n        half=half,\n        workers=workers,\n        device=device,\n    )\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.export_onnx","title":"<code>export_onnx(image_size=None, batch_size=16, opset_version=11, half=False, device='0', callbacks=None)</code>","text":"<p>Export Onnx Model</p> <p>Parameters:</p> Name Type Description Default <code>image_size</code> <code>Union[int, list[int]]</code> <p>image size. If None, same train config (recommended).</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>dynamic batch size. Defaults to 16.</p> <code>16</code> <code>opset_version</code> <code>int</code> <p>onnx opset version. Defaults to 11.</p> <code>11</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>device</code> <code>str</code> <p>device. \"cpu\" or \"gpu_id\". Defaults to \"0\".</p> <code>'0'</code> <code>callbacks</code> <code>list[BaseExportOnnxCallback]</code> <p>export onnx callbacks. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; export_onnx_result = hub.export_onnx(\n    image_size=640,\n    batch_size=16,\n    opset_version=11,\n)\n# or simply use train option by passing None\n&gt;&gt;&gt; export_onnx_result = hub.export_onnx(\n    ...,\n    image_size=None,  # use train option\n    ...\n)\n&gt;&gt;&gt; export_onnx_result.onnx_file\nhubs/my_hub/weights/model.onnx\n</code></pre> <p>Returns:</p> Name Type Description <code>ExportOnnxResult</code> <code>ExportOnnxResult</code> <p>export onnx result</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def export_onnx(\n    self,\n    image_size: Union[int, list[int]] = None,\n    batch_size: int = 16,\n    opset_version: int = 11,\n    half: bool = False,\n    device: str = \"0\",\n    callbacks: list[BaseExportOnnxCallback] = None,\n) -&gt; ExportOnnxResult:\n    \"\"\"Export Onnx Model\n\n    Args:\n        image_size (Union[int, list[int]], optional): image size. If None, same train config (recommended).\n        batch_size (int, optional): dynamic batch size. Defaults to 16.\n        opset_version (int, optional): onnx opset version. Defaults to 11.\n        half (bool, optional): half. Defaults to False.\n        device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n        callbacks (list[BaseExportOnnxCallback], optional): export onnx callbacks. Defaults to None.\n\n    Examples:\n        &gt;&gt;&gt; export_onnx_result = hub.export_onnx(\n            image_size=640,\n            batch_size=16,\n            opset_version=11,\n        )\n        # or simply use train option by passing None\n        &gt;&gt;&gt; export_onnx_result = hub.export_onnx(\n            ...,\n            image_size=None,  # use train option\n            ...\n        )\n        &gt;&gt;&gt; export_onnx_result.onnx_file\n        hubs/my_hub/weights/model.onnx\n\n    Returns:\n        ExportOnnxResult: export onnx result\n    \"\"\"\n    default_callbacks = [ExportOnnxStateWriterCallback(save_path=self.export_onnx_state_file)]\n    if callbacks is not None:\n        default_callbacks.extend(callbacks)\n\n    onnx_exporter = OnnxExporter(\n        root_dir=self.hub_dir,\n        model=self.manager.get_model(),\n        callbacks=default_callbacks,\n    )\n\n    # overwrite training config\n    train_config = self.get_train_config()\n    if image_size is None and train_config is not None:\n        image_size = train_config.image_size\n\n    return onnx_exporter.export(\n        image_size=image_size,\n        batch_size=batch_size,\n        opset_version=opset_version,\n        half=half,\n        device=device,\n    )\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.export_waffle","title":"<code>export_waffle()</code>","text":"<p>Export Waffle Model Examples:     &gt;&gt;&gt; export_waffle_result = hub.export_waffle()     &gt;&gt;&gt; export_waffle_result.waffle_file     hubs/my_hub/my_hub.waffle Returns:     ExportWaffleResult: export waffle result</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def export_waffle(self) -&gt; ExportWaffleResult:\n    \"\"\"Export Waffle Model\n    Examples:\n        &gt;&gt;&gt; export_waffle_result = hub.export_waffle()\n        &gt;&gt;&gt; export_waffle_result.waffle_file\n        hubs/my_hub/my_hub.waffle\n    Returns:\n        ExportWaffleResult: export waffle result\n    \"\"\"\n    self.check_train_sanity()\n\n    try:\n        state = ExportWaffleState(status=ExportWaffleStatus.INIT)\n        state.save_json(self.export_waffle_state_file)\n        result = ExportWaffleResult()\n\n        io.zip([self.weights_dir, self.config_dir], self.waffle_file, recursive=True)\n        result.waffle_file = self.waffle_file\n\n        state.status = ExportWaffleStatus.SUCCESS\n        state.save_json(self.export_waffle_state_file)\n\n    except (KeyboardInterrupt, SystemExit) as e:\n        state.status = ExportWaffleStatus.STOPPED\n        state.save_json(self.export_waffle_state_file)\n        if self.waffle_file.exists():\n            io.remove_file(self.waffle_file)\n    except Exception as e:\n        state.status = ExportWaffleStatus.FAILED\n        state.save_json(self.export_waffle_state_file)\n        if self.waffle_file.exists():\n            io.remove_file(self.waffle_file)\n        raise e\n\n    return result\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.from_model_config","title":"<code>from_model_config(name, model_config_file, root_dir=None, train_callbacks=None)</code>  <code>classmethod</code>","text":"<p>Create new Hub with model config.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>hub name.</p> required <code>model_config_file</code> <code>str</code> <p>model config yaml file.</p> required <code>root_dir</code> <code>str</code> <p>hub root directory. Defaults to None.</p> <code>None</code> <code>train_callbacks</code> <code>list[BaseTrainCallback]</code> <p>Train callbacks. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Hub</code> <code>Hub</code> <p>New Hub instance</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>@classmethod\ndef from_model_config(\n    cls,\n    name: str,\n    model_config_file: str,\n    root_dir: str = None,\n    train_callbacks: list[BaseTrainCallback] = None,\n) -&gt; \"Hub\":\n    \"\"\"Create new Hub with model config.\n\n    Args:\n        name (str): hub name.\n        model_config_file (str): model config yaml file.\n        root_dir (str, optional): hub root directory. Defaults to None.\n        train_callbacks (list[BaseTrainCallback], optional): Train callbacks. Defaults to None.\n\n    Returns:\n        Hub: New Hub instance\n    \"\"\"\n    root_dir = Hub.parse_root_dir(root_dir)\n    try:\n        if name in cls.get_hub_list(root_dir):\n            raise ValueError(f\"{name} already exists. Try another name.\")\n\n        model_config = io.load_yaml(model_config_file)\n        return cls.new(\n            **{\n                **model_config,\n                \"name\": name,\n                \"root_dir\": root_dir,\n                \"train_callbacks\": train_callbacks,\n            }\n        )\n    except Exception as e:\n        if (root_dir / name).exists():\n            io.remove_directory(root_dir / name, recursive=True)\n        raise e\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.from_waffle_file","title":"<code>from_waffle_file(name, waffle_file, root_dir=None, train_callbacks=None)</code>  <code>classmethod</code>","text":"<p>Import new Hub with waffle file for inference.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>hub name.</p> required <code>waffle_file</code> <code>str</code> <p>waffle file path.</p> required <code>root_dir</code> <code>str</code> <p>hub root directory. Defaults to None.</p> <code>None</code> <code>train_callbacks</code> <code>list[BaseTrainCallback]</code> <p>Train callbacks. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Hub</code> <code>Hub</code> <p>New Hub instance</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>@classmethod\ndef from_waffle_file(\n    cls,\n    name: str,\n    waffle_file: str,\n    root_dir: str = None,\n    train_callbacks: list[BaseTrainCallback] = None,\n) -&gt; \"Hub\":\n    \"\"\"Import new Hub with waffle file for inference.\n\n    Args:\n        name (str): hub name.\n        waffle_file (str): waffle file path.\n        root_dir (str, optional): hub root directory. Defaults to None.\n        train_callbacks (list[BaseTrainCallback], optional): Train callbacks. Defaults to None.\n\n    Returns:\n        Hub: New Hub instance\n    \"\"\"\n    root_dir = Hub.parse_root_dir(root_dir)\n\n    if name in cls.get_hub_list(root_dir):\n        raise FileExistsError(f\"{name} already exists. Try another name.\")\n\n    if not os.path.exists(waffle_file):\n        raise FileNotFoundError(f\"Waffle file {waffle_file} is not exist.\")\n\n    if os.path.splitext(waffle_file)[1] != \".waffle\":\n        raise ValueError(\n            f\"Invalid waffle file: {waffle_file}, Waffle File extension must be .waffle.\"\n        )\n\n    try:\n        io.unzip(waffle_file, root_dir / name, create_directory=True)\n        model_config_file = (\n            root_dir / name / BaseManager.CONFIG_DIR / BaseManager.MODEL_CONFIG_FILE\n        )\n        if not model_config_file.exists():\n            raise FileNotFoundError(\n                f\"{model_config_file} does not exists. Please check waffle file.\"\n            )\n        model_config = io.load_yaml(model_config_file)\n        return cls(\n            **{\n                **model_config,\n                \"name\": name,\n                \"root_dir\": root_dir,\n                \"train_callbacks\": train_callbacks,\n            }\n        )\n\n    except Exception as e:\n        if (root_dir / name).exists():\n            io.remove_directory(root_dir / name, recursive=True)\n        raise e\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_available_backends","title":"<code>get_available_backends()</code>  <code>classmethod</code>","text":"<p>Get available backends</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: Available backends</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>@classmethod\ndef get_available_backends(cls) -&gt; list[str]:\n    \"\"\"\n    Get available backends\n\n    Returns:\n        list[str]: Available backends\n    \"\"\"\n    return list(BACKEND_MAP.keys())\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_available_model_sizes","title":"<code>get_available_model_sizes(backend, task, model_type)</code>  <code>classmethod</code>","text":"<p>Get available model sizes</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>str</code> <p>Backend name</p> required <code>task</code> <code>str</code> <p>Task name</p> required <code>model_type</code> <code>str</code> <p>Model type</p> required <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If backend is not supported</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: Available model sizes</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>@classmethod\ndef get_available_model_sizes(cls, backend: str, task: str, model_type: str) -&gt; list[str]:\n    \"\"\"\n    Get available model sizes\n\n    Args:\n        backend (str): Backend name\n        task (str): Task name\n        model_type (str): Model type\n\n    Raises:\n        ModuleNotFoundError: If backend is not supported\n\n    Returns:\n        list[str]: Available model sizes\n    \"\"\"\n    manager = cls.get_manager_class(backend)\n    if task not in list(manager.MODEL_TYPES.keys()):\n        raise ValueError(f\"{task} is not supported with {backend}\")\n    task = TaskType.from_str(task).value\n    if model_type not in manager.MODEL_TYPES[task]:\n        raise ValueError(f\"{model_type} is not supported with {backend}\")\n    model_sizes = manager.MODEL_TYPES[task][model_type]\n    return model_sizes if isinstance(model_sizes, list) else list(model_sizes.keys())\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_available_model_types","title":"<code>get_available_model_types(backend, task)</code>  <code>classmethod</code>","text":"<p>Get available model types</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>str</code> <p>Backend name</p> required <code>task</code> <code>str</code> <p>Task name</p> required <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If backend is not supported</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: Available model types</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>@classmethod\ndef get_available_model_types(cls, backend: str, task: str) -&gt; list[str]:\n    \"\"\"\n    Get available model types\n\n    Args:\n        backend (str): Backend name\n        task (str): Task name\n\n    Raises:\n        ModuleNotFoundError: If backend is not supported\n\n    Returns:\n        list[str]: Available model types\n    \"\"\"\n\n    manager = cls.get_manager_class(backend)\n    if task not in list(manager.MODEL_TYPES.keys()):\n        raise ValueError(f\"{task} is not supported with {backend}\")\n    task = TaskType.from_str(task).value\n    return list(manager.MODEL_TYPES[task].keys())\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_available_tasks","title":"<code>get_available_tasks(backend)</code>  <code>classmethod</code>","text":"<p>Get available tasks</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>str</code> <p>Backend name</p> required <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If backend is not supported</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: Available tasks</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>@classmethod\ndef get_available_tasks(cls, backend: str) -&gt; list[str]:\n    \"\"\"\n    Get available tasks\n\n    Args:\n        backend (str): Backend name\n\n    Raises:\n        ModuleNotFoundError: If backend is not supported\n\n    Returns:\n        list[str]: Available tasks\n    \"\"\"\n    backend = backend if backend else cls.BACKEND_NAME\n    manager = cls.get_manager_class(backend)\n    return list(manager.MODEL_TYPES.keys())\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_default_train_params","title":"<code>get_default_train_params(backend, task, model_type, model_size)</code>  <code>classmethod</code>","text":"<p>Get default train params</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>str</code> <p>Backend name</p> required <code>task</code> <code>str</code> <p>Task name</p> required <code>model_type</code> <code>str</code> <p>Model type</p> required <code>model_size</code> <code>str</code> <p>Model size</p> required <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If backend is not supported</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Default train params</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>@classmethod\ndef get_default_train_params(\n    cls, backend: str, task: str, model_type: str, model_size: str\n) -&gt; dict:\n    \"\"\"\n    Get default train params\n\n    Args:\n        backend (str): Backend name\n        task (str): Task name\n        model_type (str): Model type\n        model_size (str): Model size\n\n    Raises:\n        ModuleNotFoundError: If backend is not supported\n\n    Returns:\n        dict: Default train params\n    \"\"\"\n    manager = cls.get_manager_class(backend)\n    if task not in list(manager.MODEL_TYPES.keys()):\n        raise ValueError(f\"{task} is not supported with {backend}\")\n    task = TaskType.from_str(task).value\n    if model_type not in manager.MODEL_TYPES[task]:\n        raise ValueError(f\"{model_type} is not supported with {backend}\")\n    if model_size not in manager.MODEL_TYPES[task][model_type]:\n        raise ValueError(f\"{model_size} is not supported with {backend}\")\n    return manager.DEFAULT_PARAMS[task][model_type][model_size]\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_evaluate_result","title":"<code>get_evaluate_result()</code>","text":"<p>Get evaluate result from evaluate file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; hub.get_evaluate_result()\n[\n    {\n        \"tag\": \"mAP\",\n        \"value\": 0.5,\n    },\n]\n</code></pre> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: evaluate result</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def get_evaluate_result(self) -&gt; list[dict]:\n    \"\"\"Get evaluate result from evaluate file.\n\n    Examples:\n        &gt;&gt;&gt; hub.get_evaluate_result()\n        [\n            {\n                \"tag\": \"mAP\",\n                \"value\": 0.5,\n            },\n        ]\n\n    Returns:\n        list[dict]: evaluate result\n    \"\"\"\n    return Evaluator.get_evaluate_result(root_dir=self.hub_dir)\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_evaluate_state","title":"<code>get_evaluate_state()</code>","text":"<p>Get evaluate state from evaluate state file.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>evaluate state</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def get_evaluate_state(self) -&gt; dict:\n    \"\"\"Get evaluate state from evaluate state file.\n\n    Returns:\n        dict: evaluate state\n    \"\"\"\n    if self.evaluate_state_file.exists():\n        return io.load_json(self.evaluate_state_file)\n    else:\n        # TODO: Warning\n        return None\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_export_onnx_state","title":"<code>get_export_onnx_state()</code>","text":"<p>Get export onnx state from export onnx state file.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>export onnx state</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def get_export_onnx_state(self) -&gt; dict:\n    \"\"\"Get export onnx state from export onnx state file.\n\n    Returns:\n        dict: export onnx state\n    \"\"\"\n    if self.export_onnx_state_file.exists():\n        return io.load_json(self.export_onnx_state_file)\n    else:\n        return None\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_export_waffle_state","title":"<code>get_export_waffle_state()</code>","text":"<p>Get export waffle state from export waffle state file.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>export waffle state</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def get_export_waffle_state(self) -&gt; dict:\n    \"\"\"Get export waffle state from export waffle state file.\n\n    Returns:\n        dict: export waffle state\n    \"\"\"\n    if self.export_waffle_state_file.exists():\n        return io.load_json(self.export_waffle_state_file)\n    else:\n        return None\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_hub_list","title":"<code>get_hub_list(root_dir=None)</code>  <code>classmethod</code>","text":"<p>Get hub name list in root_dir.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>str</code> <p>hub root directory. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: hub name list</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>@classmethod\ndef get_hub_list(cls, root_dir: str = None) -&gt; list[str]:\n    \"\"\"\n    Get hub name list in root_dir.\n\n    Args:\n        root_dir (str, optional): hub root directory. Defaults to None.\n\n    Returns:\n        list[str]: hub name list\n    \"\"\"\n    root_dir = Hub.parse_root_dir(root_dir)\n\n    if not root_dir.exists():\n        return []\n\n    hub_name_list = []\n    for hub_dir in root_dir.iterdir():\n        if hub_dir.is_dir():\n            model_config_file = hub_dir / BaseManager.CONFIG_DIR / BaseManager.MODEL_CONFIG_FILE\n            if model_config_file.exists():\n                hub_name_list.append(hub_dir.name)\n    return hub_name_list\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_inference_result","title":"<code>get_inference_result()</code>","text":"<p>Get inference result from inference file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; hub.get_inference_result()\n[\n    {\n        \"id\": \"00000001\",\n        \"category\": \"person\",\n        \"bbox\": [0.1, 0.2, 0.3, 0.4],\n        \"score\": 0.9,\n    },\n]\n</code></pre> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: inference result</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def get_inference_result(self) -&gt; list[dict]:\n    \"\"\"Get inference result from inference file.\n\n    Examples:\n        &gt;&gt;&gt; hub.get_inference_result()\n        [\n            {\n                \"id\": \"00000001\",\n                \"category\": \"person\",\n                \"bbox\": [0.1, 0.2, 0.3, 0.4],\n                \"score\": 0.9,\n            },\n        ]\n\n    Returns:\n        list[dict]: inference result\n    \"\"\"\n    return Inferencer.get_inference_result(root_dir=self.hub_dir)\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_inference_state","title":"<code>get_inference_state()</code>","text":"<p>Get inference state from inference state file.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>inference state</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def get_inference_state(self) -&gt; dict:\n    \"\"\"Get inference state from inference state file.\n\n    Returns:\n        dict: inference state\n    \"\"\"\n    if self.inference_state_file.exists():\n        return io.load_json(self.inference_state_file)\n    else:\n        return None\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_manager_class","title":"<code>get_manager_class(backend=None)</code>  <code>classmethod</code>","text":"<p>Get training manager class</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>str</code> <p>Backend name</p> <code>None</code> <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If backend is not supported</p> <p>Returns:</p> Name Type Description <code>BaseManager</code> <code>BaseManager</code> <p>Backend training manager Class</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>@classmethod\ndef get_manager_class(cls, backend: str = None) -&gt; \"BaseManager\":\n    \"\"\"\n    Get training manager class\n\n    Args:\n        backend (str): Backend name\n\n    Raises:\n        ModuleNotFoundError: If backend is not supported\n\n    Returns:\n        BaseManager: Backend training manager Class\n    \"\"\"\n    if backend not in list(BACKEND_MAP.keys()):\n        raise ModuleNotFoundError(f\"Backend {backend} is not supported\")\n\n    backend_info = BACKEND_MAP[backend]\n    module = importlib.import_module(backend_info[\"adapter_import_path\"])\n    adapter_class = getattr(module, backend_info[\"adapter_class_name\"])\n    return adapter_class\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_metrics","title":"<code>get_metrics()</code>","text":"<p>Get metrics per epoch from metric file.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; hub.get_metrics()\n[\n    [\n        {\n            \"tag\": \"epoch\",\n            \"value\": \"1\",\n        },\n        {\n            \"tag\": \"train_loss\",\n            \"value\": \"0.0012\",\n        }\n    ],\n]\n</code></pre> <p>Returns:</p> Type Description <code>list[list[dict]]</code> <p>list[dict]: metrics per epoch</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def get_metrics(self) -&gt; list[list[dict]]:\n    \"\"\"Get metrics per epoch from metric file.\n\n    Examples:\n        &gt;&gt;&gt; hub.get_metrics()\n        [\n            [\n                {\n                    \"tag\": \"epoch\",\n                    \"value\": \"1\",\n                },\n                {\n                    \"tag\": \"train_loss\",\n                    \"value\": \"0.0012\",\n                }\n            ],\n        ]\n\n    Returns:\n        list[dict]: metrics per epoch\n    \"\"\"\n    return self.manager.get_metrics()\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_model_config","title":"<code>get_model_config()</code>","text":"<p>Get model config from model config file.</p> <p>Returns:</p> Name Type Description <code>ModelConfig</code> <code>ModelConfig</code> <p>model config</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def get_model_config(self) -&gt; ModelConfig:\n    \"\"\"Get model config from model config file.\n\n    Returns:\n        ModelConfig: model config\n    \"\"\"\n    return self.manager.get_model_config(root_dir=self.hub_dir)\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_train_config","title":"<code>get_train_config()</code>","text":"<p>Get train config from train config file.</p> <p>Returns:</p> Name Type Description <code>TrainConfig</code> <code>TrainConfig</code> <p>train config</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def get_train_config(self) -&gt; TrainConfig:\n    \"\"\"Get train config from train config file.\n\n    Returns:\n        TrainConfig: train config\n    \"\"\"\n\n    return self.manager.get_train_config(root_dir=self.hub_dir)\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.get_train_state","title":"<code>get_train_state()</code>","text":"<p>Get train state from train state file.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>train state</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def get_train_state(self) -&gt; dict:\n    \"\"\"Get train state from train state file.\n\n    Returns:\n        dict: train state\n    \"\"\"\n    if self.train_state_file.exists():\n        return io.load_json(self.train_state_file)\n    else:\n        # TODO: Warning\n        return None\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.inference","title":"<code>inference(source, recursive=True, image_size=None, letter_box=None, batch_size=4, confidence_threshold=0.25, iou_threshold=0.5, half=False, workers=2, device='0', draw=False, show=False, callbacks=None)</code>","text":"<p>Start Inference</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Union[str, Path]</code> <p>image directory or image path or video path.</p> required <code>recursive</code> <code>bool</code> <p>recursive. Defaults to True.</p> <code>True</code> <code>image_size</code> <code>Union[int, list[int]]</code> <p>image size. If None, use train config.</p> <code>None</code> <code>letter_box</code> <code>bool</code> <p>letter box. If None, use train config.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>batch size. Defaults to 4.</p> <code>4</code> <code>confidence_threshold</code> <code>float</code> <p>confidence threshold. Not required in classification. Defaults to 0.25.</p> <code>0.25</code> <code>iou_threshold</code> <code>float</code> <p>iou threshold. Not required in classification. Defaults to 0.5.</p> <code>0.5</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>workers</code> <code>int</code> <p>workers. Defaults to 2.</p> <code>2</code> <code>device</code> <code>str</code> <p>device. \"cpu\" or \"gpu_id\". Defaults to \"0\".</p> <code>'0'</code> <code>draw</code> <code>bool</code> <p>register draw callback. Defaults to False.</p> <code>False</code> <code>show</code> <code>bool</code> <p>register show callback. Defaults to False.</p> <code>False</code> <code>callbacks</code> <code>list[BaseInferenceCallback]</code> <p>inference callbacks. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if can not detect appropriate dataset.</p> <code>e</code> <p>something gone wrong with ultralytics</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; inference_result = hub.inference(\n        source=\"path/to/images\",\n        batch_size=4,\n        image_size=640,\n        letterbox=False,\n        confidence_threshold=0.25,\n        iou_threshold=0.5,\n        workers=4,\n        device=\"0\",\n        draw=True,\n    )\n# or simply use train option by passing None\n&gt;&gt;&gt; inference_result = hub.inference(\n        ...\n        image_size=None,  # use train option or default to 224\n        letterbox=None,  # use train option or default to True\n        ...\n    )\n&gt;&gt;&gt; inference_result.predictions\n[{\"relative/path/to/image/file\": [{\"category\": \"1\", \"bbox\": [0, 0, 100, 100], \"score\": 0.9}, ...]}, ...]\n</code></pre> <p>Returns:</p> Name Type Description <code>InferenceResult</code> <code>InferenceResult</code> <p>inference result</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def inference(\n    self,\n    source: Union[str, Path],\n    recursive: bool = True,\n    image_size: Union[int, list[int]] = None,\n    letter_box: bool = None,\n    batch_size: int = 4,\n    confidence_threshold: float = 0.25,\n    iou_threshold: float = 0.5,\n    half: bool = False,\n    workers: int = 2,\n    device: str = \"0\",\n    draw: bool = False,\n    show: bool = False,\n    callbacks: list[BaseInferenceCallback] = None,\n) -&gt; InferenceResult:\n    \"\"\"Start Inference\n\n    Args:\n        source (Union[str, Path]): image directory or image path or video path.\n        recursive (bool, optional): recursive. Defaults to True.\n        image_size (Union[int, list[int]], optional): image size. If None, use train config.\n        letter_box (bool, optional): letter box. If None, use train config.\n        batch_size (int, optional): batch size. Defaults to 4.\n        confidence_threshold (float, optional): confidence threshold. Not required in classification. Defaults to 0.25.\n        iou_threshold (float, optional): iou threshold. Not required in classification. Defaults to 0.5.\n        half (bool, optional): half. Defaults to False.\n        workers (int, optional): workers. Defaults to 2.\n        device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n        draw (bool, optional): register draw callback. Defaults to False.\n        show (bool, optional): register show callback. Defaults to False.\n        callbacks (list[BaseInferenceCallback], optional): inference callbacks. Defaults to None.\n\n\n    Raises:\n        FileNotFoundError: if can not detect appropriate dataset.\n        e: something gone wrong with ultralytics\n\n    Examples:\n        &gt;&gt;&gt; inference_result = hub.inference(\n                source=\"path/to/images\",\n                batch_size=4,\n                image_size=640,\n                letterbox=False,\n                confidence_threshold=0.25,\n                iou_threshold=0.5,\n                workers=4,\n                device=\"0\",\n                draw=True,\n            )\n        # or simply use train option by passing None\n        &gt;&gt;&gt; inference_result = hub.inference(\n                ...\n                image_size=None,  # use train option or default to 224\n                letterbox=None,  # use train option or default to True\n                ...\n            )\n        &gt;&gt;&gt; inference_result.predictions\n        [{\"relative/path/to/image/file\": [{\"category\": \"1\", \"bbox\": [0, 0, 100, 100], \"score\": 0.9}, ...]}, ...]\n\n    Returns:\n        InferenceResult: inference result\n    \"\"\"\n    default_callbacks = [InferenceStateWriterCallback(save_path=self.inference_state_file)]\n    if callbacks is not None:\n        default_callbacks.extend(callbacks)\n\n    inferencer = Inferencer(\n        root_dir=self.hub_dir,\n        model=self.manager.get_model(),\n        callbacks=default_callbacks,\n    )\n    # draw option\n    if draw:\n        inferencer.register_callback(InferenceDrawCallback(self.draw_dir))\n    # show option\n    if show:\n        inferencer.register_callback(InferenceShowCallback())\n\n    # overwrite training config\n    train_config = self.get_train_config()\n    if image_size is None and train_config is not None:\n        image_size = train_config.image_size\n    if letter_box is None and train_config is not None:\n        letter_box = train_config.letter_box\n\n    return inferencer.inference(\n        source=source,\n        recursive=recursive,\n        image_size=image_size,\n        letter_box=letter_box,\n        batch_size=batch_size,\n        confidence_threshold=confidence_threshold,\n        iou_threshold=iou_threshold,\n        half=half,\n        workers=workers,\n        device=device,\n    )\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.load","title":"<code>load(name, root_dir=None, train_callbacks=None)</code>  <code>classmethod</code>","text":"<p>Load Hub by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>hub name.</p> required <code>root_dir</code> <code>str</code> <p>hub root directory. Defaults to None.</p> <code>None</code> <code>train_callbacks</code> <code>list[BaseTrainCallback]</code> <p>Train callbacks. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if hub is not exist in root_dir</p> <p>Returns:</p> Name Type Description <code>Hub</code> <code>Hub</code> <p>Hub instance</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>@classmethod\ndef load(\n    cls, name: str, root_dir: str = None, train_callbacks: list[BaseTrainCallback] = None\n) -&gt; \"Hub\":\n    \"\"\"Load Hub by name.\n\n    Args:\n        name (str): hub name.\n        root_dir (str, optional): hub root directory. Defaults to None.\n        train_callbacks (list[BaseTrainCallback], optional): Train callbacks. Defaults to None.\n\n    Raises:\n        FileNotFoundError: if hub is not exist in root_dir\n\n    Returns:\n        Hub: Hub instance\n    \"\"\"\n    root_dir = Hub.parse_root_dir(root_dir)\n    model_config_file = root_dir / name / BaseManager.CONFIG_DIR / BaseManager.MODEL_CONFIG_FILE\n    if not model_config_file.exists():\n        raise FileNotFoundError(f\"Model[{name}] does not exists. {model_config_file}\")\n    model_config = ModelConfig.load(model_config_file)\n    return cls(\n        **{\n            **model_config.to_dict(),\n            \"root_dir\": root_dir,\n            \"train_callbacks\": train_callbacks,\n        }\n    )\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.new","title":"<code>new(name, backend=None, task=None, model_type=None, model_size=None, categories=None, root_dir=None, train_callbacks=None, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create Hub.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Hub name</p> required <code>backend</code> <code>str</code> <p>Backend name. See Hub.get_available_backends. Defaults to None.</p> <code>None</code> <code>task</code> <code>str</code> <p>Task Name. See Hub.get_available_tasks. Defaults to None.</p> <code>None</code> <code>model_type</code> <code>str</code> <p>Model Type. See Hub.get_available_model_types. Defaults to None.</p> <code>None</code> <code>model_size</code> <code>str</code> <p>Model Size. See Hub.get_available_model_sizes. Defaults to None.</p> <code>None</code> <code>categories</code> <code>Union[list[dict], list]</code> <p>class dictionary or list. [{\"supercategory\": \"name\"}, ] or [\"name\",]. Defaults to None.</p> <code>None</code> <code>root_dir</code> <code>str</code> <p>Root directory of hub repository. Defaults to None.</p> <code>None</code> <code>train_callbacks</code> <code>list[BaseTrainCallback]</code> <p>Train callbacks. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Hub</code> <code>Hub</code> <p>Hub instance</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>@classmethod\ndef new(\n    cls,\n    name: str,\n    backend: str = None,\n    task: str = None,\n    model_type: str = None,\n    model_size: str = None,\n    categories: Union[list[dict], list] = None,\n    root_dir: str = None,\n    train_callbacks: list[BaseTrainCallback] = None,\n    *args,\n    **kwargs,\n) -&gt; \"Hub\":\n    \"\"\"Create Hub.\n\n    Args:\n        name (str): Hub name\n        backend (str, optional): Backend name. See Hub.get_available_backends. Defaults to None.\n        task (str, optional): Task Name. See Hub.get_available_tasks. Defaults to None.\n        model_type (str, optional): Model Type. See Hub.get_available_model_types. Defaults to None.\n        model_size (str, optional): Model Size. See Hub.get_available_model_sizes. Defaults to None.\n        categories (Union[list[dict], list], optional): class dictionary or list. [{\"supercategory\": \"name\"}, ] or [\"name\",]. Defaults to None.\n        root_dir (str, optional): Root directory of hub repository. Defaults to None.\n        train_callbacks (list[BaseTrainCallback], optional): Train callbacks. Defaults to None.\n\n    Returns:\n        Hub: Hub instance\n    \"\"\"\n    root_dir = Hub.parse_root_dir(root_dir)\n\n    if name in cls.get_hub_list(root_dir):\n        raise FileExistsError(f\"{name} already exists. Try another name.\")\n\n    try:\n        backend = backend if backend else cls.get_available_backends()[0]\n        task = TaskType.from_str(task).value if task else cls.get_available_tasks(backend)[0]\n        model_type = (\n            model_type if model_type else cls.get_available_model_types(backend, task)[0]\n        )\n        model_size = (\n            model_size\n            if model_size\n            else cls.get_available_model_sizes(backend, task, model_type)[0]\n        )\n\n        return cls(\n            name=name,\n            backend=backend,\n            task=task,\n            model_type=model_type,\n            model_size=model_size,\n            categories=categories,\n            root_dir=root_dir,\n            train_callbacks=train_callbacks,\n        )\n    except Exception as e:\n        if (root_dir / name).exists():\n            io.remove_directory(root_dir / name, recursive=True)\n        raise e\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.save_model_config","title":"<code>save_model_config()</code>","text":"<p>Save ModelConfig.</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def save_model_config(self):\n    \"\"\"Save ModelConfig.\"\"\"\n    self.manager.save_model_config(self.model_config_file)\n</code></pre>"},{"location":"waffle_hub/hub/hub/#waffle_hub.hub.Hub.train","title":"<code>train(dataset, dataset_root_dir=None, epochs=None, batch_size=None, image_size=None, learning_rate=None, letter_box=None, pretrained_model=None, device='0', workers=2, seed=0, advance_params=None, verbose=True)</code>","text":"<p>Start Train</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[Dataset, str]</code> <p>Waffle Dataset object or path or name.</p> required <code>dataset_root_dir</code> <code>str</code> <p>Waffle Dataset root directory. Defaults to None.</p> <code>None</code> <code>epochs</code> <code>int</code> <p>number of epochs. None to use default. Defaults to None.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>batch size. None to use default. Defaults to None.</p> <code>None</code> <code>image_size</code> <code>Union[int, list[int]]</code> <p>image size. None to use default. Defaults to None.</p> <code>None</code> <code>learning_rate</code> <code>float</code> <p>learning rate. None to use default. Defaults to None.</p> <code>None</code> <code>letter_box</code> <code>bool</code> <p>letter box. None to use default. Defaults to None.</p> <code>None</code> <code>pretrained_model</code> <code>str</code> <p>pretrained model. None to use default. Defaults to None.</p> <code>None</code> <code>device</code> <code>str</code> <p>\"cpu\" or \"gpu_id\" or comma seperated \"gpu_ids\". Defaults to \"0\".</p> <code>'0'</code> <code>workers</code> <code>int</code> <p>number of workers. Defaults to 2.</p> <code>2</code> <code>seed</code> <code>int</code> <p>random seed. Defaults to 0.</p> <code>0</code> <code>advance_params</code> <code>Union[dict, str]</code> <p>advance params dictionary or file (yaml, json) path. Defaults to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>verbose. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>if trained artifact exists.</p> <code>FileNotFoundError</code> <p>if can not detect appropriate dataset.</p> <code>ValueError</code> <p>if can not detect appropriate dataset.</p> <code>e</code> <p>something gone wrong with ultralytics</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; train_result = hub.train(\n        dataset=dataset,\n        epochs=100,\n        batch_size=16,\n        image_size=640,\n        learning_rate=0.001,\n        letterbox=False,\n        device=\"0\",  # use gpu 0\n        # device=\"0,1,2,3\",  # use gpu 0,1,2,3\n        # device=\"cpu\",  # use cpu\n        workers=2,\n        seed=123\n    )\n&gt;&gt;&gt; train_result.best_ckpt_file\nhubs/my_hub/weights/best_ckpt.pt\n&gt;&gt;&gt; train_result.metrics\n[[{\"tag\": \"epoch\", \"value\": 1}, {\"tag\": \"train/loss\", \"value\": 0.1}, ...], ...]\n</code></pre> <p>Returns:</p> Name Type Description <code>TrainResult</code> <code>TrainResult</code> <p>train result</p> Source code in <code>waffle_hub/hub/hub.py</code> <pre><code>def train(\n    self,\n    dataset: Union[Dataset, str, Path],\n    dataset_root_dir: str = None,\n    epochs: int = None,\n    batch_size: int = None,\n    image_size: Union[int, list[int]] = None,\n    learning_rate: float = None,\n    letter_box: bool = None,\n    pretrained_model: str = None,\n    device: str = \"0\",\n    workers: int = 2,\n    seed: int = 0,\n    advance_params: Union[dict, str] = None,\n    verbose: bool = True,\n) -&gt; TrainResult:\n    \"\"\"Start Train\n\n    Args:\n        dataset (Union[Dataset, str]): Waffle Dataset object or path or name.\n        dataset_root_dir (str, optional): Waffle Dataset root directory. Defaults to None.\n        epochs (int, optional): number of epochs. None to use default. Defaults to None.\n        batch_size (int, optional): batch size. None to use default. Defaults to None.\n        image_size (Union[int, list[int]], optional): image size. None to use default. Defaults to None.\n        learning_rate (float, optional): learning rate. None to use default. Defaults to None.\n        letter_box (bool, optional): letter box. None to use default. Defaults to None.\n        pretrained_model (str, optional): pretrained model. None to use default. Defaults to None.\n        device (str, optional):\n            \"cpu\" or \"gpu_id\" or comma seperated \"gpu_ids\". Defaults to \"0\".\n        workers (int, optional): number of workers. Defaults to 2.\n        seed (int, optional): random seed. Defaults to 0.\n        advance_params (Union[dict, str], optional): advance params dictionary or file (yaml, json) path. Defaults to None.\n        verbose (bool, optional): verbose. Defaults to True.\n\n    Raises:\n        FileExistsError: if trained artifact exists.\n        FileNotFoundError: if can not detect appropriate dataset.\n        ValueError: if can not detect appropriate dataset.\n        e: something gone wrong with ultralytics\n\n    Examples:\n        &gt;&gt;&gt; train_result = hub.train(\n                dataset=dataset,\n                epochs=100,\n                batch_size=16,\n                image_size=640,\n                learning_rate=0.001,\n                letterbox=False,\n                device=\"0\",  # use gpu 0\n                # device=\"0,1,2,3\",  # use gpu 0,1,2,3\n                # device=\"cpu\",  # use cpu\n                workers=2,\n                seed=123\n            )\n        &gt;&gt;&gt; train_result.best_ckpt_file\n        hubs/my_hub/weights/best_ckpt.pt\n        &gt;&gt;&gt; train_result.metrics\n        [[{\"tag\": \"epoch\", \"value\": 1}, {\"tag\": \"train/loss\", \"value\": 0.1}, ...], ...]\n\n    Returns:\n        TrainResult: train result\n    \"\"\"\n\n    return self.manager.train(\n        dataset=dataset,\n        dataset_root_dir=dataset_root_dir,\n        epochs=epochs,\n        batch_size=batch_size,\n        image_size=image_size,\n        learning_rate=learning_rate,\n        letter_box=letter_box,\n        pretrained_model=pretrained_model,\n        device=device,\n        workers=workers,\n        seed=seed,\n        advance_params=advance_params,\n        verbose=verbose,\n    )\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/","title":"InferenceCallback","text":"<p>             Bases: <code>BaseCallback</code>, <code>ABC</code></p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>class BaseInferenceCallback(BaseCallback, ABC):\n    def __init__(self):\n        pass\n\n    def setup(self, inferencer: Inferencer) -&gt; None:\n        \"\"\"Called when worker starts.\"\"\"\n\n    def teardown(self, inferencer: Inferencer) -&gt; None:\n        \"\"\"Called when worker ends.\"\"\"\n\n    def before_inference(self, inferencer: Inferencer) -&gt; None:\n        \"\"\"Called when the inference begins.\"\"\"\n\n    def on_inference_start(self, inferencer: Inferencer) -&gt; None:\n        \"\"\"Called when the inference function begins.\"\"\"\n\n    def on_inference_loop_start(\n        self, inferencer: Inferencer, dataset: Dataset, dataloader: DataLoader\n    ) -&gt; None:\n        \"\"\"Called when the inference loop begins.\"\"\"\n\n    def on_inference_step_start(self, inferencer: Inferencer, step: int, batch: Any) -&gt; None:\n        \"\"\"Called when the inference loop step begins.\"\"\"\n\n    def on_inference_step_end(\n        self, inferencer: Inferencer, step: int, batch: Any, result_batch: Any\n    ) -&gt; None:\n        \"\"\"Called when the inference loop step ends.\"\"\"\n\n    def on_inference_loop_end(self, inferencer: Inferencer, result: list[dict]) -&gt; None:\n        \"\"\"Called when the inference loop ends.\"\"\"\n\n    def on_inference_end(self, inferencer: Inferencer) -&gt; None:\n        \"\"\"Called when the inference function ends.\"\"\"\n\n    def after_inference(self, inferencer: Inferencer) -&gt; None:\n        \"\"\"Called when the inference ends.\"\"\"\n\n    def on_exception_stopped(self, inferencer: Inferencer, e: Exception) -&gt; None:\n        \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n\n    def on_exception_failed(self, inferencer: Inferencer, e: Exception) -&gt; None:\n        \"\"\"Called when an error occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.after_inference","title":"<code>after_inference(inferencer)</code>","text":"<p>Called when the inference ends.</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def after_inference(self, inferencer: Inferencer) -&gt; None:\n    \"\"\"Called when the inference ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.before_inference","title":"<code>before_inference(inferencer)</code>","text":"<p>Called when the inference begins.</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def before_inference(self, inferencer: Inferencer) -&gt; None:\n    \"\"\"Called when the inference begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.on_exception_failed","title":"<code>on_exception_failed(inferencer, e)</code>","text":"<p>Called when an error occurs</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def on_exception_failed(self, inferencer: Inferencer, e: Exception) -&gt; None:\n    \"\"\"Called when an error occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.on_exception_stopped","title":"<code>on_exception_stopped(inferencer, e)</code>","text":"<p>Called when SIGTERM or SIGINT occurs</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def on_exception_stopped(self, inferencer: Inferencer, e: Exception) -&gt; None:\n    \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.on_inference_end","title":"<code>on_inference_end(inferencer)</code>","text":"<p>Called when the inference function ends.</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def on_inference_end(self, inferencer: Inferencer) -&gt; None:\n    \"\"\"Called when the inference function ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.on_inference_loop_end","title":"<code>on_inference_loop_end(inferencer, result)</code>","text":"<p>Called when the inference loop ends.</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def on_inference_loop_end(self, inferencer: Inferencer, result: list[dict]) -&gt; None:\n    \"\"\"Called when the inference loop ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.on_inference_loop_start","title":"<code>on_inference_loop_start(inferencer, dataset, dataloader)</code>","text":"<p>Called when the inference loop begins.</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def on_inference_loop_start(\n    self, inferencer: Inferencer, dataset: Dataset, dataloader: DataLoader\n) -&gt; None:\n    \"\"\"Called when the inference loop begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.on_inference_start","title":"<code>on_inference_start(inferencer)</code>","text":"<p>Called when the inference function begins.</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def on_inference_start(self, inferencer: Inferencer) -&gt; None:\n    \"\"\"Called when the inference function begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.on_inference_step_end","title":"<code>on_inference_step_end(inferencer, step, batch, result_batch)</code>","text":"<p>Called when the inference loop step ends.</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def on_inference_step_end(\n    self, inferencer: Inferencer, step: int, batch: Any, result_batch: Any\n) -&gt; None:\n    \"\"\"Called when the inference loop step ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.on_inference_step_start","title":"<code>on_inference_step_start(inferencer, step, batch)</code>","text":"<p>Called when the inference loop step begins.</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def on_inference_step_start(self, inferencer: Inferencer, step: int, batch: Any) -&gt; None:\n    \"\"\"Called when the inference loop step begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.setup","title":"<code>setup(inferencer)</code>","text":"<p>Called when worker starts.</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def setup(self, inferencer: Inferencer) -&gt; None:\n    \"\"\"Called when worker starts.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/callbacks/#waffle_hub.hub.inferencer.callbacks.BaseInferenceCallback.teardown","title":"<code>teardown(inferencer)</code>","text":"<p>Called when worker ends.</p> Source code in <code>waffle_hub/hub/inferencer/callbacks/base_callback.py</code> <pre><code>def teardown(self, inferencer: Inferencer) -&gt; None:\n    \"\"\"Called when worker ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/","title":"InferenceHook","text":"<p>             Bases: <code>BaseHook</code></p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>class BaseInferenceHook(BaseHook):\n    def __init__(self, callbacks: list[BaseCallback] = None):\n        super().__init__(callbacks)\n\n    def setup(self) -&gt; None:\n        \"\"\"Called when worker starts.\"\"\"\n        _register_signal_handler()\n\n    def teardown(self) -&gt; None:\n        \"\"\"Called when worker ends.\"\"\"\n\n    def before_inference(self) -&gt; None:\n        \"\"\"Called when the inference begins.\"\"\"\n\n    def on_inference_start(self) -&gt; None:\n        \"\"\"Called when the inference function begins.\"\"\"\n        self.state.status = InferenceStatus.RUNNING\n        self.state.clear_error()\n\n    def on_inference_loop_start(self, dataset: Dataset, dataloader: DataLoader) -&gt; None:\n        \"\"\"Called when the inference loop begins.\"\"\"\n        self.state.total_step = len(dataloader) + 1\n        self.state.step = 0\n\n    def on_inference_step_start(self, step: int, batch: Any) -&gt; None:\n        \"\"\"Called when the inference loop step begins.\"\"\"\n\n    def on_inference_step_end(self, step: int, batch: Any, result_batch: Any) -&gt; None:\n        \"\"\"Called when the inference loop step ends.\"\"\"\n        self.state.step = step\n\n    def on_inference_loop_end(self, result: list[dict]) -&gt; None:\n        \"\"\"Called when the inference loop ends.\"\"\"\n\n    def on_inference_end(self) -&gt; None:\n        \"\"\"Called when the inference function ends.\"\"\"\n\n    def after_inference(self) -&gt; None:\n        \"\"\"Called when the inference ends.\"\"\"\n        self.state.step = self.state.total_step\n        self.state.status = InferenceStatus.SUCCESS\n\n    def on_exception_stopped(self, e: Exception) -&gt; None:\n        \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n        self.state.status = InferenceStatus.STOPPED\n        self.state.set_error(e)\n\n    def on_exception_failed(self, e: Exception) -&gt; None:\n        \"\"\"Called when an error occurs\"\"\"\n        self.state.status = InferenceStatus.FAILED\n        self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.after_inference","title":"<code>after_inference()</code>","text":"<p>Called when the inference ends.</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def after_inference(self) -&gt; None:\n    \"\"\"Called when the inference ends.\"\"\"\n    self.state.step = self.state.total_step\n    self.state.status = InferenceStatus.SUCCESS\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.before_inference","title":"<code>before_inference()</code>","text":"<p>Called when the inference begins.</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def before_inference(self) -&gt; None:\n    \"\"\"Called when the inference begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.on_exception_failed","title":"<code>on_exception_failed(e)</code>","text":"<p>Called when an error occurs</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def on_exception_failed(self, e: Exception) -&gt; None:\n    \"\"\"Called when an error occurs\"\"\"\n    self.state.status = InferenceStatus.FAILED\n    self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.on_exception_stopped","title":"<code>on_exception_stopped(e)</code>","text":"<p>Called when SIGTERM or SIGINT occurs</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def on_exception_stopped(self, e: Exception) -&gt; None:\n    \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n    self.state.status = InferenceStatus.STOPPED\n    self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.on_inference_end","title":"<code>on_inference_end()</code>","text":"<p>Called when the inference function ends.</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def on_inference_end(self) -&gt; None:\n    \"\"\"Called when the inference function ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.on_inference_loop_end","title":"<code>on_inference_loop_end(result)</code>","text":"<p>Called when the inference loop ends.</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def on_inference_loop_end(self, result: list[dict]) -&gt; None:\n    \"\"\"Called when the inference loop ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.on_inference_loop_start","title":"<code>on_inference_loop_start(dataset, dataloader)</code>","text":"<p>Called when the inference loop begins.</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def on_inference_loop_start(self, dataset: Dataset, dataloader: DataLoader) -&gt; None:\n    \"\"\"Called when the inference loop begins.\"\"\"\n    self.state.total_step = len(dataloader) + 1\n    self.state.step = 0\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.on_inference_start","title":"<code>on_inference_start()</code>","text":"<p>Called when the inference function begins.</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def on_inference_start(self) -&gt; None:\n    \"\"\"Called when the inference function begins.\"\"\"\n    self.state.status = InferenceStatus.RUNNING\n    self.state.clear_error()\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.on_inference_step_end","title":"<code>on_inference_step_end(step, batch, result_batch)</code>","text":"<p>Called when the inference loop step ends.</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def on_inference_step_end(self, step: int, batch: Any, result_batch: Any) -&gt; None:\n    \"\"\"Called when the inference loop step ends.\"\"\"\n    self.state.step = step\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.on_inference_step_start","title":"<code>on_inference_step_start(step, batch)</code>","text":"<p>Called when the inference loop step begins.</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def on_inference_step_start(self, step: int, batch: Any) -&gt; None:\n    \"\"\"Called when the inference loop step begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.setup","title":"<code>setup()</code>","text":"<p>Called when worker starts.</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def setup(self) -&gt; None:\n    \"\"\"Called when worker starts.\"\"\"\n    _register_signal_handler()\n</code></pre>"},{"location":"waffle_hub/inferencer/hook/#waffle_hub.hub.inferencer.hook.BaseInferenceHook.teardown","title":"<code>teardown()</code>","text":"<p>Called when worker ends.</p> Source code in <code>waffle_hub/hub/inferencer/hook.py</code> <pre><code>def teardown(self) -&gt; None:\n    \"\"\"Called when worker ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/inferencer/inferencer/","title":"Inferencer","text":"<p>             Bases: <code>BaseInferenceHook</code></p> <p>Inference manager class</p> Source code in <code>waffle_hub/hub/inferencer/inferencer.py</code> <pre><code>class Inferencer(BaseInferenceHook):\n    \"\"\"\n    Inference manager class\n    \"\"\"\n\n    # directory settting\n    INFERENCE_DIR = Path(\"inferences\")\n    DRAW_DIR = INFERENCE_DIR / Path(\"draws\")\n\n    # inference results file path ###--\n    INFERENCE_FILE = INFERENCE_DIR / \"inferences.json\"\n\n    def __init__(\n        self,\n        root_dir: Path,\n        model: ModelWrapper,\n        callbacks: list[BaseCallback] = None,\n    ):\n        super().__init__(callbacks)\n        self.root_dir = Path(root_dir)\n        self.model = model\n        self.state = InferenceState(status=InferenceStatus.INIT)\n        self.result = InferenceResult()\n\n    # properties\n    @property\n    def inference_dir(self) -&gt; Path:\n        \"\"\"Inference Results Directory\"\"\"\n        return self.root_dir / self.INFERENCE_DIR\n\n    @property\n    def draw_dir(self) -&gt; Path:\n        \"\"\"Draw Results Directory\"\"\"\n        return self.root_dir / self.DRAW_DIR\n\n    @property\n    def inference_file(self) -&gt; Path:\n        \"\"\"Inference Results File path\"\"\"\n        return self.root_dir / self.INFERENCE_FILE\n\n    @classmethod\n    def get_inference_result(cls, root_dir: Union[str, Path]) -&gt; list[dict]:\n        \"\"\"Get inference result from inference file.\n\n        Args:\n            root_dir (Union[str, Path]): root directory of inference file\n\n        Examples:\n            &gt;&gt;&gt; Inferencer.get_inference_result(root_dir)\n            [\n                {\n                    \"id\": \"00000001\",\n                    \"category\": \"person\",\n                    \"bbox\": [0.1, 0.2, 0.3, 0.4],\n                    \"score\": 0.9,\n                },\n            ]\n\n        Returns:\n            list[dict]: inference result\n        \"\"\"\n        inference_file_path = Path(root_dir) / cls.INFERENCE_FILE\n        if not inference_file_path.exists():\n            warnings.warn(f\"inference file {inference_file_path} is not exist. Inference First.\")\n            return []\n        return io.load_json(inference_file_path)\n\n    # methods\n    @device_context\n    def inference(\n        self,\n        source: Union[str, Path],\n        recursive: bool = True,\n        image_size: Union[int, list[int]] = 224,\n        letter_box: bool = True,\n        batch_size: int = 4,\n        confidence_threshold: float = 0.25,\n        iou_threshold: float = 0.5,\n        half: bool = False,\n        workers: int = 2,\n        device: str = \"0\",\n    ) -&gt; InferenceResult:\n        \"\"\"Start Inference\n\n        Args:\n            source (Union[str, Path]): image directory or image path or video path.\n            recursive (bool, optional): recursive. Defaults to True.\n            image_size (Union[int, list[int]], optional): image size. Defaults to 224.\n            letter_box (bool, optional): letter box. Defaults to True.\n            batch_size (int, optional): batch size. Defaults to 4.\n            confidence_threshold (float, optional): confidence threshold. Not required in classification. Defaults to 0.25.\n            iou_threshold (float, optional): iou threshold. Not required in classification. Defaults to 0.5.\n            half (bool, optional): half. Defaults to False.\n            workers (int, optional): workers. Defaults to 2.\n            device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n\n        Raises:\n            FileNotFoundError: if can not detect appropriate dataset.\n            e: something gone wrong with ultralytics\n\n        Examples:\n            &gt;&gt;&gt; inferencer = Inferencer(...)\n            &gt;&gt;&gt; inference_result = hub.inference(\n                    source=\"path/to/images\",\n                    batch_size=4,\n                    image_size=640,\n                    letterbox=False,\n                    confidence_threshold=0.25,\n                    iou_threshold=0.5,\n                    workers=4,\n                    device=\"0\",\n                )\n            &gt;&gt;&gt; inference_result.predictions\n            [{\"relative/path/to/image/file\": [{\"category\": \"1\", \"bbox\": [0, 0, 100, 100], \"score\": 0.9}, ...]}, ...]\n\n        Returns:\n            InferenceResult: inference result\n        \"\"\"\n\n        try:\n            self.run_default_hook(\"setup\")\n            self.run_callback_hooks(\"setup\", self)\n\n            # inference settings\n            # image_dir, image_path, video_path, dataset_name, dataset\n            if isinstance(source, (str, Path)):\n                if Path(source).exists():\n                    source = Path(source)\n                    if source.is_dir():\n                        source = source.absolute()\n                        source_type = \"image\"\n                    elif source.suffix in IMAGE_EXTS:\n                        source = source.absolute()\n                        source_type = \"image\"\n                    elif source.suffix in VIDEO_EXTS:\n                        source = str(source.absolute())\n                        source_type = \"video\"\n                    else:\n                        raise ValueError(\n                            f\"Invalid source: {source}\\n\"\n                            + \"Please use image directory or image path or video path.\"\n                        )\n                else:\n                    raise FileNotFoundError(f\"Source {source} is not exist.\")\n            else:\n                raise ValueError(\n                    f\"Invalid source: {source}\\n\"\n                    + \"Please use image directory or image path or video path.\"\n                )\n\n            self.cfg = InferenceConfig(\n                source=source,\n                source_type=source_type,\n                batch_size=batch_size,\n                recursive=recursive,\n                image_size=image_size if isinstance(image_size, list) else [image_size, image_size],\n                letter_box=letter_box,\n                confidence_threshold=confidence_threshold,\n                iou_threshold=iou_threshold,\n                half=half,\n                workers=workers,\n                device=\"cpu\" if device == \"cpu\" else f\"cuda:{device}\",\n            )\n            self.run_default_hook(\"before_inference\")\n            self.run_callback_hooks(\"before_inference\", self)\n\n            # run inference\n            self._inference()\n\n            self.run_default_hook(\"after_inference\")\n            self.run_callback_hooks(\"after_inference\", self)\n\n        except (KeyboardInterrupt, SystemExit) as e:\n            self.run_default_hook(\"on_exception_stopped\", e)\n            self.run_callback_hooks(\"on_exception_stopped\", self, e)\n            raise e\n        except Exception as e:\n            self.run_default_hook(\"on_exception_failed\", e)\n            self.run_callback_hooks(\"on_exception_failed\", self, e)\n            # if self.inference_dir.exists():\n            #     io.remove_directory(self.inference_dir, recursive=True)\n            raise e\n        finally:\n            self.run_default_hook(\"teardown\")\n            self.run_callback_hooks(\"teardown\", self)\n\n        return self.result\n\n    def benchmark(\n        self,\n        image_size: Union[int, list[int]] = 224,\n        batch_size: int = 16,\n        device: str = \"0\",\n        half: bool = False,\n        trial: int = 100,\n    ) -&gt; dict:\n        \"\"\"Benchmark Model\n\n        Args:\n            image_size (Union[int, list[int]], optional): Inference image size. Defaults to 224.\n            batch_size (int, optional): dynamic batch size. Defaults to 16.\n            device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n            half (bool, optional): half. Defaults to False.\n            trial (int, optional): number of trials. Defaults to 100.\n\n        Examples:\n            &gt;&gt;&gt; inferencer = Inferencer(...)\n            &gt;&gt;&gt; inferencer.benchmark(\n                    image_size=640,\n                    batch_size=16,\n                    device=\"0\",\n                    half=False,\n                    trial=100,\n                )\n            {\n                \"inference_time\": 0.123,\n                \"fps\": 123.123,\n                \"image_size\": [640, 640],\n                \"batch_size\": 16,\n                \"device\": \"0\",\n                \"cpu_name\": \"Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz\",\n                \"gpu_name\": \"GeForce GTX 1080 Ti\",\n            }\n\n        Returns:\n            dict: benchmark result\n        \"\"\"\n\n        if half and (not torch.cuda.is_available() or device == \"cpu\"):\n            raise RuntimeError(\"half is not supported in cpu\")\n\n        image_size = [image_size, image_size] if isinstance(image_size, int) else image_size\n\n        device = \"cpu\" if device == \"cpu\" else f\"cuda:{device}\"\n\n        self.model = self.model.to(device) if not half else self.model.half().to(device)\n\n        dummy_input = torch.randn(\n            batch_size, 3, *image_size, dtype=torch.float32 if not half else torch.float16\n        )\n        dummy_input = dummy_input.to(device)\n\n        self.model.eval()\n        with torch.no_grad():\n            start = time.time()\n            for _ in tqdm.tqdm(range(trial)):\n                self.model(dummy_input)\n            end = time.time()\n            inference_time = end - start\n\n        return {\n            \"inference_time\": inference_time,\n            # image throughput per second\n            \"fps\": trial * batch_size / inference_time,\n            \"image_size\": image_size,\n            \"batch_size\": batch_size,\n            \"precision\": \"fp16\" if half else \"fp32\",\n            \"device\": device,\n            \"cpu_name\": cpuinfo.get_cpu_info()[\"brand_raw\"],\n            \"gpu_name\": torch.cuda.get_device_name(0) if device != \"cpu\" else None,\n        }\n\n    def _inference(self) -&gt; str:\n        self.run_default_hook(\"on_inference_start\")\n        self.run_callback_hooks(\"on_inference_start\", self)\n\n        device = self.cfg.device\n        model = self.model.to(device)\n        result_parser = get_parser(self.model.task)(\n            **self.cfg.to_dict(), categories=self.model.categories\n        )\n\n        if self.cfg.source_type == \"image\":\n            dataset = get_dataset_class(self.cfg.source_type)(\n                self.cfg.source,\n                self.cfg.image_size,\n                letter_box=self.cfg.letter_box,\n                recursive=self.cfg.recursive,\n            )\n            dataloader = dataset.get_dataloader(self.cfg.batch_size, self.cfg.workers)\n        elif self.cfg.source_type == \"video\":\n            dataset = get_dataset_class(self.cfg.source_type)(\n                self.cfg.source,\n                self.cfg.image_size,\n                letter_box=self.cfg.letter_box,\n            )\n            dataloader = dataset.get_dataloader(self.cfg.batch_size, self.cfg.workers)\n        else:\n            raise ValueError(f\"Invalid source type: {self.cfg.source_type}\")\n\n        self.run_default_hook(\"on_inference_loop_start\", dataset, dataloader)\n        self.run_callback_hooks(\"on_inference_loop_start\", self, dataset, dataloader)\n\n        results = []\n        for i, batch in tqdm.tqdm(enumerate(dataloader, start=1), total=len(dataloader)):\n            self.run_default_hook(\"on_inference_step_start\", i, batch)\n            self.run_callback_hooks(\"on_inference_step_start\", self, i, batch)\n            images, image_infos = batch\n\n            result_batch = model(images.to(device))\n            result_batch = result_parser(result_batch, image_infos)\n\n            for result, image_info in zip(result_batch, image_infos):\n                results.append({str(image_info.image_rel_path): [res.to_dict() for res in result]})\n\n            self.run_default_hook(\"on_inference_step_end\", i, batch, result_batch)\n            self.run_callback_hooks(\"on_inference_step_end\", self, i, batch, result_batch)\n\n        self.run_default_hook(\"on_inference_loop_end\", results)\n        self.run_callback_hooks(\"on_inference_loop_end\", self, results)\n\n        self.result.predictions = results\n        io.save_json(\n            results,\n            self.inference_file,\n            create_directory=True,\n        )\n\n        self.run_default_hook(\"on_inference_end\")\n        self.run_callback_hooks(\"on_inference_end\", self)\n</code></pre>"},{"location":"waffle_hub/inferencer/inferencer/#waffle_hub.hub.inferencer.inferencer.Inferencer.draw_dir","title":"<code>draw_dir: Path</code>  <code>property</code>","text":"<p>Draw Results Directory</p>"},{"location":"waffle_hub/inferencer/inferencer/#waffle_hub.hub.inferencer.inferencer.Inferencer.inference_dir","title":"<code>inference_dir: Path</code>  <code>property</code>","text":"<p>Inference Results Directory</p>"},{"location":"waffle_hub/inferencer/inferencer/#waffle_hub.hub.inferencer.inferencer.Inferencer.inference_file","title":"<code>inference_file: Path</code>  <code>property</code>","text":"<p>Inference Results File path</p>"},{"location":"waffle_hub/inferencer/inferencer/#waffle_hub.hub.inferencer.inferencer.Inferencer.benchmark","title":"<code>benchmark(image_size=224, batch_size=16, device='0', half=False, trial=100)</code>","text":"<p>Benchmark Model</p> <p>Parameters:</p> Name Type Description Default <code>image_size</code> <code>Union[int, list[int]]</code> <p>Inference image size. Defaults to 224.</p> <code>224</code> <code>batch_size</code> <code>int</code> <p>dynamic batch size. Defaults to 16.</p> <code>16</code> <code>device</code> <code>str</code> <p>device. \"cpu\" or \"gpu_id\". Defaults to \"0\".</p> <code>'0'</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>trial</code> <code>int</code> <p>number of trials. Defaults to 100.</p> <code>100</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; inferencer = Inferencer(...)\n&gt;&gt;&gt; inferencer.benchmark(\n        image_size=640,\n        batch_size=16,\n        device=\"0\",\n        half=False,\n        trial=100,\n    )\n{\n    \"inference_time\": 0.123,\n    \"fps\": 123.123,\n    \"image_size\": [640, 640],\n    \"batch_size\": 16,\n    \"device\": \"0\",\n    \"cpu_name\": \"Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz\",\n    \"gpu_name\": \"GeForce GTX 1080 Ti\",\n}\n</code></pre> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>benchmark result</p> Source code in <code>waffle_hub/hub/inferencer/inferencer.py</code> <pre><code>def benchmark(\n    self,\n    image_size: Union[int, list[int]] = 224,\n    batch_size: int = 16,\n    device: str = \"0\",\n    half: bool = False,\n    trial: int = 100,\n) -&gt; dict:\n    \"\"\"Benchmark Model\n\n    Args:\n        image_size (Union[int, list[int]], optional): Inference image size. Defaults to 224.\n        batch_size (int, optional): dynamic batch size. Defaults to 16.\n        device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n        half (bool, optional): half. Defaults to False.\n        trial (int, optional): number of trials. Defaults to 100.\n\n    Examples:\n        &gt;&gt;&gt; inferencer = Inferencer(...)\n        &gt;&gt;&gt; inferencer.benchmark(\n                image_size=640,\n                batch_size=16,\n                device=\"0\",\n                half=False,\n                trial=100,\n            )\n        {\n            \"inference_time\": 0.123,\n            \"fps\": 123.123,\n            \"image_size\": [640, 640],\n            \"batch_size\": 16,\n            \"device\": \"0\",\n            \"cpu_name\": \"Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz\",\n            \"gpu_name\": \"GeForce GTX 1080 Ti\",\n        }\n\n    Returns:\n        dict: benchmark result\n    \"\"\"\n\n    if half and (not torch.cuda.is_available() or device == \"cpu\"):\n        raise RuntimeError(\"half is not supported in cpu\")\n\n    image_size = [image_size, image_size] if isinstance(image_size, int) else image_size\n\n    device = \"cpu\" if device == \"cpu\" else f\"cuda:{device}\"\n\n    self.model = self.model.to(device) if not half else self.model.half().to(device)\n\n    dummy_input = torch.randn(\n        batch_size, 3, *image_size, dtype=torch.float32 if not half else torch.float16\n    )\n    dummy_input = dummy_input.to(device)\n\n    self.model.eval()\n    with torch.no_grad():\n        start = time.time()\n        for _ in tqdm.tqdm(range(trial)):\n            self.model(dummy_input)\n        end = time.time()\n        inference_time = end - start\n\n    return {\n        \"inference_time\": inference_time,\n        # image throughput per second\n        \"fps\": trial * batch_size / inference_time,\n        \"image_size\": image_size,\n        \"batch_size\": batch_size,\n        \"precision\": \"fp16\" if half else \"fp32\",\n        \"device\": device,\n        \"cpu_name\": cpuinfo.get_cpu_info()[\"brand_raw\"],\n        \"gpu_name\": torch.cuda.get_device_name(0) if device != \"cpu\" else None,\n    }\n</code></pre>"},{"location":"waffle_hub/inferencer/inferencer/#waffle_hub.hub.inferencer.inferencer.Inferencer.get_inference_result","title":"<code>get_inference_result(root_dir)</code>  <code>classmethod</code>","text":"<p>Get inference result from inference file.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>Union[str, Path]</code> <p>root directory of inference file</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; Inferencer.get_inference_result(root_dir)\n[\n    {\n        \"id\": \"00000001\",\n        \"category\": \"person\",\n        \"bbox\": [0.1, 0.2, 0.3, 0.4],\n        \"score\": 0.9,\n    },\n]\n</code></pre> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: inference result</p> Source code in <code>waffle_hub/hub/inferencer/inferencer.py</code> <pre><code>@classmethod\ndef get_inference_result(cls, root_dir: Union[str, Path]) -&gt; list[dict]:\n    \"\"\"Get inference result from inference file.\n\n    Args:\n        root_dir (Union[str, Path]): root directory of inference file\n\n    Examples:\n        &gt;&gt;&gt; Inferencer.get_inference_result(root_dir)\n        [\n            {\n                \"id\": \"00000001\",\n                \"category\": \"person\",\n                \"bbox\": [0.1, 0.2, 0.3, 0.4],\n                \"score\": 0.9,\n            },\n        ]\n\n    Returns:\n        list[dict]: inference result\n    \"\"\"\n    inference_file_path = Path(root_dir) / cls.INFERENCE_FILE\n    if not inference_file_path.exists():\n        warnings.warn(f\"inference file {inference_file_path} is not exist. Inference First.\")\n        return []\n    return io.load_json(inference_file_path)\n</code></pre>"},{"location":"waffle_hub/inferencer/inferencer/#waffle_hub.hub.inferencer.inferencer.Inferencer.inference","title":"<code>inference(source, recursive=True, image_size=224, letter_box=True, batch_size=4, confidence_threshold=0.25, iou_threshold=0.5, half=False, workers=2, device='0')</code>","text":"<p>Start Inference</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Union[str, Path]</code> <p>image directory or image path or video path.</p> required <code>recursive</code> <code>bool</code> <p>recursive. Defaults to True.</p> <code>True</code> <code>image_size</code> <code>Union[int, list[int]]</code> <p>image size. Defaults to 224.</p> <code>224</code> <code>letter_box</code> <code>bool</code> <p>letter box. Defaults to True.</p> <code>True</code> <code>batch_size</code> <code>int</code> <p>batch size. Defaults to 4.</p> <code>4</code> <code>confidence_threshold</code> <code>float</code> <p>confidence threshold. Not required in classification. Defaults to 0.25.</p> <code>0.25</code> <code>iou_threshold</code> <code>float</code> <p>iou threshold. Not required in classification. Defaults to 0.5.</p> <code>0.5</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>workers</code> <code>int</code> <p>workers. Defaults to 2.</p> <code>2</code> <code>device</code> <code>str</code> <p>device. \"cpu\" or \"gpu_id\". Defaults to \"0\".</p> <code>'0'</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>if can not detect appropriate dataset.</p> <code>e</code> <p>something gone wrong with ultralytics</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; inferencer = Inferencer(...)\n&gt;&gt;&gt; inference_result = hub.inference(\n        source=\"path/to/images\",\n        batch_size=4,\n        image_size=640,\n        letterbox=False,\n        confidence_threshold=0.25,\n        iou_threshold=0.5,\n        workers=4,\n        device=\"0\",\n    )\n&gt;&gt;&gt; inference_result.predictions\n[{\"relative/path/to/image/file\": [{\"category\": \"1\", \"bbox\": [0, 0, 100, 100], \"score\": 0.9}, ...]}, ...]\n</code></pre> <p>Returns:</p> Name Type Description <code>InferenceResult</code> <code>InferenceResult</code> <p>inference result</p> Source code in <code>waffle_hub/hub/inferencer/inferencer.py</code> <pre><code>@device_context\ndef inference(\n    self,\n    source: Union[str, Path],\n    recursive: bool = True,\n    image_size: Union[int, list[int]] = 224,\n    letter_box: bool = True,\n    batch_size: int = 4,\n    confidence_threshold: float = 0.25,\n    iou_threshold: float = 0.5,\n    half: bool = False,\n    workers: int = 2,\n    device: str = \"0\",\n) -&gt; InferenceResult:\n    \"\"\"Start Inference\n\n    Args:\n        source (Union[str, Path]): image directory or image path or video path.\n        recursive (bool, optional): recursive. Defaults to True.\n        image_size (Union[int, list[int]], optional): image size. Defaults to 224.\n        letter_box (bool, optional): letter box. Defaults to True.\n        batch_size (int, optional): batch size. Defaults to 4.\n        confidence_threshold (float, optional): confidence threshold. Not required in classification. Defaults to 0.25.\n        iou_threshold (float, optional): iou threshold. Not required in classification. Defaults to 0.5.\n        half (bool, optional): half. Defaults to False.\n        workers (int, optional): workers. Defaults to 2.\n        device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n\n    Raises:\n        FileNotFoundError: if can not detect appropriate dataset.\n        e: something gone wrong with ultralytics\n\n    Examples:\n        &gt;&gt;&gt; inferencer = Inferencer(...)\n        &gt;&gt;&gt; inference_result = hub.inference(\n                source=\"path/to/images\",\n                batch_size=4,\n                image_size=640,\n                letterbox=False,\n                confidence_threshold=0.25,\n                iou_threshold=0.5,\n                workers=4,\n                device=\"0\",\n            )\n        &gt;&gt;&gt; inference_result.predictions\n        [{\"relative/path/to/image/file\": [{\"category\": \"1\", \"bbox\": [0, 0, 100, 100], \"score\": 0.9}, ...]}, ...]\n\n    Returns:\n        InferenceResult: inference result\n    \"\"\"\n\n    try:\n        self.run_default_hook(\"setup\")\n        self.run_callback_hooks(\"setup\", self)\n\n        # inference settings\n        # image_dir, image_path, video_path, dataset_name, dataset\n        if isinstance(source, (str, Path)):\n            if Path(source).exists():\n                source = Path(source)\n                if source.is_dir():\n                    source = source.absolute()\n                    source_type = \"image\"\n                elif source.suffix in IMAGE_EXTS:\n                    source = source.absolute()\n                    source_type = \"image\"\n                elif source.suffix in VIDEO_EXTS:\n                    source = str(source.absolute())\n                    source_type = \"video\"\n                else:\n                    raise ValueError(\n                        f\"Invalid source: {source}\\n\"\n                        + \"Please use image directory or image path or video path.\"\n                    )\n            else:\n                raise FileNotFoundError(f\"Source {source} is not exist.\")\n        else:\n            raise ValueError(\n                f\"Invalid source: {source}\\n\"\n                + \"Please use image directory or image path or video path.\"\n            )\n\n        self.cfg = InferenceConfig(\n            source=source,\n            source_type=source_type,\n            batch_size=batch_size,\n            recursive=recursive,\n            image_size=image_size if isinstance(image_size, list) else [image_size, image_size],\n            letter_box=letter_box,\n            confidence_threshold=confidence_threshold,\n            iou_threshold=iou_threshold,\n            half=half,\n            workers=workers,\n            device=\"cpu\" if device == \"cpu\" else f\"cuda:{device}\",\n        )\n        self.run_default_hook(\"before_inference\")\n        self.run_callback_hooks(\"before_inference\", self)\n\n        # run inference\n        self._inference()\n\n        self.run_default_hook(\"after_inference\")\n        self.run_callback_hooks(\"after_inference\", self)\n\n    except (KeyboardInterrupt, SystemExit) as e:\n        self.run_default_hook(\"on_exception_stopped\", e)\n        self.run_callback_hooks(\"on_exception_stopped\", self, e)\n        raise e\n    except Exception as e:\n        self.run_default_hook(\"on_exception_failed\", e)\n        self.run_callback_hooks(\"on_exception_failed\", self, e)\n        # if self.inference_dir.exists():\n        #     io.remove_directory(self.inference_dir, recursive=True)\n        raise e\n    finally:\n        self.run_default_hook(\"teardown\")\n        self.run_callback_hooks(\"teardown\", self)\n\n    return self.result\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/","title":"TrainCallback","text":"<p>             Bases: <code>BaseCallback</code></p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>class BaseTrainCallback(BaseCallback):\n    def setup(self, manager: BaseManager) -&gt; None:\n        \"\"\"Called when worker starts.\"\"\"\n\n    def teardown(self, manager: BaseManager) -&gt; None:\n        \"\"\"Called when worker ends.\"\"\"\n\n    def before_train(self, manager: BaseManager) -&gt; None:\n        \"\"\"Called when the train begins.\"\"\"\n\n    def on_train_start(self, manager: BaseManager) -&gt; None:\n        \"\"\"Called when the train function begins.\"\"\"\n\n    def training(self, manager: BaseManager) -&gt; None:\n        \"\"\"Called when the training\"\"\"\n\n    def on_train_end(self, manager: BaseManager) -&gt; None:\n        \"\"\"Called when the train function ends.\"\"\"\n\n    def after_train(self, manager: BaseManager) -&gt; None:\n        \"\"\"Called when the train ends.\"\"\"\n\n    def on_evaluate_start(self, manager: BaseManager) -&gt; None:\n        \"\"\"Called when the evaluate function begins.\"\"\"\n\n    def on_evaluate_end(self, manager: BaseManager) -&gt; None:\n        \"\"\"Called when the evaluate function ends.\"\"\"\n\n    def on_exception_stopped(self, manager: BaseManager, e: Exception) -&gt; None:\n        \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n\n    def on_exception_failed(self, manager: BaseManager, e: Exception) -&gt; None:\n        \"\"\"Called when an error occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/#waffle_hub.hub.manager.callbacks.BaseTrainCallback.after_train","title":"<code>after_train(manager)</code>","text":"<p>Called when the train ends.</p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>def after_train(self, manager: BaseManager) -&gt; None:\n    \"\"\"Called when the train ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/#waffle_hub.hub.manager.callbacks.BaseTrainCallback.before_train","title":"<code>before_train(manager)</code>","text":"<p>Called when the train begins.</p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>def before_train(self, manager: BaseManager) -&gt; None:\n    \"\"\"Called when the train begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/#waffle_hub.hub.manager.callbacks.BaseTrainCallback.on_evaluate_end","title":"<code>on_evaluate_end(manager)</code>","text":"<p>Called when the evaluate function ends.</p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>def on_evaluate_end(self, manager: BaseManager) -&gt; None:\n    \"\"\"Called when the evaluate function ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/#waffle_hub.hub.manager.callbacks.BaseTrainCallback.on_evaluate_start","title":"<code>on_evaluate_start(manager)</code>","text":"<p>Called when the evaluate function begins.</p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>def on_evaluate_start(self, manager: BaseManager) -&gt; None:\n    \"\"\"Called when the evaluate function begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/#waffle_hub.hub.manager.callbacks.BaseTrainCallback.on_exception_failed","title":"<code>on_exception_failed(manager, e)</code>","text":"<p>Called when an error occurs</p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>def on_exception_failed(self, manager: BaseManager, e: Exception) -&gt; None:\n    \"\"\"Called when an error occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/#waffle_hub.hub.manager.callbacks.BaseTrainCallback.on_exception_stopped","title":"<code>on_exception_stopped(manager, e)</code>","text":"<p>Called when SIGTERM or SIGINT occurs</p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>def on_exception_stopped(self, manager: BaseManager, e: Exception) -&gt; None:\n    \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/#waffle_hub.hub.manager.callbacks.BaseTrainCallback.on_train_end","title":"<code>on_train_end(manager)</code>","text":"<p>Called when the train function ends.</p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>def on_train_end(self, manager: BaseManager) -&gt; None:\n    \"\"\"Called when the train function ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/#waffle_hub.hub.manager.callbacks.BaseTrainCallback.on_train_start","title":"<code>on_train_start(manager)</code>","text":"<p>Called when the train function begins.</p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>def on_train_start(self, manager: BaseManager) -&gt; None:\n    \"\"\"Called when the train function begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/#waffle_hub.hub.manager.callbacks.BaseTrainCallback.setup","title":"<code>setup(manager)</code>","text":"<p>Called when worker starts.</p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>def setup(self, manager: BaseManager) -&gt; None:\n    \"\"\"Called when worker starts.\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/#waffle_hub.hub.manager.callbacks.BaseTrainCallback.teardown","title":"<code>teardown(manager)</code>","text":"<p>Called when worker ends.</p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>def teardown(self, manager: BaseManager) -&gt; None:\n    \"\"\"Called when worker ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/callbacks/#waffle_hub.hub.manager.callbacks.BaseTrainCallback.training","title":"<code>training(manager)</code>","text":"<p>Called when the training</p> Source code in <code>waffle_hub/hub/manager/callbacks/base_callback.py</code> <pre><code>def training(self, manager: BaseManager) -&gt; None:\n    \"\"\"Called when the training\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/hook/","title":"TrainHook","text":"<p>             Bases: <code>BaseHook</code></p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>class BaseTrainHook(BaseHook):\n    def __init__(self, callbacks: list[BaseCallback] = None):\n        super().__init__(callbacks=callbacks)\n        self.metric_logger: MetricLogger = None\n\n    def setup(self) -&gt; None:\n        \"\"\"Called when worker starts.\"\"\"\n        _register_signal_handler()\n        self.metric_logger = MetricLogger(\n            name=self.name,\n            log_dir=self.train_log_dir,\n            func=self.get_metrics,\n            interval=10,\n            prefix=\"waffle\",\n            state=self.state,\n        )\n\n    def teardown(self) -&gt; None:\n        \"\"\"Called when worker ends.\"\"\"\n        if self.metric_logger is not None:\n            self.metric_logger.stop()\n\n    def before_train(self) -&gt; None:\n        \"\"\"Called when the train begins.\"\"\"\n        self.state.total_step = self.cfg.epochs\n\n    def on_train_start(self) -&gt; None:\n        \"\"\"Called when the train function begins.\"\"\"\n        self.state.status = TrainStatus.RUNNING\n        self.state.clear_error()\n        self.metric_logger.start()\n\n    def training(self) -&gt; None:\n        \"\"\"Called when the training\"\"\"\n\n    def on_train_end(self) -&gt; None:\n        \"\"\"Called when the train function ends.\"\"\"\n\n    def after_train(self) -&gt; None:\n        \"\"\"Called when the train ends.\"\"\"\n        # write result\n        self.result.best_ckpt_file = self.best_ckpt_file\n        self.result.last_ckpt_file = self.last_ckpt_file\n        self.result.metrics = self.get_metrics()\n\n        self.state.status = TrainStatus.SUCCESS\n\n    def on_evaluate_start(self) -&gt; None:\n        \"\"\"Called when the evaluate function begins.\"\"\"\n\n    def on_evaluate_end(self) -&gt; None:\n        \"\"\"Called when the evaluate function ends.\"\"\"\n\n    def on_exception_stopped(self, e: Exception) -&gt; None:\n        \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n        self.state.status = TrainStatus.STOPPED\n        self.state.set_error(e)\n\n    def on_exception_failed(self, e: Exception) -&gt; None:\n        \"\"\"Called when an error occurs\"\"\"\n        self.state.status = TrainStatus.FAILED\n        self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/manager/hook/#waffle_hub.hub.manager.hook.BaseTrainHook.after_train","title":"<code>after_train()</code>","text":"<p>Called when the train ends.</p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>def after_train(self) -&gt; None:\n    \"\"\"Called when the train ends.\"\"\"\n    # write result\n    self.result.best_ckpt_file = self.best_ckpt_file\n    self.result.last_ckpt_file = self.last_ckpt_file\n    self.result.metrics = self.get_metrics()\n\n    self.state.status = TrainStatus.SUCCESS\n</code></pre>"},{"location":"waffle_hub/manager/hook/#waffle_hub.hub.manager.hook.BaseTrainHook.before_train","title":"<code>before_train()</code>","text":"<p>Called when the train begins.</p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>def before_train(self) -&gt; None:\n    \"\"\"Called when the train begins.\"\"\"\n    self.state.total_step = self.cfg.epochs\n</code></pre>"},{"location":"waffle_hub/manager/hook/#waffle_hub.hub.manager.hook.BaseTrainHook.on_evaluate_end","title":"<code>on_evaluate_end()</code>","text":"<p>Called when the evaluate function ends.</p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>def on_evaluate_end(self) -&gt; None:\n    \"\"\"Called when the evaluate function ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/hook/#waffle_hub.hub.manager.hook.BaseTrainHook.on_evaluate_start","title":"<code>on_evaluate_start()</code>","text":"<p>Called when the evaluate function begins.</p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>def on_evaluate_start(self) -&gt; None:\n    \"\"\"Called when the evaluate function begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/hook/#waffle_hub.hub.manager.hook.BaseTrainHook.on_exception_failed","title":"<code>on_exception_failed(e)</code>","text":"<p>Called when an error occurs</p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>def on_exception_failed(self, e: Exception) -&gt; None:\n    \"\"\"Called when an error occurs\"\"\"\n    self.state.status = TrainStatus.FAILED\n    self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/manager/hook/#waffle_hub.hub.manager.hook.BaseTrainHook.on_exception_stopped","title":"<code>on_exception_stopped(e)</code>","text":"<p>Called when SIGTERM or SIGINT occurs</p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>def on_exception_stopped(self, e: Exception) -&gt; None:\n    \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n    self.state.status = TrainStatus.STOPPED\n    self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/manager/hook/#waffle_hub.hub.manager.hook.BaseTrainHook.on_train_end","title":"<code>on_train_end()</code>","text":"<p>Called when the train function ends.</p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>def on_train_end(self) -&gt; None:\n    \"\"\"Called when the train function ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/hook/#waffle_hub.hub.manager.hook.BaseTrainHook.on_train_start","title":"<code>on_train_start()</code>","text":"<p>Called when the train function begins.</p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>def on_train_start(self) -&gt; None:\n    \"\"\"Called when the train function begins.\"\"\"\n    self.state.status = TrainStatus.RUNNING\n    self.state.clear_error()\n    self.metric_logger.start()\n</code></pre>"},{"location":"waffle_hub/manager/hook/#waffle_hub.hub.manager.hook.BaseTrainHook.setup","title":"<code>setup()</code>","text":"<p>Called when worker starts.</p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>def setup(self) -&gt; None:\n    \"\"\"Called when worker starts.\"\"\"\n    _register_signal_handler()\n    self.metric_logger = MetricLogger(\n        name=self.name,\n        log_dir=self.train_log_dir,\n        func=self.get_metrics,\n        interval=10,\n        prefix=\"waffle\",\n        state=self.state,\n    )\n</code></pre>"},{"location":"waffle_hub/manager/hook/#waffle_hub.hub.manager.hook.BaseTrainHook.teardown","title":"<code>teardown()</code>","text":"<p>Called when worker ends.</p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>def teardown(self) -&gt; None:\n    \"\"\"Called when worker ends.\"\"\"\n    if self.metric_logger is not None:\n        self.metric_logger.stop()\n</code></pre>"},{"location":"waffle_hub/manager/hook/#waffle_hub.hub.manager.hook.BaseTrainHook.training","title":"<code>training()</code>","text":"<p>Called when the training</p> Source code in <code>waffle_hub/hub/manager/hook.py</code> <pre><code>def training(self) -&gt; None:\n    \"\"\"Called when the training\"\"\"\n</code></pre>"},{"location":"waffle_hub/manager/manager/","title":"Manager","text":"<p>             Bases: <code>BaseTrainHook</code>, <code>ABC</code></p> <p>Base Manager</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>class BaseManager(BaseTrainHook, ABC):\n    \"\"\"\n    Base Manager\n    \"\"\"\n\n    # abstract property\n    ## model spec\n    BACKEND_NAME = None\n    BACKEND_VERSION = None\n    MODEL_TYPES = None\n\n    ## trainer spec\n    MULTI_GPU_TRAIN = None\n    DEFAULT_PARAMS = None\n    DEFAULT_ADVANCE_PARAMS = None\n\n    # directory settting\n    CONFIG_DIR = Path(\"configs\")\n    ARTIFACTS_DIR = Path(\"artifacts\")\n    TRAIN_LOG_DIR = Path(\"logs\")\n    WEIGHTS_DIR = Path(\"weights\")\n\n    # train config file name\n    MODEL_CONFIG_FILE = \"model.yaml\"\n    TRAIN_CONFIG_FILE = \"train.yaml\"\n\n    # train results file name\n    LAST_CKPT_FILE = \"last_ckpt.pt\"\n    BEST_CKPT_FILE = \"best_ckpt.pt\"  # TODO: best metric?\n    METRIC_FILE = \"metrics.json\"\n\n    def __init__(\n        self,\n        root_dir: Path,\n        name: str,\n        task: Union[str, TaskType],\n        model_type: str,\n        model_size: str,\n        categories: list[Union[str, int, float, dict, Category]] = None,\n        callbacks: list[BaseCallback] = None,\n        load: bool = False,\n        train_state: TrainState = None,\n    ):\n        # abstract property\n        if self.BACKEND_NAME is None:\n            raise AttributeError(\"BACKEND_NAME must be specified.\")\n\n        if self.BACKEND_VERSION is None:\n            raise AttributeError(\"BACKEND_VERSION must be specified.\")\n\n        if self.MODEL_TYPES is None:\n            raise AttributeError(\"MODEL_TYPES must be specified.\")\n\n        if self.DEFAULT_PARAMS is None:\n            raise AttributeError(\"DEFAULT_PARAMS must be specified.\")\n\n        if self.MULTI_GPU_TRAIN is None:\n            raise AttributeError(\"MULTI_GPU_TRAIN must be specified.\")\n\n        super().__init__(callbacks=callbacks)\n        self.root_dir = Path(root_dir)\n        self.name = name\n        self.task = task\n        self.model_type = model_type\n        self.model_size = model_size\n        self.categories = categories\n        self.backend = self.BACKEND_NAME\n\n        if load:\n            self.state = (\n                train_state if train_state is not None else TrainState(status=TrainStatus.INIT)\n            )\n        else:\n            if self.model_config_file.exists():\n                raise FileExistsError(\"Manager already exists. Try to 'load' function.\")\n            self.state = TrainState(status=TrainStatus.INIT)\n\n        self.result = TrainResult()\n\n        self.save_model_config(\n            model_config_file=self.model_config_file,\n        )\n\n    # properties\n    @property\n    def task(self) -&gt; str:\n        \"\"\"Task Name\"\"\"\n        return self.__task\n\n    @task.setter\n    @setter_type_validator(Union[str, TaskType])\n    def task(self, v):\n        if v not in list(self.MODEL_TYPES.keys()):\n            raise ValueError(\n                f\"Task {v} is not supported. Choose one of {[task.value for task in list(self.MODEL_TYPES.keys())]}\"\n            )\n        self.__task = str(v.value) if isinstance(v, TaskType) else str(v).lower()\n\n    @property\n    def model_type(self) -&gt; str:\n        \"\"\"Model Type\"\"\"\n        return self.__model_type\n\n    @model_type.setter\n    @setter_type_validator(str)\n    def model_type(self, v):\n        if v not in self.MODEL_TYPES[self.task]:\n            raise ValueError(\n                f\"Model Type {v} is not supported. Choose one of {self.MODEL_TYPES[self.task]}\"\n            )\n        self.__model_type = v\n\n    @property\n    def model_size(self) -&gt; str:\n        \"\"\"Model Size\"\"\"\n        return self.__model_size\n\n    @model_size.setter\n    @setter_type_validator(str)\n    def model_size(self, v):\n        if v not in self.MODEL_TYPES[self.task][self.model_type]:\n            raise ValueError(\n                f\"Model Size {v} is not supported. Choose one of {self.MODEL_TYPES[self.task][self.model_type]}\"\n            )\n        self.__model_size = v\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Version\"\"\"\n        return self.__version\n\n    @version.setter\n    @setter_type_validator(str)\n    def version(self, v):\n        self.__version = v\n\n    @property\n    def categories(self) -&gt; list[Category]:\n        return self.__categories\n\n    @categories.setter\n    @setter_type_validator(list)\n    def categories(self, v):\n        if v is None or len(v) == 0:\n            warnings.warn(\n                \"Categories is not specified.\\n\"\n                + \"It follows the categories of Dataset when the training starts.\"\n            )\n            v = []\n        elif isinstance(v[0], dict):\n            v = [\n                getattr(Category, self.task.lower())(\n                    **{\n                        **category,\n                        \"category_id\": category.get(\"category_id\", i),\n                    }\n                )\n                for i, category in enumerate(v, start=1)\n            ]\n        elif isinstance(v[0], (str, int, float)):\n            v = [\n                getattr(Category, self.task.lower())(\n                    category_id=i,\n                    supercategory=\"object\",\n                    name=str(category),\n                )\n                for i, category in enumerate(v, start=1)\n            ]\n            warnings.warn(\n                \"Super category is not specified. It may cause unexpected errors in some backends.\\n\"\n                + \"To avoid this warning, please specify category as a list of dictionary or Category\"\n            )\n        elif isinstance(v[0], Category):\n            pass\n\n        self.__categories = v\n\n    # path properties\n    @property\n    def config_dir(self) -&gt; Path:\n        \"\"\"Config Directory\"\"\"\n        return self.root_dir / self.CONFIG_DIR\n\n    @property\n    def model_config_file(self) -&gt; Path:\n        \"\"\"Model Config yaml File\"\"\"\n        return self.config_dir / self.MODEL_CONFIG_FILE\n\n    @property\n    def train_config_file(self) -&gt; Path:\n        \"\"\"Train Config yaml File\"\"\"\n        return self.config_dir / self.TRAIN_CONFIG_FILE\n\n    @property\n    def artifacts_dir(self) -&gt; Path:\n        \"\"\"Artifacts Directory. This is raw output of each backend.\"\"\"\n        return self.root_dir / self.ARTIFACTS_DIR\n\n    @property\n    def train_log_dir(self) -&gt; Path:\n        \"\"\"Train Log Directory.\"\"\"\n        return self.root_dir / self.TRAIN_LOG_DIR\n\n    @property\n    def weights_dir(self) -&gt; Path:\n        \"\"\"Weights Directory.\"\"\"\n        return self.root_dir / self.WEIGHTS_DIR\n\n    @property\n    def last_ckpt_file(self) -&gt; Path:\n        return self.weights_dir / self.LAST_CKPT_FILE\n\n    @property\n    def best_ckpt_file(self) -&gt; Path:\n        return self.weights_dir / self.BEST_CKPT_FILE\n\n    @property\n    def metric_file(self) -&gt; Path:\n        return self.root_dir / self.METRIC_FILE\n\n    # manager common methods\n    def set_model_name(self, name: str):\n        \"\"\"Set model name\n        if model name is not same with model config name, it will cause unexpected errors\n\n        Args:\n            name (str): model name\n        \"\"\"\n        self.name = name\n        ModelConfig(\n            name=self.name,\n            backend=self.BACKEND_NAME,\n            version=self.BACKEND_VERSION,\n            task=self.task,\n            model_type=self.model_type,\n            model_size=self.model_size,\n            categories=list(map(lambda x: x.to_dict(), self.categories)),\n        ).save_yaml(self.model_config_file)\n\n    def get_categories(self) -&gt; list[Category]:\n        return self.categories\n\n    def get_category_names(self) -&gt; list[str]:\n        return [category.name for category in self.categories]\n\n    @classmethod\n    def is_exists(cls, root_dir: str) -&gt; bool:\n        \"\"\"\n        Manager is exists (model config file is exists)\n\n        Args:\n            root_dir (str): Root directory\n\n        Returns:\n            bool: True or False\n        \"\"\"\n        model_config_file = Path(root_dir) / cls.CONFIG_DIR / cls.MODEL_CONFIG_FILE\n        return model_config_file.exists()\n\n    @classmethod\n    def from_model_config_file(\n        cls,\n        root_dir: str,\n        name: str,\n        model_config_file_path: Union[str, Path],\n        callbacks: list[BaseCallback] = None,\n    ):\n        \"\"\"\n        Create Manager from model config file\n\n        Args:\n            root_dir (str): Root directory\n            name (str): Model name\n            model_config_file_path (Union[str, Path]): Model config file path\n            callbacks (list[BaseCallback], optional): Callbacks. Defaults to None.\n\n        Returns:\n            BaseManager: Manager\n        \"\"\"\n        if not model_config_file_path.exists():\n            raise FileNotFoundError(f\"Model config file {model_config_file_path} is not exist.\")\n\n        model_config = ModelConfig.load(model_config_file_path)\n\n        if model_config[\"backend\"] != cls.BACKEND_NAME:\n            raise ValueError(\n                f\"Model backend is not matched with hub backend. Model backend: {model_config['backend']}, Hub backend: {cls.BACKEND_NAME}\"\n            )\n\n        return cls(\n            root_dir=root_dir,\n            name=name,\n            task=model_config[\"task\"],\n            model_type=model_config[\"model_type\"],\n            model_size=model_config[\"model_size\"],\n            categories=model_config[\"categories\"],\n            callbacks=callbacks,\n        )\n\n    @classmethod\n    def load(\n        cls, root_dir: str, train_state: TrainState = None, callbacks: list[BaseCallback] = None\n    ):\n        \"\"\"\n        Load Manager from model config file in root directory\n\n        Args:\n            root_dir (str): Root directory\n            train_state (TrainState, optional): Train state. Defaults to None.\n            callbacks (list[BaseCallback], optional): Callbacks. Defaults to None.\n\n        Returns:\n            BaseManager: Manager\n        \"\"\"\n        model_config_file_path = Path(root_dir) / cls.CONFIG_DIR / cls.MODEL_CONFIG_FILE\n        if not model_config_file_path.exists():\n            raise FileNotFoundError(\n                f\"Model config file {model_config_file_path} is not exist. Init first.\"\n            )\n\n        model_config = ModelConfig.load(model_config_file_path)\n\n        if model_config[\"backend\"] != cls.BACKEND_NAME:\n            raise ValueError(\n                f\"Model backend is not matched with hub backend. Model backend: {model_config['backend']}, Hub backend: {cls.BACKEND_NAME}\"\n            )\n\n        return cls(\n            root_dir=root_dir,\n            name=model_config[\"name\"],\n            task=model_config[\"task\"],\n            model_type=model_config[\"model_type\"],\n            model_size=model_config[\"model_size\"],\n            categories=model_config[\"categories\"],\n            callbacks=callbacks,\n            load=True,\n            train_state=train_state,\n        )\n\n    def delete_manager(self):\n        \"\"\"\n        Delete manager.\n        \"\"\"\n        if self.root_dir.exists():\n            io.remove_directory(self.root_dir, recursive=True)\n        del self\n        return None\n\n    def delete_artifacts(self):\n        \"\"\"\n        Delete manager.\n        \"\"\"\n        # TODO: utils 1.0 \uc5f0\ub3d9 \uc2dc get \ud568\uc218 \uc0ac\uc6a9\n        if self.train_config_file.exists():\n            io.remove_file(self.train_config_file)\n        if self.artifacts_dir.exists():\n            io.remove_directory(self.artifacts_dir, recursive=True)\n        if self.weights_dir.exists():\n            io.remove_directory(self.weights_dir, recursive=True)\n        if self.train_log_dir.exists():\n            io.remove_directory(self.train_log_dir, recursive=True)\n        if self.metric_file.exists():\n            io.remove_file(self.metric_file)\n        return None\n\n    # Configs methods\n    @classmethod\n    def get_model_config(cls, root_dir: Union[str, Path]) -&gt; ModelConfig:\n        \"\"\"Get model config from model config yaml file\n\n        Args:\n            root_dir (Path): root directory of model config yaml file\n\n        Returns:\n            ModelConfig: model config\n        \"\"\"\n        model_config_file_path = Path(root_dir) / cls.CONFIG_DIR / cls.MODEL_CONFIG_FILE\n        if not model_config_file_path.exists():\n            warnings.warn(f\"Model config file {model_config_file_path} is not exist.\")\n            return []\n        return ModelConfig.load(model_config_file_path)\n\n    @classmethod\n    def get_train_config(cls, root_dir: Union[str, Path]) -&gt; TrainConfig:\n        \"\"\"Get train config from train config yaml file.\n\n        Args:\n            root_dir (Path): root directory of train config yaml file\n\n        Returns:\n            TrainConfig: train config of train config yaml file\n        \"\"\"\n        train_config_file_path = Path(root_dir) / cls.CONFIG_DIR / cls.TRAIN_CONFIG_FILE\n        if not train_config_file_path.exists():\n            warnings.warn(f\"Train config file {train_config_file_path} is not exist. Train first!\")\n            return None\n        return TrainConfig.load(train_config_file_path)\n\n    def save_model_config(\n        self,\n        model_config_file: Path,\n    ):\n        \"\"\"Save model config to model config yaml file\n\n        Args:\n            model_config_file (Path): model config yaml file\n        \"\"\"\n        ModelConfig(\n            name=self.name,\n            backend=self.BACKEND_NAME,\n            version=self.BACKEND_VERSION,\n            task=self.task,\n            model_type=self.model_type,\n            model_size=self.model_size,\n            categories=list(map(lambda x: x.to_dict(), self.categories)),\n        ).save_yaml(model_config_file)\n\n    def save_train_config(\n        self,\n        cfg: TrainConfig,\n        train_config_path: Path,\n    ):\n        \"\"\"Save train config to yaml file\n\n        Args:\n            train_config_path (Path): file path for saving train config\n        \"\"\"\n        cfg.save_yaml(train_config_path)\n\n    # Model abstract method\n    @abstractmethod\n    def get_model(self) -&gt; ModelWrapper:\n        \"\"\"Get model for inference or evaluation\n        Returns:\n            ModelWrapper: best model wrapper\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def _get_preprocess(self, *args, **kwargs):\n        raise NotImplementedError\n\n    @abstractmethod\n    def _get_postprocess(self, *args, **kwargs):\n        raise NotImplementedError\n\n    # Train abstract method\n    @abstractmethod\n    def get_metrics(self):\n        raise NotImplementedError\n\n    def check_train_sanity(self) -&gt; bool:\n        \"\"\"Check if all essential files are exist.\n\n        Returns:\n            bool: True if all files are exist else False\n        \"\"\"\n        if not self.best_ckpt_file.exists():  # last_ckpt_file.exists() or ??\n            raise ValueError(\"Train first! hub.train(...).\")\n        return True\n\n    # need override\n    def get_default_advance_train_params(\n        cls, task: str = None, model_type: str = None, model_size: str = None\n    ) -&gt; dict:\n        \"\"\"\n        Get default train advance params\n\n        Args:\n            task (str): Task name\n            model_type (str): Model type\n            model_size (str): Model size\n\n        Raises:\n            ModuleNotFoundError: If backend is not supported\n\n        Returns:\n            dict: Default train advance params\n        \"\"\"\n        raise NotImplementedError(f\"{cls.BACKEND_NAME} does not support advance_params argument.\")\n\n    def train(\n        self,\n        dataset: Union[Dataset, str, Path],\n        dataset_root_dir: str = None,\n        epochs: int = None,\n        batch_size: int = None,\n        image_size: Union[int, list[int]] = None,\n        learning_rate: float = None,\n        letter_box: bool = None,\n        pretrained_model: str = None,\n        device: str = \"0\",\n        workers: int = 2,\n        seed: int = 0,\n        advance_params: Union[dict, str] = None,\n        verbose: bool = True,\n    ) -&gt; TrainResult:\n        \"\"\"Start Train\n\n        Args:\n            dataset (Union[Dataset, str, Path]): Waffle Dataset object or path or name.\n            dataset_root_dir (str, optional): Waffle Dataset root directory. Defaults to None.\n            epochs (int, optional): number of epochs. None to use default. Defaults to None.\n            batch_size (int, optional): batch size. None to use default. Defaults to None.\n            image_size (Union[int, list[int]], optional): image size. None to use default. Defaults to None.\n            learning_rate (float, optional): learning rate. None to use default. Defaults to None.\n            letter_box (bool, optional): letter box. None to use default. Defaults to None.\n            pretrained_model (str, optional): pretrained model. None to use default. Defaults to None.\n            device (str, optional):\n                \"cpu\" or \"gpu_id\" or comma seperated \"gpu_ids\". Defaults to \"0\".\n            workers (int, optional): number of workers. Defaults to 2.\n            seed (int, optional): random seed. Defaults to 0.\n            advance_params (Union[dict, str], optional): advance params dictionary or file (yaml, json) path. Defaults to None.\n            verbose (bool, optional): verbose. Defaults to True.\n\n        Returns:\n            TrainResult: train result\n        \"\"\"\n        try:\n            # check if it is already trained\n            self.run_default_hook(\"setup\")\n            self.run_callback_hooks(\"setup\", self)\n\n            # check if it is already trained # TODO: resume\n            rank = os.getenv(\"RANK\", -1)\n            if self.artifacts_dir.exists() and rank in [\n                -1,\n                0,\n            ]:  # TODO: need to ensure that training is not already running\n                raise FileExistsError(\n                    f\"{self.artifacts_dir}\\n\"\n                    \"Train artifacts already exist. Remove artifact to re-train [delete_artifact].\"\n                )\n\n            # parse dataset\n            export_path, dataset_path = self._parse_dataset(dataset, dataset_root_dir)\n\n            self.cfg = self._parse_train_config(\n                dataset_path=export_path,\n                epochs=epochs,\n                batch_size=batch_size,\n                image_size=image_size,\n                learning_rate=learning_rate,\n                letter_box=letter_box,\n                pretrained_model=pretrained_model,\n                device=device,\n                workers=workers,\n                seed=seed,\n                advance_params=advance_params,\n                verbose=verbose,\n            )\n\n            # save train config\n            self.save_train_config(self.cfg, self.train_config_file)\n\n            # check device\n            device = self.cfg.device\n            if device == \"cpu\":\n                # logger.info(\"CPU training\")\n                pass\n            elif device.isdigit():\n                if not torch.cuda.is_available():\n                    raise ValueError(\"CUDA is not available.\")\n            elif \",\" in device:\n                if not torch.cuda.is_available():\n                    raise ValueError(\"CUDA is not available.\")\n                if not self.MULTI_GPU_TRAIN:\n                    raise ValueError(f\"{self.backend} does not support MULTI_GPU_TRAIN.\")\n                if len(device.split(\",\")) &gt; torch.cuda.device_count():\n                    raise ValueError(\n                        f\"GPU number is not enough. {device}\\n\"\n                        + f\"Given device: {device}\\n\"\n                        + f\"Available device count: {torch.cuda.device_count()}\"\n                    )\n                # TODO: occurs unexpected errors\n                # if not all([int(x) &lt; torch.cuda.device_count() for x in device.split(\",\")]):\n                #     raise IndexError(\n                #         f\"GPU index is out of range. device id should be smaller than {torch.cuda.device_count()}\\n\"\n                #     )\n                # logger.info(f\"Multi GPU training: {device}\")\n            else:\n                raise ValueError(f\"Invalid device: {device}\\n\" + \"Please use 'cpu', '0', '0,1,2,3'\")\n\n            self.run_default_hook(\"before_train\")\n            self.run_callback_hooks(\"before_train\", self)\n\n            self._train()\n\n            self._evaluate(dataset_path)\n\n            self.run_default_hook(\"after_train\")\n            self.run_callback_hooks(\"after_train\", self)\n\n        except FileExistsError as e:\n            raise e\n        except (KeyboardInterrupt, SystemExit) as e:\n            self.run_default_hook(\"on_exception_stopped\", e)\n            self.run_callback_hooks(\"on_exception_stopped\", self, e)\n            if self.artifacts_dir.exists():\n                self.run_default_hook(\"on_train_end\")\n                self.run_callback_hooks(\"on_train_end\", self)\n            raise e\n        except Exception as e:\n            self.run_default_hook(\"on_exception_failed\", e)\n            self.run_callback_hooks(\"on_exception_failed\", self, e)\n            if self.artifacts_dir.exists():\n                io.remove_directory(self.artifacts_dir, recursive=True)\n            raise e\n        finally:\n            self.run_default_hook(\"teardown\")\n            self.run_callback_hooks(\"teardown\", self)\n\n        return self.result\n\n    def _train(self):\n        self.run_default_hook(\"on_train_start\")\n        self.run_callback_hooks(\"on_train_start\", self)\n\n        self.run_default_hook(\"training\")\n        self.run_callback_hooks(\"training\", self)\n\n        self.run_default_hook(\"on_train_end\")\n        self.run_callback_hooks(\"on_train_end\", self)\n\n    def _parse_dataset(\n        self, dataset: Union[Dataset, str, Path], dataset_root_dir: str = None\n    ) -&gt; (Path, Path):\n        \"\"\"parse dataset\n\n        Args:\n            dataset (Union[Dataset, str, Path]): Dataset\n            dataset_root_dir (str): Dataset root directory\n\n        Returns:\n            (Path, Path): Export directory, train dataset path\n        \"\"\"\n        #\n        if isinstance(dataset, (str, Path)):\n            if Path(dataset).exists():\n                dataset = Path(dataset)\n                dataset = Dataset.load(\n                    name=dataset.parts[-1], root_dir=dataset.parents[0].absolute()\n                )\n            elif dataset in Dataset.get_dataset_list(dataset_root_dir):\n                dataset = Dataset.load(name=dataset, root_dir=dataset_root_dir)\n            else:\n                raise FileNotFoundError(f\"Dataset {dataset} is not exist.\")\n\n        # check category match\n        if not self.categories:\n            self.categories = dataset.get_categories()\n            self.save_model_config(self.model_config_file)\n        elif set(dataset.get_category_names()) != set(self.get_category_names()):\n            raise ValueError(\n                \"Dataset categories are not matched with hub categories. \\n\"\n                + f\"Dataset categories: {dataset.get_category_names()}, Hub categories: {self.get_category_names()}\"\n            )\n\n        # check task match\n        if dataset.task.lower() != self.task.lower():\n            raise ValueError(\n                f\"Dataset task is not matched with hub task. Dataset task: {dataset.task}, Hub task: {self.task}\"\n            )\n\n        # convert dataset to backend format if not exist\n        export_dir = dataset.export_dir / EXPORT_MAP[self.backend]\n        if not export_dir.exists():\n            ## LOGGER!!\n            # logger.info(f\"[Dataset] Exporting dataset to {self.backend} format...\")\n            export_dir = dataset.export(self.backend)\n            # logger.info(\"[Dataset] Exporting done.\")\n\n        return export_dir, dataset.dataset_dir\n\n    def _parse_train_config(\n        self,\n        dataset_path: Path,\n        epochs: int,\n        batch_size: int = None,\n        image_size: Union[int, list[int]] = None,\n        learning_rate: float = None,\n        letter_box: bool = None,\n        pretrained_model: str = None,\n        device: str = \"0\",\n        workers: int = 2,\n        seed: int = 0,\n        advance_params: Union[dict, str] = None,\n        verbose: bool = True,\n    ) -&gt; TrainConfig:\n        # parse train config\n        cfg = TrainConfig(\n            dataset_path=dataset_path,\n            epochs=epochs,\n            batch_size=batch_size,\n            image_size=image_size,\n            learning_rate=learning_rate,\n            letter_box=letter_box,\n            pretrained_model=pretrained_model,\n            device=device,\n            workers=workers,\n            seed=seed,\n            advance_params=advance_params if advance_params else {},\n            verbose=verbose,\n        )\n\n        ## overwrite train config with default config\n        for k, v in cfg.to_dict().items():\n            if v is None:\n                field_value = getattr(\n                    self.DEFAULT_PARAMS[self.task][self.model_type][self.model_size], k\n                )\n                setattr(cfg, k, field_value)\n        cfg.image_size = (\n            cfg.image_size if isinstance(cfg.image_size, list) else [cfg.image_size, cfg.image_size]\n        )\n\n        ## overwrite train advance config\n        if cfg.advance_params:\n            if isinstance(cfg.advance_params, (str, PurePath)):\n                # check if it is yaml or json\n                if Path(cfg.advance_params).exists():\n                    if Path(cfg.advance_params).suffix in [\".yaml\", \".yml\"]:\n                        cfg.advance_params = io.load_yaml(cfg.advance_params)\n                    elif Path(cfg.advance_params).suffix in [\".json\"]:\n                        cfg.advance_params = io.load_json(cfg.advance_params)\n                    else:\n                        raise ValueError(\n                            f\"Advance parameter file should be yaml or json. {cfg.advance_params}\"\n                        )\n                else:\n                    raise FileNotFoundError(f\"Advance parameter file is not exist.\")\n            elif not isinstance(cfg.advance_params, dict):\n                raise ValueError(\n                    f\"Advance parameter should be dictionary or file path. {cfg.advance_params}\"\n                )\n\n            default_advance_param = self.get_default_advance_train_params()\n            for key in cfg.advance_params.keys():\n                if key not in default_advance_param:\n                    raise ValueError(\n                        f\"Advance parameter {key} is not supported.\\n\"\n                        + f\"Supported parameters: {list(default_advance_param.keys())}\"\n                    )\n        return cfg\n\n    def _evaluate(self, dataset_path: Path):\n        # evaluate\n        self.evaluator = Evaluator(root_dir=self.root_dir, model=self.get_model())\n\n        self.run_default_hook(\"on_evaluate_start\")\n        self.run_callback_hooks(\"on_evaluate_start\", self)\n\n        result = self.evaluator.evaluate(\n            dataset=dataset_path,\n            batch_size=self.cfg.batch_size,\n            image_size=self.cfg.image_size,\n            letter_box=self.cfg.letter_box,\n            device=self.cfg.device,\n            workers=self.cfg.workers,\n        )\n        self.result.eval_metrics = result.eval_metrics\n\n        self.run_default_hook(\"on_evaluate_end\")\n        self.run_callback_hooks(\"on_evaluate_end\", self)\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.artifacts_dir","title":"<code>artifacts_dir: Path</code>  <code>property</code>","text":"<p>Artifacts Directory. This is raw output of each backend.</p>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.config_dir","title":"<code>config_dir: Path</code>  <code>property</code>","text":"<p>Config Directory</p>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.model_config_file","title":"<code>model_config_file: Path</code>  <code>property</code>","text":"<p>Model Config yaml File</p>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.model_size","title":"<code>model_size: str</code>  <code>property</code> <code>writable</code>","text":"<p>Model Size</p>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.model_type","title":"<code>model_type: str</code>  <code>property</code> <code>writable</code>","text":"<p>Model Type</p>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.task","title":"<code>task: str</code>  <code>property</code> <code>writable</code>","text":"<p>Task Name</p>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.train_config_file","title":"<code>train_config_file: Path</code>  <code>property</code>","text":"<p>Train Config yaml File</p>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.train_log_dir","title":"<code>train_log_dir: Path</code>  <code>property</code>","text":"<p>Train Log Directory.</p>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.version","title":"<code>version: str</code>  <code>property</code> <code>writable</code>","text":"<p>Version</p>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.weights_dir","title":"<code>weights_dir: Path</code>  <code>property</code>","text":"<p>Weights Directory.</p>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.check_train_sanity","title":"<code>check_train_sanity()</code>","text":"<p>Check if all essential files are exist.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if all files are exist else False</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>def check_train_sanity(self) -&gt; bool:\n    \"\"\"Check if all essential files are exist.\n\n    Returns:\n        bool: True if all files are exist else False\n    \"\"\"\n    if not self.best_ckpt_file.exists():  # last_ckpt_file.exists() or ??\n        raise ValueError(\"Train first! hub.train(...).\")\n    return True\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.delete_artifacts","title":"<code>delete_artifacts()</code>","text":"<p>Delete manager.</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>def delete_artifacts(self):\n    \"\"\"\n    Delete manager.\n    \"\"\"\n    # TODO: utils 1.0 \uc5f0\ub3d9 \uc2dc get \ud568\uc218 \uc0ac\uc6a9\n    if self.train_config_file.exists():\n        io.remove_file(self.train_config_file)\n    if self.artifacts_dir.exists():\n        io.remove_directory(self.artifacts_dir, recursive=True)\n    if self.weights_dir.exists():\n        io.remove_directory(self.weights_dir, recursive=True)\n    if self.train_log_dir.exists():\n        io.remove_directory(self.train_log_dir, recursive=True)\n    if self.metric_file.exists():\n        io.remove_file(self.metric_file)\n    return None\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.delete_manager","title":"<code>delete_manager()</code>","text":"<p>Delete manager.</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>def delete_manager(self):\n    \"\"\"\n    Delete manager.\n    \"\"\"\n    if self.root_dir.exists():\n        io.remove_directory(self.root_dir, recursive=True)\n    del self\n    return None\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.from_model_config_file","title":"<code>from_model_config_file(root_dir, name, model_config_file_path, callbacks=None)</code>  <code>classmethod</code>","text":"<p>Create Manager from model config file</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>str</code> <p>Root directory</p> required <code>name</code> <code>str</code> <p>Model name</p> required <code>model_config_file_path</code> <code>Union[str, Path]</code> <p>Model config file path</p> required <code>callbacks</code> <code>list[BaseCallback]</code> <p>Callbacks. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BaseManager</code> <p>Manager</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>@classmethod\ndef from_model_config_file(\n    cls,\n    root_dir: str,\n    name: str,\n    model_config_file_path: Union[str, Path],\n    callbacks: list[BaseCallback] = None,\n):\n    \"\"\"\n    Create Manager from model config file\n\n    Args:\n        root_dir (str): Root directory\n        name (str): Model name\n        model_config_file_path (Union[str, Path]): Model config file path\n        callbacks (list[BaseCallback], optional): Callbacks. Defaults to None.\n\n    Returns:\n        BaseManager: Manager\n    \"\"\"\n    if not model_config_file_path.exists():\n        raise FileNotFoundError(f\"Model config file {model_config_file_path} is not exist.\")\n\n    model_config = ModelConfig.load(model_config_file_path)\n\n    if model_config[\"backend\"] != cls.BACKEND_NAME:\n        raise ValueError(\n            f\"Model backend is not matched with hub backend. Model backend: {model_config['backend']}, Hub backend: {cls.BACKEND_NAME}\"\n        )\n\n    return cls(\n        root_dir=root_dir,\n        name=name,\n        task=model_config[\"task\"],\n        model_type=model_config[\"model_type\"],\n        model_size=model_config[\"model_size\"],\n        categories=model_config[\"categories\"],\n        callbacks=callbacks,\n    )\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.get_default_advance_train_params","title":"<code>get_default_advance_train_params(task=None, model_type=None, model_size=None)</code>","text":"<p>Get default train advance params</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>str</code> <p>Task name</p> <code>None</code> <code>model_type</code> <code>str</code> <p>Model type</p> <code>None</code> <code>model_size</code> <code>str</code> <p>Model size</p> <code>None</code> <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If backend is not supported</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Default train advance params</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>def get_default_advance_train_params(\n    cls, task: str = None, model_type: str = None, model_size: str = None\n) -&gt; dict:\n    \"\"\"\n    Get default train advance params\n\n    Args:\n        task (str): Task name\n        model_type (str): Model type\n        model_size (str): Model size\n\n    Raises:\n        ModuleNotFoundError: If backend is not supported\n\n    Returns:\n        dict: Default train advance params\n    \"\"\"\n    raise NotImplementedError(f\"{cls.BACKEND_NAME} does not support advance_params argument.\")\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.get_model","title":"<code>get_model()</code>  <code>abstractmethod</code>","text":"<p>Get model for inference or evaluation Returns:     ModelWrapper: best model wrapper</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>@abstractmethod\ndef get_model(self) -&gt; ModelWrapper:\n    \"\"\"Get model for inference or evaluation\n    Returns:\n        ModelWrapper: best model wrapper\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.get_model_config","title":"<code>get_model_config(root_dir)</code>  <code>classmethod</code>","text":"<p>Get model config from model config yaml file</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>Path</code> <p>root directory of model config yaml file</p> required <p>Returns:</p> Name Type Description <code>ModelConfig</code> <code>ModelConfig</code> <p>model config</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>@classmethod\ndef get_model_config(cls, root_dir: Union[str, Path]) -&gt; ModelConfig:\n    \"\"\"Get model config from model config yaml file\n\n    Args:\n        root_dir (Path): root directory of model config yaml file\n\n    Returns:\n        ModelConfig: model config\n    \"\"\"\n    model_config_file_path = Path(root_dir) / cls.CONFIG_DIR / cls.MODEL_CONFIG_FILE\n    if not model_config_file_path.exists():\n        warnings.warn(f\"Model config file {model_config_file_path} is not exist.\")\n        return []\n    return ModelConfig.load(model_config_file_path)\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.get_train_config","title":"<code>get_train_config(root_dir)</code>  <code>classmethod</code>","text":"<p>Get train config from train config yaml file.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>Path</code> <p>root directory of train config yaml file</p> required <p>Returns:</p> Name Type Description <code>TrainConfig</code> <code>TrainConfig</code> <p>train config of train config yaml file</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>@classmethod\ndef get_train_config(cls, root_dir: Union[str, Path]) -&gt; TrainConfig:\n    \"\"\"Get train config from train config yaml file.\n\n    Args:\n        root_dir (Path): root directory of train config yaml file\n\n    Returns:\n        TrainConfig: train config of train config yaml file\n    \"\"\"\n    train_config_file_path = Path(root_dir) / cls.CONFIG_DIR / cls.TRAIN_CONFIG_FILE\n    if not train_config_file_path.exists():\n        warnings.warn(f\"Train config file {train_config_file_path} is not exist. Train first!\")\n        return None\n    return TrainConfig.load(train_config_file_path)\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.is_exists","title":"<code>is_exists(root_dir)</code>  <code>classmethod</code>","text":"<p>Manager is exists (model config file is exists)</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>str</code> <p>Root directory</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True or False</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>@classmethod\ndef is_exists(cls, root_dir: str) -&gt; bool:\n    \"\"\"\n    Manager is exists (model config file is exists)\n\n    Args:\n        root_dir (str): Root directory\n\n    Returns:\n        bool: True or False\n    \"\"\"\n    model_config_file = Path(root_dir) / cls.CONFIG_DIR / cls.MODEL_CONFIG_FILE\n    return model_config_file.exists()\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.load","title":"<code>load(root_dir, train_state=None, callbacks=None)</code>  <code>classmethod</code>","text":"<p>Load Manager from model config file in root directory</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>str</code> <p>Root directory</p> required <code>train_state</code> <code>TrainState</code> <p>Train state. Defaults to None.</p> <code>None</code> <code>callbacks</code> <code>list[BaseCallback]</code> <p>Callbacks. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BaseManager</code> <p>Manager</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>@classmethod\ndef load(\n    cls, root_dir: str, train_state: TrainState = None, callbacks: list[BaseCallback] = None\n):\n    \"\"\"\n    Load Manager from model config file in root directory\n\n    Args:\n        root_dir (str): Root directory\n        train_state (TrainState, optional): Train state. Defaults to None.\n        callbacks (list[BaseCallback], optional): Callbacks. Defaults to None.\n\n    Returns:\n        BaseManager: Manager\n    \"\"\"\n    model_config_file_path = Path(root_dir) / cls.CONFIG_DIR / cls.MODEL_CONFIG_FILE\n    if not model_config_file_path.exists():\n        raise FileNotFoundError(\n            f\"Model config file {model_config_file_path} is not exist. Init first.\"\n        )\n\n    model_config = ModelConfig.load(model_config_file_path)\n\n    if model_config[\"backend\"] != cls.BACKEND_NAME:\n        raise ValueError(\n            f\"Model backend is not matched with hub backend. Model backend: {model_config['backend']}, Hub backend: {cls.BACKEND_NAME}\"\n        )\n\n    return cls(\n        root_dir=root_dir,\n        name=model_config[\"name\"],\n        task=model_config[\"task\"],\n        model_type=model_config[\"model_type\"],\n        model_size=model_config[\"model_size\"],\n        categories=model_config[\"categories\"],\n        callbacks=callbacks,\n        load=True,\n        train_state=train_state,\n    )\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.save_model_config","title":"<code>save_model_config(model_config_file)</code>","text":"<p>Save model config to model config yaml file</p> <p>Parameters:</p> Name Type Description Default <code>model_config_file</code> <code>Path</code> <p>model config yaml file</p> required Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>def save_model_config(\n    self,\n    model_config_file: Path,\n):\n    \"\"\"Save model config to model config yaml file\n\n    Args:\n        model_config_file (Path): model config yaml file\n    \"\"\"\n    ModelConfig(\n        name=self.name,\n        backend=self.BACKEND_NAME,\n        version=self.BACKEND_VERSION,\n        task=self.task,\n        model_type=self.model_type,\n        model_size=self.model_size,\n        categories=list(map(lambda x: x.to_dict(), self.categories)),\n    ).save_yaml(model_config_file)\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.save_train_config","title":"<code>save_train_config(cfg, train_config_path)</code>","text":"<p>Save train config to yaml file</p> <p>Parameters:</p> Name Type Description Default <code>train_config_path</code> <code>Path</code> <p>file path for saving train config</p> required Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>def save_train_config(\n    self,\n    cfg: TrainConfig,\n    train_config_path: Path,\n):\n    \"\"\"Save train config to yaml file\n\n    Args:\n        train_config_path (Path): file path for saving train config\n    \"\"\"\n    cfg.save_yaml(train_config_path)\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.set_model_name","title":"<code>set_model_name(name)</code>","text":"<p>Set model name if model name is not same with model config name, it will cause unexpected errors</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>model name</p> required Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>def set_model_name(self, name: str):\n    \"\"\"Set model name\n    if model name is not same with model config name, it will cause unexpected errors\n\n    Args:\n        name (str): model name\n    \"\"\"\n    self.name = name\n    ModelConfig(\n        name=self.name,\n        backend=self.BACKEND_NAME,\n        version=self.BACKEND_VERSION,\n        task=self.task,\n        model_type=self.model_type,\n        model_size=self.model_size,\n        categories=list(map(lambda x: x.to_dict(), self.categories)),\n    ).save_yaml(self.model_config_file)\n</code></pre>"},{"location":"waffle_hub/manager/manager/#waffle_hub.hub.manager.base_manager.BaseManager.train","title":"<code>train(dataset, dataset_root_dir=None, epochs=None, batch_size=None, image_size=None, learning_rate=None, letter_box=None, pretrained_model=None, device='0', workers=2, seed=0, advance_params=None, verbose=True)</code>","text":"<p>Start Train</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[Dataset, str, Path]</code> <p>Waffle Dataset object or path or name.</p> required <code>dataset_root_dir</code> <code>str</code> <p>Waffle Dataset root directory. Defaults to None.</p> <code>None</code> <code>epochs</code> <code>int</code> <p>number of epochs. None to use default. Defaults to None.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>batch size. None to use default. Defaults to None.</p> <code>None</code> <code>image_size</code> <code>Union[int, list[int]]</code> <p>image size. None to use default. Defaults to None.</p> <code>None</code> <code>learning_rate</code> <code>float</code> <p>learning rate. None to use default. Defaults to None.</p> <code>None</code> <code>letter_box</code> <code>bool</code> <p>letter box. None to use default. Defaults to None.</p> <code>None</code> <code>pretrained_model</code> <code>str</code> <p>pretrained model. None to use default. Defaults to None.</p> <code>None</code> <code>device</code> <code>str</code> <p>\"cpu\" or \"gpu_id\" or comma seperated \"gpu_ids\". Defaults to \"0\".</p> <code>'0'</code> <code>workers</code> <code>int</code> <p>number of workers. Defaults to 2.</p> <code>2</code> <code>seed</code> <code>int</code> <p>random seed. Defaults to 0.</p> <code>0</code> <code>advance_params</code> <code>Union[dict, str]</code> <p>advance params dictionary or file (yaml, json) path. Defaults to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>verbose. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>TrainResult</code> <code>TrainResult</code> <p>train result</p> Source code in <code>waffle_hub/hub/manager/base_manager.py</code> <pre><code>def train(\n    self,\n    dataset: Union[Dataset, str, Path],\n    dataset_root_dir: str = None,\n    epochs: int = None,\n    batch_size: int = None,\n    image_size: Union[int, list[int]] = None,\n    learning_rate: float = None,\n    letter_box: bool = None,\n    pretrained_model: str = None,\n    device: str = \"0\",\n    workers: int = 2,\n    seed: int = 0,\n    advance_params: Union[dict, str] = None,\n    verbose: bool = True,\n) -&gt; TrainResult:\n    \"\"\"Start Train\n\n    Args:\n        dataset (Union[Dataset, str, Path]): Waffle Dataset object or path or name.\n        dataset_root_dir (str, optional): Waffle Dataset root directory. Defaults to None.\n        epochs (int, optional): number of epochs. None to use default. Defaults to None.\n        batch_size (int, optional): batch size. None to use default. Defaults to None.\n        image_size (Union[int, list[int]], optional): image size. None to use default. Defaults to None.\n        learning_rate (float, optional): learning rate. None to use default. Defaults to None.\n        letter_box (bool, optional): letter box. None to use default. Defaults to None.\n        pretrained_model (str, optional): pretrained model. None to use default. Defaults to None.\n        device (str, optional):\n            \"cpu\" or \"gpu_id\" or comma seperated \"gpu_ids\". Defaults to \"0\".\n        workers (int, optional): number of workers. Defaults to 2.\n        seed (int, optional): random seed. Defaults to 0.\n        advance_params (Union[dict, str], optional): advance params dictionary or file (yaml, json) path. Defaults to None.\n        verbose (bool, optional): verbose. Defaults to True.\n\n    Returns:\n        TrainResult: train result\n    \"\"\"\n    try:\n        # check if it is already trained\n        self.run_default_hook(\"setup\")\n        self.run_callback_hooks(\"setup\", self)\n\n        # check if it is already trained # TODO: resume\n        rank = os.getenv(\"RANK\", -1)\n        if self.artifacts_dir.exists() and rank in [\n            -1,\n            0,\n        ]:  # TODO: need to ensure that training is not already running\n            raise FileExistsError(\n                f\"{self.artifacts_dir}\\n\"\n                \"Train artifacts already exist. Remove artifact to re-train [delete_artifact].\"\n            )\n\n        # parse dataset\n        export_path, dataset_path = self._parse_dataset(dataset, dataset_root_dir)\n\n        self.cfg = self._parse_train_config(\n            dataset_path=export_path,\n            epochs=epochs,\n            batch_size=batch_size,\n            image_size=image_size,\n            learning_rate=learning_rate,\n            letter_box=letter_box,\n            pretrained_model=pretrained_model,\n            device=device,\n            workers=workers,\n            seed=seed,\n            advance_params=advance_params,\n            verbose=verbose,\n        )\n\n        # save train config\n        self.save_train_config(self.cfg, self.train_config_file)\n\n        # check device\n        device = self.cfg.device\n        if device == \"cpu\":\n            # logger.info(\"CPU training\")\n            pass\n        elif device.isdigit():\n            if not torch.cuda.is_available():\n                raise ValueError(\"CUDA is not available.\")\n        elif \",\" in device:\n            if not torch.cuda.is_available():\n                raise ValueError(\"CUDA is not available.\")\n            if not self.MULTI_GPU_TRAIN:\n                raise ValueError(f\"{self.backend} does not support MULTI_GPU_TRAIN.\")\n            if len(device.split(\",\")) &gt; torch.cuda.device_count():\n                raise ValueError(\n                    f\"GPU number is not enough. {device}\\n\"\n                    + f\"Given device: {device}\\n\"\n                    + f\"Available device count: {torch.cuda.device_count()}\"\n                )\n            # TODO: occurs unexpected errors\n            # if not all([int(x) &lt; torch.cuda.device_count() for x in device.split(\",\")]):\n            #     raise IndexError(\n            #         f\"GPU index is out of range. device id should be smaller than {torch.cuda.device_count()}\\n\"\n            #     )\n            # logger.info(f\"Multi GPU training: {device}\")\n        else:\n            raise ValueError(f\"Invalid device: {device}\\n\" + \"Please use 'cpu', '0', '0,1,2,3'\")\n\n        self.run_default_hook(\"before_train\")\n        self.run_callback_hooks(\"before_train\", self)\n\n        self._train()\n\n        self._evaluate(dataset_path)\n\n        self.run_default_hook(\"after_train\")\n        self.run_callback_hooks(\"after_train\", self)\n\n    except FileExistsError as e:\n        raise e\n    except (KeyboardInterrupt, SystemExit) as e:\n        self.run_default_hook(\"on_exception_stopped\", e)\n        self.run_callback_hooks(\"on_exception_stopped\", self, e)\n        if self.artifacts_dir.exists():\n            self.run_default_hook(\"on_train_end\")\n            self.run_callback_hooks(\"on_train_end\", self)\n        raise e\n    except Exception as e:\n        self.run_default_hook(\"on_exception_failed\", e)\n        self.run_callback_hooks(\"on_exception_failed\", self, e)\n        if self.artifacts_dir.exists():\n            io.remove_directory(self.artifacts_dir, recursive=True)\n        raise e\n    finally:\n        self.run_default_hook(\"teardown\")\n        self.run_callback_hooks(\"teardown\", self)\n\n    return self.result\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/callbacks/","title":"ExportOnnxCallback","text":"<p>             Bases: <code>BaseCallback</code>, <code>ABC</code></p> Source code in <code>waffle_hub/hub/onnx_exporter/callbacks/base_callback.py</code> <pre><code>class BaseExportOnnxCallback(BaseCallback, ABC):\n    def __init__(self):\n        pass\n\n    def setup(self, onnx_exporter: OnnxExporter) -&gt; None:\n        \"\"\"Called when worker starts.\"\"\"\n\n    def teardown(self, onnx_exporter: OnnxExporter) -&gt; None:\n        \"\"\"Called when worker ends.\"\"\"\n\n    def before_export_onnx(self, onnx_exporter: OnnxExporter) -&gt; None:\n        \"\"\"Called when the export_onnx begins.\"\"\"\n\n    def on_export_onnx_start(self, onnx_exporter: OnnxExporter) -&gt; None:\n        \"\"\"Called when the export_onnx function begins.\"\"\"\n\n    def on_export_onnx_end(self, onnx_exporter: OnnxExporter) -&gt; None:\n        \"\"\"Called when the export_onnx loop step ends.\"\"\"\n\n    def after_export_onnx(self, onnx_exporter: OnnxExporter) -&gt; None:\n        \"\"\"Called when the export_onnx ends.\"\"\"\n\n    def on_exception_stopped(self, onnx_exporter: OnnxExporter, e: Exception) -&gt; None:\n        \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n\n    def on_exception_failed(self, onnx_exporter: OnnxExporter, e: Exception) -&gt; None:\n        \"\"\"Called when an error occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/callbacks/#waffle_hub.hub.onnx_exporter.callbacks.BaseExportOnnxCallback.after_export_onnx","title":"<code>after_export_onnx(onnx_exporter)</code>","text":"<p>Called when the export_onnx ends.</p> Source code in <code>waffle_hub/hub/onnx_exporter/callbacks/base_callback.py</code> <pre><code>def after_export_onnx(self, onnx_exporter: OnnxExporter) -&gt; None:\n    \"\"\"Called when the export_onnx ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/callbacks/#waffle_hub.hub.onnx_exporter.callbacks.BaseExportOnnxCallback.before_export_onnx","title":"<code>before_export_onnx(onnx_exporter)</code>","text":"<p>Called when the export_onnx begins.</p> Source code in <code>waffle_hub/hub/onnx_exporter/callbacks/base_callback.py</code> <pre><code>def before_export_onnx(self, onnx_exporter: OnnxExporter) -&gt; None:\n    \"\"\"Called when the export_onnx begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/callbacks/#waffle_hub.hub.onnx_exporter.callbacks.BaseExportOnnxCallback.on_exception_failed","title":"<code>on_exception_failed(onnx_exporter, e)</code>","text":"<p>Called when an error occurs</p> Source code in <code>waffle_hub/hub/onnx_exporter/callbacks/base_callback.py</code> <pre><code>def on_exception_failed(self, onnx_exporter: OnnxExporter, e: Exception) -&gt; None:\n    \"\"\"Called when an error occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/callbacks/#waffle_hub.hub.onnx_exporter.callbacks.BaseExportOnnxCallback.on_exception_stopped","title":"<code>on_exception_stopped(onnx_exporter, e)</code>","text":"<p>Called when SIGTERM or SIGINT occurs</p> Source code in <code>waffle_hub/hub/onnx_exporter/callbacks/base_callback.py</code> <pre><code>def on_exception_stopped(self, onnx_exporter: OnnxExporter, e: Exception) -&gt; None:\n    \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/callbacks/#waffle_hub.hub.onnx_exporter.callbacks.BaseExportOnnxCallback.on_export_onnx_end","title":"<code>on_export_onnx_end(onnx_exporter)</code>","text":"<p>Called when the export_onnx loop step ends.</p> Source code in <code>waffle_hub/hub/onnx_exporter/callbacks/base_callback.py</code> <pre><code>def on_export_onnx_end(self, onnx_exporter: OnnxExporter) -&gt; None:\n    \"\"\"Called when the export_onnx loop step ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/callbacks/#waffle_hub.hub.onnx_exporter.callbacks.BaseExportOnnxCallback.on_export_onnx_start","title":"<code>on_export_onnx_start(onnx_exporter)</code>","text":"<p>Called when the export_onnx function begins.</p> Source code in <code>waffle_hub/hub/onnx_exporter/callbacks/base_callback.py</code> <pre><code>def on_export_onnx_start(self, onnx_exporter: OnnxExporter) -&gt; None:\n    \"\"\"Called when the export_onnx function begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/callbacks/#waffle_hub.hub.onnx_exporter.callbacks.BaseExportOnnxCallback.setup","title":"<code>setup(onnx_exporter)</code>","text":"<p>Called when worker starts.</p> Source code in <code>waffle_hub/hub/onnx_exporter/callbacks/base_callback.py</code> <pre><code>def setup(self, onnx_exporter: OnnxExporter) -&gt; None:\n    \"\"\"Called when worker starts.\"\"\"\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/callbacks/#waffle_hub.hub.onnx_exporter.callbacks.BaseExportOnnxCallback.teardown","title":"<code>teardown(onnx_exporter)</code>","text":"<p>Called when worker ends.</p> Source code in <code>waffle_hub/hub/onnx_exporter/callbacks/base_callback.py</code> <pre><code>def teardown(self, onnx_exporter: OnnxExporter) -&gt; None:\n    \"\"\"Called when worker ends.\"\"\"\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/exporter/","title":"Onnx Exporter","text":"<p>             Bases: <code>BaseExportOnnxHook</code></p> <p>export onnx manager class</p> Source code in <code>waffle_hub/hub/onnx_exporter/exporter.py</code> <pre><code>class OnnxExporter(BaseExportOnnxHook):\n    \"\"\"\n    export onnx manager class\n    \"\"\"\n\n    # directory settting\n    EXPORT_DIR = Path(\"weights\")\n\n    # export results file path ##--\n    ONNX_FILE = EXPORT_DIR / \"model.onnx\"\n\n    def __init__(\n        self,\n        root_dir: Path,\n        model: ModelWrapper,\n        callbacks: list[BaseCallback] = None,\n    ):\n        super().__init__(callbacks)\n        self.root_dir = Path(root_dir)\n        self.model = model\n        self.state = ExportOnnxState(status=ExportOnnxStatus.INIT)\n        self.result = ExportOnnxResult()\n\n    # properties\n    @property\n    def export_dir(self) -&gt; Path:\n        \"\"\"Export Directory\"\"\"\n        return self.root_dir / self.EXPORT_DIR\n\n    @property\n    def onnx_file(self) -&gt; Path:\n        \"\"\"Best Checkpoint ONNX File\"\"\"\n        return self.root_dir / self.ONNX_FILE\n\n    # methods\n    @device_context\n    def export(\n        self,\n        image_size: Union[int, list[int]] = [640, 640],\n        batch_size: int = 16,\n        opset_version: int = 11,\n        half: bool = False,\n        device: str = \"0\",\n    ) -&gt; ExportOnnxResult:\n        \"\"\"Export Onnx Model\n\n        Args:\n            image_size (Union[int, list[int]], optional): Export image size. Default to [640, 640].\n            batch_size (int, optional): dynamic batch size. Defaults to 16.\n            opset_version (int, optional): onnx opset version. Defaults to 11.\n            half (bool, optional): half. Defaults to False.\n            device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n\n        Examples:\n            &gt;&gt;&gt; exporter = OnnxExporter(...)\n            &gt;&gt;&gt; export_onnx_result = exporter.export(\n                image_size=640,\n                batch_size=16,\n                opset_version=11,\n            )\n            &gt;&gt;&gt; export_onnx_result.onnx_file\n            hubs/my_hub/weights/model.onnx\n\n        Returns:\n            ExportOnnxResult: export onnx result\n        \"\"\"\n\n        try:\n            self.run_default_hook(\"setup\")\n            self.run_callback_hooks(\"setup\", self)\n\n            self.cfg = ExportOnnxConfig(\n                image_size=image_size if isinstance(image_size, list) else [image_size, image_size],\n                batch_size=batch_size,\n                opset_version=opset_version,\n                half=half,\n                device=\"cpu\" if device == \"cpu\" else f\"cuda:{device}\",\n            )\n            self.run_default_hook(\"before_export_onnx\")\n            self.run_callback_hooks(\"before_export_onnx\", self)\n\n            self._export_onnx()\n\n            self.run_default_hook(\"after_export_onnx\")\n            self.run_callback_hooks(\"after_export_onnx\", self)\n\n        except (KeyboardInterrupt, SystemExit) as e:\n            self.run_default_hook(\"on_exception_stopped\", e)\n            self.run_callback_hooks(\"on_exception_stopped\", self, e)\n            raise e\n        except Exception as e:\n            self.run_default_hook(\"on_exception_failed\", e)\n            self.run_callback_hooks(\"on_exception_failed\", self, e)\n            if self.onnx_file.exists():\n                io.remove_file(self.onnx_file)\n            raise e\n        finally:\n            self.run_default_hook(\"teardown\")\n            self.run_callback_hooks(\"teardown\", self)\n\n        return self.result\n\n    def _export_onnx(self):\n        self.run_default_hook(\"on_export_onnx_start\")\n        self.run_callback_hooks(\"on_export_onnx_start\", self)\n\n        image_size = self.cfg.image_size\n        image_size = [image_size, image_size] if isinstance(image_size, int) else image_size\n\n        model = self.model.half() if self.cfg.half else self.model\n        model = model.to(self.cfg.device)\n\n        input_name = [\"inputs\"]\n        if self.model.task == TaskType.OBJECT_DETECTION:\n            output_names = [\"bbox\", \"conf\", \"class_id\"]\n        elif self.model.task == TaskType.CLASSIFICATION:\n            output_names = [\"predictions\"]\n        elif self.model.task == TaskType.INSTANCE_SEGMENTATION:\n            output_names = [\"bbox\", \"conf\", \"class_id\", \"masks\"]\n        elif self.model.task == TaskType.TEXT_RECOGNITION:\n            output_names = [\"class_ids\", \"confs\"]\n        elif self.model.task == TaskType.SEMANTIC_SEGMENTATION:\n            output_names = [\"score_map\"]\n        else:\n            raise NotImplementedError(f\"{self.task} does not support export yet.\")\n\n        dummy_input = torch.randn(\n            self.cfg.batch_size,\n            3,\n            *image_size,\n            dtype=torch.float16 if self.cfg.half else torch.float32,\n        )\n        dummy_input = dummy_input.to(self.cfg.device)\n\n        torch.onnx.export(\n            model,\n            dummy_input,\n            str(self.onnx_file),\n            input_names=input_name,\n            output_names=output_names,\n            opset_version=self.cfg.opset_version,\n            dynamic_axes={name: {0: \"batch_size\"} for name in input_name + output_names},\n        )\n\n        self.run_default_hook(\"on_export_onnx_end\")\n        self.run_callback_hooks(\"on_export_onnx_end\", self)\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/exporter/#waffle_hub.hub.onnx_exporter.exporter.OnnxExporter.export_dir","title":"<code>export_dir: Path</code>  <code>property</code>","text":"<p>Export Directory</p>"},{"location":"waffle_hub/onnx_exporter/exporter/#waffle_hub.hub.onnx_exporter.exporter.OnnxExporter.onnx_file","title":"<code>onnx_file: Path</code>  <code>property</code>","text":"<p>Best Checkpoint ONNX File</p>"},{"location":"waffle_hub/onnx_exporter/exporter/#waffle_hub.hub.onnx_exporter.exporter.OnnxExporter.export","title":"<code>export(image_size=[640, 640], batch_size=16, opset_version=11, half=False, device='0')</code>","text":"<p>Export Onnx Model</p> <p>Parameters:</p> Name Type Description Default <code>image_size</code> <code>Union[int, list[int]]</code> <p>Export image size. Default to [640, 640].</p> <code>[640, 640]</code> <code>batch_size</code> <code>int</code> <p>dynamic batch size. Defaults to 16.</p> <code>16</code> <code>opset_version</code> <code>int</code> <p>onnx opset version. Defaults to 11.</p> <code>11</code> <code>half</code> <code>bool</code> <p>half. Defaults to False.</p> <code>False</code> <code>device</code> <code>str</code> <p>device. \"cpu\" or \"gpu_id\". Defaults to \"0\".</p> <code>'0'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; exporter = OnnxExporter(...)\n&gt;&gt;&gt; export_onnx_result = exporter.export(\n    image_size=640,\n    batch_size=16,\n    opset_version=11,\n)\n&gt;&gt;&gt; export_onnx_result.onnx_file\nhubs/my_hub/weights/model.onnx\n</code></pre> <p>Returns:</p> Name Type Description <code>ExportOnnxResult</code> <code>ExportOnnxResult</code> <p>export onnx result</p> Source code in <code>waffle_hub/hub/onnx_exporter/exporter.py</code> <pre><code>@device_context\ndef export(\n    self,\n    image_size: Union[int, list[int]] = [640, 640],\n    batch_size: int = 16,\n    opset_version: int = 11,\n    half: bool = False,\n    device: str = \"0\",\n) -&gt; ExportOnnxResult:\n    \"\"\"Export Onnx Model\n\n    Args:\n        image_size (Union[int, list[int]], optional): Export image size. Default to [640, 640].\n        batch_size (int, optional): dynamic batch size. Defaults to 16.\n        opset_version (int, optional): onnx opset version. Defaults to 11.\n        half (bool, optional): half. Defaults to False.\n        device (str, optional): device. \"cpu\" or \"gpu_id\". Defaults to \"0\".\n\n    Examples:\n        &gt;&gt;&gt; exporter = OnnxExporter(...)\n        &gt;&gt;&gt; export_onnx_result = exporter.export(\n            image_size=640,\n            batch_size=16,\n            opset_version=11,\n        )\n        &gt;&gt;&gt; export_onnx_result.onnx_file\n        hubs/my_hub/weights/model.onnx\n\n    Returns:\n        ExportOnnxResult: export onnx result\n    \"\"\"\n\n    try:\n        self.run_default_hook(\"setup\")\n        self.run_callback_hooks(\"setup\", self)\n\n        self.cfg = ExportOnnxConfig(\n            image_size=image_size if isinstance(image_size, list) else [image_size, image_size],\n            batch_size=batch_size,\n            opset_version=opset_version,\n            half=half,\n            device=\"cpu\" if device == \"cpu\" else f\"cuda:{device}\",\n        )\n        self.run_default_hook(\"before_export_onnx\")\n        self.run_callback_hooks(\"before_export_onnx\", self)\n\n        self._export_onnx()\n\n        self.run_default_hook(\"after_export_onnx\")\n        self.run_callback_hooks(\"after_export_onnx\", self)\n\n    except (KeyboardInterrupt, SystemExit) as e:\n        self.run_default_hook(\"on_exception_stopped\", e)\n        self.run_callback_hooks(\"on_exception_stopped\", self, e)\n        raise e\n    except Exception as e:\n        self.run_default_hook(\"on_exception_failed\", e)\n        self.run_callback_hooks(\"on_exception_failed\", self, e)\n        if self.onnx_file.exists():\n            io.remove_file(self.onnx_file)\n        raise e\n    finally:\n        self.run_default_hook(\"teardown\")\n        self.run_callback_hooks(\"teardown\", self)\n\n    return self.result\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/hook/","title":"ExportOnnxHook","text":"<p>             Bases: <code>BaseHook</code></p> Source code in <code>waffle_hub/hub/onnx_exporter/hook.py</code> <pre><code>class BaseExportOnnxHook(BaseHook):\n    def __init__(self, callbacks: list[BaseCallback] = None):\n        super().__init__(callbacks)\n\n    def setup(self) -&gt; None:\n        \"\"\"Called when worker starts.\"\"\"\n        _register_signal_handler()\n\n    def teardown(self) -&gt; None:\n        \"\"\"Called when worker ends.\"\"\"\n\n    def before_export_onnx(self) -&gt; None:\n        \"\"\"Called when the export_onnx begins.\"\"\"\n\n    def on_export_onnx_start(self) -&gt; None:\n        \"\"\"Called when the export_onnx function begins.\"\"\"\n        self.state.status = ExportOnnxStatus.RUNNING\n        self.state.clear_error()\n\n    def on_export_onnx_end(self) -&gt; None:\n        \"\"\"Called when the export_onnx loop step ends.\"\"\"\n        self.result.onnx_file = self.onnx_file\n\n    def after_export_onnx(self) -&gt; None:\n        \"\"\"Called when the export_onnx ends.\"\"\"\n        self.state.status = ExportOnnxStatus.SUCCESS\n\n    def on_exception_stopped(self, e: Exception) -&gt; None:\n        \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n        self.state.status = ExportOnnxStatus.STOPPED\n        self.state.set_error(e)\n\n    def on_exception_failed(self, e: Exception) -&gt; None:\n        \"\"\"Called when an error occurs\"\"\"\n        self.state.status = ExportOnnxStatus.FAILED\n        self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/hook/#waffle_hub.hub.onnx_exporter.hook.BaseExportOnnxHook.after_export_onnx","title":"<code>after_export_onnx()</code>","text":"<p>Called when the export_onnx ends.</p> Source code in <code>waffle_hub/hub/onnx_exporter/hook.py</code> <pre><code>def after_export_onnx(self) -&gt; None:\n    \"\"\"Called when the export_onnx ends.\"\"\"\n    self.state.status = ExportOnnxStatus.SUCCESS\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/hook/#waffle_hub.hub.onnx_exporter.hook.BaseExportOnnxHook.before_export_onnx","title":"<code>before_export_onnx()</code>","text":"<p>Called when the export_onnx begins.</p> Source code in <code>waffle_hub/hub/onnx_exporter/hook.py</code> <pre><code>def before_export_onnx(self) -&gt; None:\n    \"\"\"Called when the export_onnx begins.\"\"\"\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/hook/#waffle_hub.hub.onnx_exporter.hook.BaseExportOnnxHook.on_exception_failed","title":"<code>on_exception_failed(e)</code>","text":"<p>Called when an error occurs</p> Source code in <code>waffle_hub/hub/onnx_exporter/hook.py</code> <pre><code>def on_exception_failed(self, e: Exception) -&gt; None:\n    \"\"\"Called when an error occurs\"\"\"\n    self.state.status = ExportOnnxStatus.FAILED\n    self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/hook/#waffle_hub.hub.onnx_exporter.hook.BaseExportOnnxHook.on_exception_stopped","title":"<code>on_exception_stopped(e)</code>","text":"<p>Called when SIGTERM or SIGINT occurs</p> Source code in <code>waffle_hub/hub/onnx_exporter/hook.py</code> <pre><code>def on_exception_stopped(self, e: Exception) -&gt; None:\n    \"\"\"Called when SIGTERM or SIGINT occurs\"\"\"\n    self.state.status = ExportOnnxStatus.STOPPED\n    self.state.set_error(e)\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/hook/#waffle_hub.hub.onnx_exporter.hook.BaseExportOnnxHook.on_export_onnx_end","title":"<code>on_export_onnx_end()</code>","text":"<p>Called when the export_onnx loop step ends.</p> Source code in <code>waffle_hub/hub/onnx_exporter/hook.py</code> <pre><code>def on_export_onnx_end(self) -&gt; None:\n    \"\"\"Called when the export_onnx loop step ends.\"\"\"\n    self.result.onnx_file = self.onnx_file\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/hook/#waffle_hub.hub.onnx_exporter.hook.BaseExportOnnxHook.on_export_onnx_start","title":"<code>on_export_onnx_start()</code>","text":"<p>Called when the export_onnx function begins.</p> Source code in <code>waffle_hub/hub/onnx_exporter/hook.py</code> <pre><code>def on_export_onnx_start(self) -&gt; None:\n    \"\"\"Called when the export_onnx function begins.\"\"\"\n    self.state.status = ExportOnnxStatus.RUNNING\n    self.state.clear_error()\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/hook/#waffle_hub.hub.onnx_exporter.hook.BaseExportOnnxHook.setup","title":"<code>setup()</code>","text":"<p>Called when worker starts.</p> Source code in <code>waffle_hub/hub/onnx_exporter/hook.py</code> <pre><code>def setup(self) -&gt; None:\n    \"\"\"Called when worker starts.\"\"\"\n    _register_signal_handler()\n</code></pre>"},{"location":"waffle_hub/onnx_exporter/hook/#waffle_hub.hub.onnx_exporter.hook.BaseExportOnnxHook.teardown","title":"<code>teardown()</code>","text":"<p>Called when worker ends.</p> Source code in <code>waffle_hub/hub/onnx_exporter/hook.py</code> <pre><code>def teardown(self) -&gt; None:\n    \"\"\"Called when worker ends.\"\"\"\n</code></pre>"}]}